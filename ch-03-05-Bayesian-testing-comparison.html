<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11.4 Testing via model comparison | An Introduction to Data Analysis</title>
  <meta name="description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="generator" content="bookdown 0.32.1 and GitBook 2.6.7" />

  <meta property="og:title" content="11.4 Testing via model comparison | An Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11.4 Testing via model comparison | An Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Introductory text for statistics and data analysis (using R)" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-03-05-Bayes-testing-estimation.html"/>
<link rel="next" href="Chap-04-01-simple-linear-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!--<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.css">-->
<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.css">

<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-v0.9.13.js" defer async></script>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />

<script type="application/javascript">
document.addEventListener('DOMContentLoaded', function() {
  document.querySelectorAll('.collapsibleSolution, .collapsibleProof').forEach(function(collapsible) {
    const content = collapsible.querySelector('.content')
    content.style.display = 'none';
    collapsible.querySelector('.trigger').addEventListener('click', function() {
      if (content.style.display === 'none') {
        content.style.display = 'block';
      } else {
        content.style.display = 'none';
      }
    })
  })
})
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
<link rel="stylesheet" href="webppl-editor.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="index.html#section" id="toc-section"></a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="Chap-01-00-intro-learning-goals.html"><a href="Chap-01-00-intro-learning-goals.html"><i class="fa fa-check"></i><b>1.1</b> Learning goals</a></li>
<li class="chapter" data-level="1.2" data-path="Chap-01-00-intro-course-structure.html"><a href="Chap-01-00-intro-course-structure.html"><i class="fa fa-check"></i><b>1.2</b> Course structure</a></li>
<li class="chapter" data-level="1.3" data-path="Chap-01-00-intro-tools.html"><a href="Chap-01-00-intro-tools.html"><i class="fa fa-check"></i><b>1.3</b> Tools used in this course</a></li>
<li class="chapter" data-level="1.4" data-path="Chap-01-00-intro-topics.html"><a href="Chap-01-00-intro-topics.html"><i class="fa fa-check"></i><b>1.4</b> Topics covered (and not covered) in the course</a></li>
<li class="chapter" data-level="1.5" data-path="Chap-01-00-intro-data-sets.html"><a href="Chap-01-00-intro-data-sets.html"><i class="fa fa-check"></i><b>1.5</b> Data sets covered</a></li>
<li class="chapter" data-level="1.6" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html"><i class="fa fa-check"></i><b>1.6</b> Installation</a></li>
<li class="chapter" data-level="1.7" data-path="Chap-01-00-intro-schedule.html"><a href="Chap-01-00-intro-schedule.html"><i class="fa fa-check"></i><b>1.7</b> Example schedule (12-week course)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap-01-01-R.html"><a href="Chap-01-01-R.html"><i class="fa fa-check"></i><b>2</b> Basics of R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>2.1</b> First steps</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#functions"><i class="fa fa-check"></i><b>2.1.1</b> Functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>2.1.2</b> Variables</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>2.1.3</b> Literate coding</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>2.1.4</b> Objects</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#packages"><i class="fa fa-check"></i><b>2.1.5</b> Packages</a></li>
<li class="chapter" data-level="2.1.6" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#Chap-01-01-R-help"><i class="fa fa-check"></i><b>2.1.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>2.2</b> Data types</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numeric-vectors-matrices"><i class="fa fa-check"></i><b>2.2.1</b> Numeric vectors &amp; matrices</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>2.2.2</b> Booleans</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>2.2.3</b> Special values</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>2.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>2.2.5</b> Factors</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>2.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html"><i class="fa fa-check"></i><b>2.3</b> Functions</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#some-important-built-in-functions"><i class="fa fa-check"></i><b>2.3.1</b> Some important built-in functions</a></li>
<li class="chapter" data-level="2.3.2" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#defining-your-own-functions"><i class="fa fa-check"></i><b>2.3.2</b> Defining your own functions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html"><i class="fa fa-check"></i><b>2.4</b> Loops and maps</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#for-loops"><i class="fa fa-check"></i><b>2.4.1</b> For-loops</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#functional-iterators"><i class="fa fa-check"></i><b>2.4.2</b> Functional iterators</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html"><i class="fa fa-check"></i><b>2.5</b> Piping</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html#excursion-more-on-pipes-in-r"><i class="fa fa-check"></i><b>2.5.1</b> Excursion: More on pipes in R</a></li>
<li class="chapter" data-level="2.5.2" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html#excursion-multiple-assignments-or-unpacking"><i class="fa fa-check"></i><b>2.5.2</b> Excursion: Multiple assignments, or “unpacking”</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch-01-01-Rmarkdown.html"><a href="ch-01-01-Rmarkdown.html"><i class="fa fa-check"></i><b>2.6</b> Rmarkdown</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="3" data-path="Chap-02-01-data.html"><a href="Chap-02-01-data.html"><i class="fa fa-check"></i><b>3</b> Data, variables &amp; experimental designs</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Chap-02-01-data-what-is-data.html"><a href="Chap-02-01-data-what-is-data.html"><i class="fa fa-check"></i><b>3.1</b> What is data?</a></li>
<li class="chapter" data-level="3.2" data-path="Chap-02-01-data-kinds-of-data.html"><a href="Chap-02-01-data-kinds-of-data.html"><i class="fa fa-check"></i><b>3.2</b> Different kinds of data</a></li>
<li class="chapter" data-level="3.3" data-path="Chap-02-01-data-variables.html"><a href="Chap-02-01-data-variables.html"><i class="fa fa-check"></i><b>3.3</b> On the notion of “variables”</a></li>
<li class="chapter" data-level="3.4" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html"><i class="fa fa-check"></i><b>3.4</b> Basics of experimental design</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#what-to-analyze-dependent-variables"><i class="fa fa-check"></i><b>3.4.1</b> What to analyze? – Dependent variables</a></li>
<li class="chapter" data-level="3.4.2" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#conditions-trials-items"><i class="fa fa-check"></i><b>3.4.2</b> Conditions, trials, items</a></li>
<li class="chapter" data-level="3.4.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#sample-size"><i class="fa fa-check"></i><b>3.4.3</b> Sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Chap-02-02-data-IO.html"><a href="Chap-02-02-data-IO.html"><i class="fa fa-check"></i><b>4.1</b> Data in, data out</a></li>
<li class="chapter" data-level="4.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#running-example"><i class="fa fa-check"></i><b>4.2.1</b> Running example</a></li>
<li class="chapter" data-level="4.2.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>4.2.2</b> Definition of <em>tidy data</em></a></li>
<li class="chapter" data-level="4.2.3" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#excursion-non-redundant-data"><i class="fa fa-check"></i><b>4.2.3</b> Excursion: non-redundant data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html"><i class="fa fa-check"></i><b>4.3</b> Data manipulation: the basics</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#pivoting"><i class="fa fa-check"></i><b>4.3.1</b> Pivoting</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#subsetting-rows-columns"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting rows &amp; columns</a></li>
<li class="chapter" data-level="4.3.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#Chap-02-02-tidy-selection"><i class="fa fa-check"></i><b>4.3.3</b> Tidy selection of column names</a></li>
<li class="chapter" data-level="4.3.4" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#adding-changing-and-renaming-columns"><i class="fa fa-check"></i><b>4.3.4</b> Adding, changing and renaming columns</a></li>
<li class="chapter" data-level="4.3.5" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#splitting-and-uniting-columns"><i class="fa fa-check"></i><b>4.3.5</b> Splitting and uniting columns</a></li>
<li class="chapter" data-level="4.3.6" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#sorting-a-data-set"><i class="fa fa-check"></i><b>4.3.6</b> Sorting a data set</a></li>
<li class="chapter" data-level="4.3.7" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#combining-tibbles"><i class="fa fa-check"></i><b>4.3.7</b> Combining tibbles</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chap-02-02-data-grouping-nesting.html"><a href="Chap-02-02-data-grouping-nesting.html"><i class="fa fa-check"></i><b>4.4</b> Grouped operations</a></li>
<li class="chapter" data-level="4.5" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html"><i class="fa fa-check"></i><b>4.5</b> Case study: the King of France</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html#cleaning-the-data"><i class="fa fa-check"></i><b>4.5.1</b> Cleaning the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap-02-03-summary-statistics.html"><a href="Chap-02-03-summary-statistics.html"><i class="fa fa-check"></i><b>5</b> Summary statistics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html"><i class="fa fa-check"></i><b>5.1</b> Counts and proportions</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#loading-and-inspecting-the-data"><i class="fa fa-check"></i><b>5.1.1</b> Loading and inspecting the data</a></li>
<li class="chapter" data-level="5.1.2" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#obtaining-counts-with-n-count-and-tally"><i class="fa fa-check"></i><b>5.1.2</b> Obtaining counts with <code>n</code>, <code>count</code> and <code>tally</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html"><i class="fa fa-check"></i><b>5.2</b> Central tendency and dispersion</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#the-data-for-the-remainder-of-the-chapter"><i class="fa fa-check"></i><b>5.2.1</b> The data for the remainder of the chapter</a></li>
<li class="chapter" data-level="5.2.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.2.2</b> Measures of central tendency</a></li>
<li class="chapter" data-level="5.2.3" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-dispersion"><i class="fa fa-check"></i><b>5.2.3</b> Measures of dispersion</a></li>
<li class="chapter" data-level="5.2.4" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#excursion-quantifying-confidence-with-bootstrapping"><i class="fa fa-check"></i><b>5.2.4</b> Excursion: Quantifying confidence with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html"><i class="fa fa-check"></i><b>5.3</b> Covariance and correlation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#covariance"><i class="fa fa-check"></i><b>5.3.1</b> Covariance</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#correlation"><i class="fa fa-check"></i><b>5.3.2</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap-02-02-visualization.html"><a href="Chap-02-02-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Chap-02-04-Anscombe-example.html"><a href="Chap-02-04-Anscombe-example.html"><i class="fa fa-check"></i><b>6.1</b> Motivating example: Anscombe’s quartet</a></li>
<li class="chapter" data-level="6.2" data-path="Chap-02-04-good-visualization.html"><a href="Chap-02-04-good-visualization.html"><i class="fa fa-check"></i><b>6.2</b> Visualization: the good, the bad and the infographic</a></li>
<li class="chapter" data-level="6.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html"><i class="fa fa-check"></i><b>6.3</b> Basics of <code>ggplot</code></a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#incremental-composition-of-a-plot"><i class="fa fa-check"></i><b>6.3.1</b> Incremental composition of a plot</a></li>
<li class="chapter" data-level="6.3.2" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#elements-in-the-layered-grammar-of-graphs"><i class="fa fa-check"></i><b>6.3.2</b> Elements in the layered grammar of graphs</a></li>
<li class="chapter" data-level="6.3.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#layers-and-groups"><i class="fa fa-check"></i><b>6.3.3</b> Layers and groups</a></li>
<li class="chapter" data-level="6.3.4" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#grouping"><i class="fa fa-check"></i><b>6.3.4</b> Grouping</a></li>
<li class="chapter" data-level="6.3.5" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#example-of-a-customized-plot"><i class="fa fa-check"></i><b>6.3.5</b> Example of a customized plot</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html"><i class="fa fa-check"></i><b>6.4</b> A rendezvous with popular geoms</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#scatter-plots-with-geom_point"><i class="fa fa-check"></i><b>6.4.1</b> Scatter plots with <code>geom_point</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#smooth"><i class="fa fa-check"></i><b>6.4.2</b> Smooth</a></li>
<li class="chapter" data-level="6.4.3" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#line"><i class="fa fa-check"></i><b>6.4.3</b> Line</a></li>
<li class="chapter" data-level="6.4.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#bar-plot"><i class="fa fa-check"></i><b>6.4.4</b> Bar plot</a></li>
<li class="chapter" data-level="6.4.5" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#plotting-distributions-histograms-boxplots-densities-and-violins"><i class="fa fa-check"></i><b>6.4.5</b> Plotting distributions: histograms, boxplots, densities and violins</a></li>
<li class="chapter" data-level="6.4.6" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#rugs"><i class="fa fa-check"></i><b>6.4.6</b> Rugs</a></li>
<li class="chapter" data-level="6.4.7" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#annotation"><i class="fa fa-check"></i><b>6.4.7</b> Annotation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Chap-02-04-faceting.html"><a href="Chap-02-04-faceting.html"><i class="fa fa-check"></i><b>6.5</b> Faceting</a></li>
<li class="chapter" data-level="6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html"><i class="fa fa-check"></i><b>6.6</b> Customization etc.</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#themes"><i class="fa fa-check"></i><b>6.6.1</b> Themes</a></li>
<li class="chapter" data-level="6.6.2" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#guides"><i class="fa fa-check"></i><b>6.6.2</b> Guides</a></li>
<li class="chapter" data-level="6.6.3" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#axes-ticks-and-tick-labels"><i class="fa fa-check"></i><b>6.6.3</b> Axes, ticks and tick labels</a></li>
<li class="chapter" data-level="6.6.4" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#labels"><i class="fa fa-check"></i><b>6.6.4</b> Labels</a></li>
<li class="chapter" data-level="6.6.5" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#combining-arranging-plots"><i class="fa fa-check"></i><b>6.6.5</b> Combining &amp; arranging plots</a></li>
<li class="chapter" data-level="6.6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#latex-expressions-in-plot-labels"><i class="fa fa-check"></i><b>6.6.6</b> LaTeX expressions in plot labels</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Bayesian Data Analysis</b></span></li>
<li class="chapter" data-level="7" data-path="Chap-03-01-probability.html"><a href="Chap-03-01-probability.html"><i class="fa fa-check"></i><b>7</b> Basics of Probability Theory</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html"><i class="fa fa-check"></i><b>7.1</b> Probability</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#outcomes-events-observations"><i class="fa fa-check"></i><b>7.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="7.1.2" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.3" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#interpretations-of-probability"><i class="fa fa-check"></i><b>7.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="7.1.4" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#distributions-as-samples"><i class="fa fa-check"></i><b>7.1.4</b> Distributions as samples</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html"><i class="fa fa-check"></i><b>7.2</b> Structured events &amp; marginal distributions</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#probability-table-for-a-flip-and-draw-scenario"><i class="fa fa-check"></i><b>7.2.1</b> Probability table for a flip-and-draw scenario</a></li>
<li class="chapter" data-level="7.2.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>7.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="7.2.3" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#marginalization"><i class="fa fa-check"></i><b>7.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html"><i class="fa fa-check"></i><b>7.3</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#bayes-rule"><i class="fa fa-check"></i><b>7.3.1</b> Bayes rule</a></li>
<li class="chapter" data-level="7.3.2" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence"><i class="fa fa-check"></i><b>7.3.2</b> Stochastic (in-)dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html"><i class="fa fa-check"></i><b>7.4</b> Random variables</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>7.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="7.4.2" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>7.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
<li class="chapter" data-level="7.4.3" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#expected-value-variance"><i class="fa fa-check"></i><b>7.4.3</b> Expected value &amp; variance</a></li>
<li class="chapter" data-level="7.4.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#composite-random-variables"><i class="fa fa-check"></i><b>7.4.4</b> Composite random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Chap-03-01-probability-R.html"><a href="Chap-03-01-probability-R.html"><i class="fa fa-check"></i><b>7.5</b> Probability distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap-03-03-models.html"><a href="Chap-03-03-models.html"><i class="fa fa-check"></i><b>8</b> Statistical models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html"><i class="fa fa-check"></i><b>8.1</b> Statistical models</a></li>
<li class="chapter" data-level="8.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html"><i class="fa fa-check"></i><b>8.2</b> Notation &amp; graphical representation</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#formula-notation"><i class="fa fa-check"></i><b>8.2.1</b> Formula notation</a></li>
<li class="chapter" data-level="8.2.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#graphical-notation"><i class="fa fa-check"></i><b>8.2.2</b> Graphical notation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html"><i class="fa fa-check"></i><b>8.3</b> Parameters, priors, and prior predictions</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#whats-a-model-parameter"><i class="fa fa-check"></i><b>8.3.1</b> What’s a model parameter?</a></li>
<li class="chapter" data-level="8.3.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-02-models-priors"><i class="fa fa-check"></i><b>8.3.2</b> Priors over parameters</a></li>
<li class="chapter" data-level="8.3.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-03-models-parameters-prior-predictive"><i class="fa fa-check"></i><b>8.3.3</b> Prior predictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-03-04-parameter-estimation.html"><a href="ch-03-04-parameter-estimation.html"><i class="fa fa-check"></i><b>9</b> Bayesian parameter estimation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html"><i class="fa fa-check"></i><b>9.1</b> Bayes rule for parameter estimation</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#definitions-and-terminology"><i class="fa fa-check"></i><b>9.1.1</b> Definitions and terminology</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#the-effects-of-prior-and-likelihood-on-the-posterior"><i class="fa fa-check"></i><b>9.1.2</b> The effects of prior and likelihood on the posterior</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#ch-03-04-parameter-estimation-conjugacy"><i class="fa fa-check"></i><b>9.1.3</b> Computing Bayesian posteriors with conjugate priors</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#excursion-sequential-updating"><i class="fa fa-check"></i><b>9.1.4</b> Excursion: Sequential updating</a></li>
<li class="chapter" data-level="9.1.5" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>9.1.5</b> Posterior predictive distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html"><i class="fa fa-check"></i><b>9.2</b> Point-valued and interval-ranged estimates</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#point-valued-estimates"><i class="fa fa-check"></i><b>9.2.1</b> Point-valued estimates</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#interval-ranged-estimates"><i class="fa fa-check"></i><b>9.2.2</b> Interval-ranged estimates</a></li>
<li class="chapter" data-level="9.2.3" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#computing-bayesian-estimates"><i class="fa fa-check"></i><b>9.2.3</b> Computing Bayesian estimates</a></li>
<li class="chapter" data-level="9.2.4" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#excursion-computing-mles-and-maps-in-r"><i class="fa fa-check"></i><b>9.2.4</b> Excursion: Computing MLEs and MAPs in R</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html"><i class="fa fa-check"></i><b>9.3</b> Approximating the posterior</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-MCMC"><i class="fa fa-check"></i><b>9.3.1</b> Of apples and trees: Markov Chain Monte Carlo sampling</a></li>
<li class="chapter" data-level="9.3.2" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-estimation-Stan"><i class="fa fa-check"></i><b>9.3.2</b> Excursion: Probabilistic modeling with Stan</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html"><i class="fa fa-check"></i><b>9.4</b> Estimating the parameters of a Normal distribution</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#uninformative-priors"><i class="fa fa-check"></i><b>9.4.1</b> Uninformative priors</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#conjugate-priors"><i class="fa fa-check"></i><b>9.4.2</b> Conjugate priors</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#estimating-the-difference-between-group-means"><i class="fa fa-check"></i><b>9.4.3</b> Estimating the difference between group means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap-03-06-model-comparison.html"><a href="Chap-03-06-model-comparison.html"><i class="fa fa-check"></i><b>10</b> Model Comparison</a>
<ul>
<li class="chapter" data-level="10.1" data-path="Chap-03-06-model-comparison-case-study.html"><a href="Chap-03-06-model-comparison-case-study.html"><i class="fa fa-check"></i><b>10.1</b> Case study: recall models</a></li>
<li class="chapter" data-level="10.2" data-path="Chap-03-06-model-comparison-AIC.html"><a href="Chap-03-06-model-comparison-AIC.html"><i class="fa fa-check"></i><b>10.2</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="10.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html"><i class="fa fa-check"></i><b>10.3</b> Bayes factors</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-grid"><i class="fa fa-check"></i><b>10.3.1</b> Grid approximation</a></li>
<li class="chapter" data-level="10.3.2" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-naiveMC"><i class="fa fa-check"></i><b>10.3.2</b> Naive Monte Carlo</a></li>
<li class="chapter" data-level="10.3.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-bridge"><i class="fa fa-check"></i><b>10.3.3</b> Excursion: Bridge sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-03-07-hypothesis-testing-Bayes.html"><a href="ch-03-07-hypothesis-testing-Bayes.html"><i class="fa fa-check"></i><b>11</b> Bayesian hypothesis testing</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><a href="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><i class="fa fa-check"></i><b>11.1</b> Statistical hypotheses</a></li>
<li class="chapter" data-level="11.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html"><i class="fa fa-check"></i><b>11.2</b> Data and models for this chapter</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#section-1"><i class="fa fa-check"></i><b>11.2.1</b> 24/7</a></li>
<li class="chapter" data-level="11.2.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#simon-task"><i class="fa fa-check"></i><b>11.2.2</b> Simon task</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html"><i class="fa fa-check"></i><b>11.3</b> Testing via posterior estimation</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-247"><i class="fa fa-check"></i><b>11.3.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-simon-task"><i class="fa fa-check"></i><b>11.3.2</b> Example: Simon Task</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html"><i class="fa fa-check"></i><b>11.4</b> Testing via model comparison</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey"><i class="fa fa-check"></i><b>11.4.1</b> The Savage-Dickey method</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models"><i class="fa fa-check"></i><b>11.4.2</b> Encompassing models</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Applied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="12" data-path="Chap-04-01-simple-linear-regression.html"><a href="Chap-04-01-simple-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Linear regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html"><i class="fa fa-check"></i><b>12.1</b> Ordinary least squares regression</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-without-any-further-information"><i class="fa fa-check"></i><b>12.1.1</b> Prediction without any further information</a></li>
<li class="chapter" data-level="12.1.2" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-with-knowledge-of-unemployment-rate"><i class="fa fa-check"></i><b>12.1.2</b> Prediction with knowledge of unemployment rate</a></li>
<li class="chapter" data-level="12.1.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#linear-regression-general-problem-formulation"><i class="fa fa-check"></i><b>12.1.3</b> Linear regression: general problem formulation</a></li>
<li class="chapter" data-level="12.1.4" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#finding-the-ols-solution"><i class="fa fa-check"></i><b>12.1.4</b> Finding the OLS-solution</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html"><i class="fa fa-check"></i><b>12.2</b> A maximum-likelihood approach</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#a-likelihood-based-model"><i class="fa fa-check"></i><b>12.2.1</b> A likelihood-based model</a></li>
<li class="chapter" data-level="12.2.2" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-optim"><i class="fa fa-check"></i><b>12.2.2</b> Finding the MLE-solution with <code>optim</code></a></li>
<li class="chapter" data-level="12.2.3" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-glm"><i class="fa fa-check"></i><b>12.2.3</b> Finding the MLE-solution with <code>glm</code></a></li>
<li class="chapter" data-level="12.2.4" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-math"><i class="fa fa-check"></i><b>12.2.4</b> Finding the MLE-solution with math</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html"><i class="fa fa-check"></i><b>12.3</b> A Bayesian approach</a></li>
<li class="chapter" data-level="12.4" data-path="comparison-of-approaches.html"><a href="comparison-of-approaches.html"><i class="fa fa-check"></i><b>12.4</b> Comparison of approaches</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap-04-02-Bayes-regression-practice.html"><a href="Chap-04-02-Bayes-regression-practice.html"><i class="fa fa-check"></i><b>13</b> Bayesian regression in practice</a>
<ul>
<li class="chapter" data-level="13.1" data-path="simple-linear-regression-with-brms.html"><a href="simple-linear-regression-with-brms.html"><i class="fa fa-check"></i><b>13.1</b> Simple linear regression with <code>brms</code></a></li>
<li class="chapter" data-level="13.2" data-path="extracting-posterior-samples.html"><a href="extracting-posterior-samples.html"><i class="fa fa-check"></i><b>13.2</b> Extracting posterior samples</a></li>
<li class="chapter" data-level="13.3" data-path="excursion-inspecting-the-underlying-stan-code.html"><a href="excursion-inspecting-the-underlying-stan-code.html"><i class="fa fa-check"></i><b>13.3</b> [Excursion:] Inspecting the underlying Stan code</a></li>
<li class="chapter" data-level="13.4" data-path="setting-priors.html"><a href="setting-priors.html"><i class="fa fa-check"></i><b>13.4</b> Setting priors</a></li>
<li class="chapter" data-level="13.5" data-path="posterior-predictions.html"><a href="posterior-predictions.html"><i class="fa fa-check"></i><b>13.5</b> Posterior predictions</a></li>
<li class="chapter" data-level="13.6" data-path="testing-hypotheses.html"><a href="testing-hypotheses.html"><i class="fa fa-check"></i><b>13.6</b> Testing hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap-04-03-predictors.html"><a href="Chap-04-03-predictors.html"><i class="fa fa-check"></i><b>14</b> Categorical predictors</a>
<ul>
<li class="chapter" data-level="14.1" data-path="Chap-04-03-predictors-two-levels.html"><a href="Chap-04-03-predictors-two-levels.html"><i class="fa fa-check"></i><b>14.1</b> Single two-level predictor</a></li>
<li class="chapter" data-level="14.2" data-path="Chap-04-03-predictors-multi-levels.html"><a href="Chap-04-03-predictors-multi-levels.html"><i class="fa fa-check"></i><b>14.2</b> Single multi-level predictor</a></li>
<li class="chapter" data-level="14.3" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html"><i class="fa fa-check"></i><b>14.3</b> Multiple predictors</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html#treatment-coding"><i class="fa fa-check"></i><b>14.3.1</b> Treatment coding</a></li>
<li class="chapter" data-level="14.3.2" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html#sum-coding"><i class="fa fa-check"></i><b>14.3.2</b> Sum coding</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="Chap-04-04-GLM.html"><a href="Chap-04-04-GLM.html"><i class="fa fa-check"></i><b>15</b> Generalized linear model</a>
<ul>
<li class="chapter" data-level="15.1" data-path="generalizing-the-linear-regression-model.html"><a href="generalizing-the-linear-regression-model.html"><i class="fa fa-check"></i><b>15.1</b> Generalizing the linear regression model</a></li>
<li class="chapter" data-level="15.2" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>15.2</b> Logistic regression</a></li>
</ul></li>
<li class="part"><span><b>V Frequentist statistics</b></span></li>
<li class="chapter" data-level="16" data-path="ch-05-01-frequentist-hypothesis-testing.html"><a href="ch-05-01-frequentist-hypothesis-testing.html"><i class="fa fa-check"></i><b>16</b> Null Hypothesis Significance Testing</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch-05-01-frequentist-testing-overview.html"><a href="ch-05-01-frequentist-testing-overview.html"><i class="fa fa-check"></i><b>16.1</b> Frequentist statistics: why &amp; how</a></li>
<li class="chapter" data-level="16.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html"><i class="fa fa-check"></i><b>16.2</b> Quantifying evidence against a null-model with <em>p</em>-values</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#frequentist-null-models"><i class="fa fa-check"></i><b>16.2.1</b> Frequentist null-models</a></li>
<li class="chapter" data-level="16.2.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#one--vs.-two-sided-p-values"><i class="fa fa-check"></i><b>16.2.2</b> One- vs. two-sided <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="16.2.3" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#significance-categorical-decisions"><i class="fa fa-check"></i><b>16.2.3</b> Significance &amp; categorical decisions</a></li>
<li class="chapter" data-level="16.2.4" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#how-not-to-interpret-p-values"><i class="fa fa-check"></i><b>16.2.4</b> How (not) to interpret <em>p</em>-values</a></li>
<li class="chapter" data-level="16.2.5" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#excursion-distribution-of-p-values"><i class="fa fa-check"></i><b>16.2.5</b> [Excursion] Distribution of <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html"><i class="fa fa-check"></i><b>16.3</b> [Excursion] Central Limit Theorem</a></li>
<li class="chapter" data-level="16.4" data-path="ch-03-04-hypothesis-significance-errors.html"><a href="ch-03-04-hypothesis-significance-errors.html"><i class="fa fa-check"></i><b>16.4</b> [Excursion] The Neyman-Pearson approach</a></li>
<li class="chapter" data-level="16.5" data-path="ch-05-01-frequentist-testing-confidence-intervals.html"><a href="ch-05-01-frequentist-testing-confidence-intervals.html"><i class="fa fa-check"></i><b>16.5</b> Confidence intervals</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="ch-05-01-frequentist-testing-confidence-intervals.html"><a href="ch-05-01-frequentist-testing-confidence-intervals.html#relation-of-p-values-to-confidence-intervals"><i class="fa fa-check"></i><b>16.5.1</b> Relation of <em>p</em>-values to confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html"><i class="fa fa-check"></i><b>16.6</b> Selected tests</a>
<ul>
<li class="chapter" data-level="16.6.1" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-Pearsons-Chi"><i class="fa fa-check"></i><b>16.6.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span>-tests</a></li>
<li class="chapter" data-level="16.6.2" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-z-test"><i class="fa fa-check"></i><b>16.6.2</b> <em>z</em>-test</a></li>
<li class="chapter" data-level="16.6.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-t-test"><i class="fa fa-check"></i><b>16.6.3</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="16.6.4" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-ANOVA"><i class="fa fa-check"></i><b>16.6.4</b> ANOVA</a></li>
<li class="chapter" data-level="16.6.5" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#linear-regression"><i class="fa fa-check"></i><b>16.6.5</b> Linear regression</a></li>
<li class="chapter" data-level="16.6.6" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#Chap-05-01-LR-test"><i class="fa fa-check"></i><b>16.6.6</b> Likelihood-Ratio Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch-05-02-comparison-freq-Bayes.html"><a href="ch-05-02-comparison-freq-Bayes.html"><i class="fa fa-check"></i><b>17</b> Comparing frequentist and Bayesian statistics</a>
<ul>
<li class="chapter" data-level="17.1" data-path="frequentist-and-bayesian-statistical-models.html"><a href="frequentist-and-bayesian-statistical-models.html"><i class="fa fa-check"></i><b>17.1</b> Frequentist and Bayesian statistical models</a></li>
<li class="chapter" data-level="17.2" data-path="approximation-in-the-model-or-through-the-computation.html"><a href="approximation-in-the-model-or-through-the-computation.html"><i class="fa fa-check"></i><b>17.2</b> Approximation: in the model or through the computation</a></li>
<li class="chapter" data-level="17.3" data-path="mc-simulated-p-values.html"><a href="mc-simulated-p-values.html"><i class="fa fa-check"></i><b>17.3</b> MC-simulated <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="17.4" data-path="bayesian-p-values-model-checking.html"><a href="bayesian-p-values-model-checking.html"><i class="fa fa-check"></i><b>17.4</b> Bayesian <span class="math inline">\(p\)</span>-values &amp; model checking</a></li>
<li class="chapter" data-level="17.5" data-path="ch-05-01-estimation-comparison.html"><a href="ch-05-01-estimation-comparison.html"><i class="fa fa-check"></i><b>17.5</b> Comparing Bayesian and frequentist estimates</a></li>
<li class="chapter" data-level="17.6" data-path="beliefs-decisions-and-long-term-error.html"><a href="beliefs-decisions-and-long-term-error.html"><i class="fa fa-check"></i><b>17.6</b> Beliefs, decisions and long-term error</a></li>
<li class="chapter" data-level="17.7" data-path="evidence-for-the-null.html"><a href="evidence-for-the-null.html"><i class="fa fa-check"></i><b>17.7</b> Evidence for the null</a></li>
<li class="chapter" data-level="17.8" data-path="Chap-05-02-models-three-pillars.html"><a href="Chap-05-02-models-three-pillars.html"><i class="fa fa-check"></i><b>17.8</b> Three pillars of data analysis</a></li>
<li class="chapter" data-level="17.9" data-path="testing-hypotheses-by-estimation-comparison-model-checking.html"><a href="testing-hypotheses-by-estimation-comparison-model-checking.html"><i class="fa fa-check"></i><b>17.9</b> Testing hypotheses by estimation, comparison &amp; model checking</a></li>
<li class="chapter" data-level="17.10" data-path="jeffreys-lindley-paradox.html"><a href="jeffreys-lindley-paradox.html"><i class="fa fa-check"></i><b>17.10</b> Jeffreys-Lindley paradox</a></li>
<li class="chapter" data-level="17.11" data-path="explicit-beliefs-vs.-implicit-intentions.html"><a href="explicit-beliefs-vs.-implicit-intentions.html"><i class="fa fa-check"></i><b>17.11</b> Explicit beliefs vs. implicit intentions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="app-90-further-material.html"><a href="app-90-further-material.html"><i class="fa fa-check"></i><b>A</b> Further useful material</a>
<ul>
<li class="chapter" data-level="A.1" data-path="material-on-introduction-to-probability.html"><a href="material-on-introduction-to-probability.html"><i class="fa fa-check"></i><b>A.1</b> Material on <em>Introduction to Probability</em>:</a></li>
<li class="chapter" data-level="A.2" data-path="material-on-bayesian-data-analysis.html"><a href="material-on-bayesian-data-analysis.html"><i class="fa fa-check"></i><b>A.2</b> Material on <em>Bayesian Data Analysis</em>:</a></li>
<li class="chapter" data-level="A.3" data-path="material-on-frequentist-statistics.html"><a href="material-on-frequentist-statistics.html"><i class="fa fa-check"></i><b>A.3</b> Material on <em>frequentist statistics</em>:</a></li>
<li class="chapter" data-level="A.4" data-path="material-on-r-tidyverse-etc..html"><a href="material-on-r-tidyverse-etc..html"><i class="fa fa-check"></i><b>A.4</b> Material on <em>R, tidyverse, etc.</em>:</a></li>
<li class="chapter" data-level="A.5" data-path="further-information-for-rstudio.html"><a href="further-information-for-rstudio.html"><i class="fa fa-check"></i><b>A.5</b> Further information for RStudio</a></li>
<li class="chapter" data-level="A.6" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html"><i class="fa fa-check"></i><b>A.6</b> Further information on WebPPL</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#primitives-and-sampling-functions"><i class="fa fa-check"></i><b>A.6.1</b> Primitives and sampling functions</a></li>
<li class="chapter" data-level="A.6.2" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#inference-with-infer"><i class="fa fa-check"></i><b>A.6.2</b> Inference with <code>Infer()</code></a></li>
<li class="chapter" data-level="A.6.3" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#visualization"><i class="fa fa-check"></i><b>A.6.3</b> Visualization</a></li>
<li class="chapter" data-level="A.6.4" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#installation"><i class="fa fa-check"></i><b>A.6.4</b> Installation</a></li>
<li class="chapter" data-level="A.6.5" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#usage"><i class="fa fa-check"></i><b>A.6.5</b> Usage</a></li>
<li class="chapter" data-level="A.6.6" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#keyboard-shortcuts-for-in-browser-use"><i class="fa fa-check"></i><b>A.6.6</b> Keyboard shortcuts (for in-browser use)</a></li>
<li class="chapter" data-level="A.6.7" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#further-resources"><i class="fa fa-check"></i><b>A.6.7</b> Further resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="app-91-distributions.html"><a href="app-91-distributions.html"><i class="fa fa-check"></i><b>B</b> Common probability distributions</a>
<ul>
<li class="chapter" data-level="B.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.1</b> Selected continuous distributions of random variables</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-normal"><i class="fa fa-check"></i><b>B.1.1</b> Normal distribution</a></li>
<li class="chapter" data-level="B.1.2" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-chi2"><i class="fa fa-check"></i><b>B.1.2</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="B.1.3" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-F"><i class="fa fa-check"></i><b>B.1.3</b> F-distribution</a></li>
<li class="chapter" data-level="B.1.4" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-students-t"><i class="fa fa-check"></i><b>B.1.4</b> Student’s <em>t</em>-distribution</a></li>
<li class="chapter" data-level="B.1.5" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-beta"><i class="fa fa-check"></i><b>B.1.5</b> Beta distribution</a></li>
<li class="chapter" data-level="B.1.6" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#uniform-distribution"><i class="fa fa-check"></i><b>B.1.6</b> Uniform distribution</a></li>
<li class="chapter" data-level="B.1.7" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-dirichlet"><i class="fa fa-check"></i><b>B.1.7</b> Dirichlet distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.2</b> Selected discrete distributions of random variables</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-binomial"><i class="fa fa-check"></i><b>B.2.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="B.2.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-multinomial"><i class="fa fa-check"></i><b>B.2.2</b> Multinomial distribution</a></li>
<li class="chapter" data-level="B.2.3" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-bernoulli"><i class="fa fa-check"></i><b>B.2.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="B.2.4" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-categorical"><i class="fa fa-check"></i><b>B.2.4</b> Categorical distribution</a></li>
<li class="chapter" data-level="B.2.5" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-beta-binomial"><i class="fa fa-check"></i><b>B.2.5</b> Beta-Binomial distribution</a></li>
<li class="chapter" data-level="B.2.6" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#poisson-distribution"><i class="fa fa-check"></i><b>B.2.6</b> Poisson distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="app-92-exponential-family.html"><a href="app-92-exponential-family.html"><i class="fa fa-check"></i><b>C</b> Exponential Family and Maximum Entropy</a>
<ul>
<li class="chapter" data-level="C.1" data-path="an-important-family-the-exponential-family.html"><a href="an-important-family-the-exponential-family.html"><i class="fa fa-check"></i><b>C.1</b> An important family: The Exponential Family</a></li>
<li class="chapter" data-level="C.2" data-path="the-maximum-entropy-principle.html"><a href="the-maximum-entropy-principle.html"><i class="fa fa-check"></i><b>C.2</b> The Maximum Entropy Principle</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="the-maximum-entropy-principle.html"><a href="the-maximum-entropy-principle.html#information-entropy"><i class="fa fa-check"></i><b>C.2.1</b> Information Entropy</a></li>
<li class="chapter" data-level="C.2.2" data-path="the-maximum-entropy-principle.html"><a href="the-maximum-entropy-principle.html#deriving-probability-distributions-using-the-maximum-entropy-principle"><i class="fa fa-check"></i><b>C.2.2</b> Deriving Probability Distributions using the Maximum Entropy Principle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="app-93-data-sets.html"><a href="app-93-data-sets.html"><i class="fa fa-check"></i><b>D</b> Data sets used in the book</a>
<ul>
<li class="chapter" data-level="D.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html"><i class="fa fa-check"></i><b>D.1</b> Mental Chronometry</a>
<ul>
<li class="chapter" data-level="D.1.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#nature-origin-and-rationale-of-the-data"><i class="fa fa-check"></i><b>D.1.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.1.2" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#loading-and-preprocessing-the-data"><i class="fa fa-check"></i><b>D.1.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.1.3" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#cleaning-the-data-1"><i class="fa fa-check"></i><b>D.1.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.1.4" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#exploration-summary-stats-plots"><i class="fa fa-check"></i><b>D.1.4</b> Exploration: summary stats &amp; plots</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html"><i class="fa fa-check"></i><b>D.2</b> Simon Task</a>
<ul>
<li class="chapter" data-level="D.2.1" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html#experiment"><i class="fa fa-check"></i><b>D.2.1</b> Experiment</a></li>
<li class="chapter" data-level="D.2.2" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html#hypotheses"><i class="fa fa-check"></i><b>D.2.2</b> Hypotheses</a></li>
<li class="chapter" data-level="D.2.3" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html#results"><i class="fa fa-check"></i><b>D.2.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html"><i class="fa fa-check"></i><b>D.3</b> King of France</a>
<ul>
<li class="chapter" data-level="D.3.1" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#app-93-data-sets-king-of-france-background"><i class="fa fa-check"></i><b>D.3.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.3.2" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#loading-and-preprocessing-the-data-1"><i class="fa fa-check"></i><b>D.3.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.3.3" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#cleaning-the-data-3"><i class="fa fa-check"></i><b>D.3.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.3.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#exploration-summary-stats-plots-1"><i class="fa fa-check"></i><b>D.3.4</b> Exploration: summary stats &amp; plots</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html"><i class="fa fa-check"></i><b>D.4</b> Bio-Logic Jazz-Metal (and where to consume it)</a>
<ul>
<li class="chapter" data-level="D.4.1" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#nature-origin-and-rationale-of-the-data-1"><i class="fa fa-check"></i><b>D.4.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.4.2" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#loading-and-preprocessing-the-data-2"><i class="fa fa-check"></i><b>D.4.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.4.3" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#exploration-counts-plots"><i class="fa fa-check"></i><b>D.4.3</b> Exploration: counts &amp; plots</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html"><i class="fa fa-check"></i><b>D.5</b> Avocado prices</a>
<ul>
<li class="chapter" data-level="D.5.1" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#nature-origin-and-rationale-of-the-data-2"><i class="fa fa-check"></i><b>D.5.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.5.2" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#loading-and-preprocessing-the-data-3"><i class="fa fa-check"></i><b>D.5.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.5.3" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#summary-statistics"><i class="fa fa-check"></i><b>D.5.3</b> Summary statistics</a></li>
<li class="chapter" data-level="D.5.4" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#plots"><i class="fa fa-check"></i><b>D.5.4</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="D.6" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html"><i class="fa fa-check"></i><b>D.6</b> Annual average world surface temperature</a>
<ul>
<li class="chapter" data-level="D.6.1" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#nature-origin-and-rationale-of-the-data-3"><i class="fa fa-check"></i><b>D.6.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.6.2" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#loading-and-preprocessing-the-data-4"><i class="fa fa-check"></i><b>D.6.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.6.3" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#hypothesis-modeling-approach"><i class="fa fa-check"></i><b>D.6.3</b> Hypothesis &amp; modeling approach</a></li>
<li class="chapter" data-level="D.6.4" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#plotting"><i class="fa fa-check"></i><b>D.6.4</b> Plotting</a></li>
</ul></li>
<li class="chapter" data-level="D.7" data-path="app-93-data-sets-murder-data.html"><a href="app-93-data-sets-murder-data.html"><i class="fa fa-check"></i><b>D.7</b> Murder data</a>
<ul>
<li class="chapter" data-level="D.7.1" data-path="app-93-data-sets-murder-data.html"><a href="app-93-data-sets-murder-data.html#nature-origin-and-rationale-of-the-data-4"><i class="fa fa-check"></i><b>D.7.1</b> Nature, origin and rationale of the data</a></li>
</ul></li>
<li class="chapter" data-level="D.8" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html"><i class="fa fa-check"></i><b>D.8</b> Politeness data</a>
<ul>
<li class="chapter" data-level="D.8.1" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#nature-origin-and-rationale-of-the-data-5"><i class="fa fa-check"></i><b>D.8.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.8.2" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#hypotheses-2"><i class="fa fa-check"></i><b>D.8.2</b> Hypotheses</a></li>
<li class="chapter" data-level="D.8.3" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#summary-statistics-1"><i class="fa fa-check"></i><b>D.8.3</b> Summary statistics</a></li>
<li class="chapter" data-level="D.8.4" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#visualization-1"><i class="fa fa-check"></i><b>D.8.4</b> Visualization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="app-94-open-science.html"><a href="app-94-open-science.html"><i class="fa fa-check"></i><b>E</b> Open science practices</a>
<ul>
<li class="chapter" data-level="E.1" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html"><i class="fa fa-check"></i><b>E.1</b> Psychology’s replication crisis</a>
<ul>
<li class="chapter" data-level="E.1.1" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html#publication-bias-qrps-and-false-positives"><i class="fa fa-check"></i><b>E.1.1</b> Publication bias, QRP’s, and false-positives</a></li>
<li class="chapter" data-level="E.1.2" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html#low-statistical-power"><i class="fa fa-check"></i><b>E.1.2</b> Low statistical power</a></li>
<li class="chapter" data-level="E.1.3" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html#lack-of-transparency"><i class="fa fa-check"></i><b>E.1.3</b> Lack of transparency</a></li>
</ul></li>
<li class="chapter" data-level="E.2" data-path="app-94-remedies.html"><a href="app-94-remedies.html"><i class="fa fa-check"></i><b>E.2</b> Possible remedies</a>
<ul>
<li class="chapter" data-level="E.2.1" data-path="app-94-remedies.html"><a href="app-94-remedies.html#improve-scientific-rigor"><i class="fa fa-check"></i><b>E.2.1</b> Improve scientific rigor</a></li>
<li class="chapter" data-level="E.2.2" data-path="app-94-remedies.html"><a href="app-94-remedies.html#realigning-incentive-structures"><i class="fa fa-check"></i><b>E.2.2</b> Realigning incentive structures</a></li>
<li class="chapter" data-level="E.2.3" data-path="app-94-remedies.html"><a href="app-94-remedies.html#promote-transparency"><i class="fa fa-check"></i><b>E.2.3</b> Promote transparency</a></li>
</ul></li>
<li class="chapter" data-level="E.3" data-path="app-94-recap.html"><a href="app-94-recap.html"><i class="fa fa-check"></i><b>E.3</b> Chapter summary</a></li>
<li class="chapter" data-level="E.4" data-path="app-94-resources.html"><a href="app-94-resources.html"><i class="fa fa-check"></i><b>E.4</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-03-05-Bayesian-testing-comparison" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Testing via model comparison<a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-05-Bayesian-testing-comparison" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Testing hypotheses based on parameter estimation, and in particular the categorical decision rules for accepting or rejecting hypotheses outlined in the previous section, only give a very coarse-grained picture.
Bayesian analysis is about providing quantitative information about uncertainty and evidence, which are intuitive and easily interpretable.
So, we would also like to have a quantitative assessment of the evidence for or against a hypothesis provided by some data against the background of a given model.
This is what the comparison-based approaches to Bayesian hypothesis testing give us.</p>
<p>Here is some further motivation why model comparison might be a good replacement for “testing via estimation”.
A statistical hypothesis <span class="math inline">\(H\)</span> is basically an event: a subset of parameter values are picked out of the whole parameter space.
After observing data <span class="math inline">\(D_\text{obs}\)</span> and based on model <span class="math inline">\(M\)</span>, the ideal measure to have is <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span>: given data and model, how likely is the hypothesis in question?
The problem with this posterior formulation <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is that, for it to be meaningful, it must quantify over the set of all alternative hypotheses.
If <span class="math inline">\(H\)</span> is a point-valued hypothesis over a single parameter, the set of all alternative hypotheses could comprise all other logically possible point-valued hypotheses for the same parameter.
But then, if that parameter is a continuous parameter, the posterior density at <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is not meaningfully interpretable as a probability (mass).
If <span class="math inline">\(H\)</span> is an interval-based hypothesis, the posterior <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> would be meaningfully interpretable as a probability (mass), but still the question of what exactly the space of alternatives is is left implicit.
Moreover, the posterior <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is influenced by the model’s prior over <span class="math inline">\(H\)</span>.
So, a nominally high value of <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is as such uninteresting because we would need to take the prior <span class="math inline">\(P_M(H)\)</span> into account as well.</p>
<p>This is why a comparison-based approach to Bayesian hypothesis testing explicitly compares two models:</p>
<ul>
<li><strong>The null model</strong> <span class="math inline">\(M_0\)</span> is the model that incorporates the assumption of the hypothesis <span class="math inline">\(H\)</span> to be tested. For example, the null model would put prior probability zero on those parameter values which are ruled out by <span class="math inline">\(H\)</span>.</li>
<li><strong>The alternative model</strong> <span class="math inline">\(M_1\)</span> is an explicitly formulated model which incorporates some contextually or technically useful alternative to <span class="math inline">\(M_0\)</span>.</li>
</ul>
<p>The comparison-based approach to hypothesis testing then quantifies, using Bayes factors, the evidence that <span class="math inline">\(D_\text{obs}\)</span> provides for or against <span class="math inline">\(M_0\)</span> (the model representing the “null hypothesis”) over the alternative model <span class="math inline">\(M_1\)</span> (the model representing the alternative hypothesis).
In this way, by looking at the ratio:</p>
<p><span class="math display">\[
BF_{01} = \frac{P(D_\text{obs} \mid M_0)}{P(D_\text{obs} \mid M_1)}
\]</span></p>
<p>this approach is independent of the prior probability assigned to models <span class="math inline">\(P(M_0)\)</span> and <span class="math inline">\(P(M_1)\)</span>.
Notice, however, that it is <em>not</em> independent of the priors over <span class="math inline">\(\theta\)</span> used in <span class="math inline">\(M_1\)</span>!</p>
<p>When the null hypothesis is point-valued, the alternative model is <em>not</em> based on the complement <span class="math inline">\(\theta \neq \theta^*\)</span>, but on the technically much more practical and also conceptually more plausible alternative model that assumes that <span class="math inline">\(\theta\)</span> is free to range over a larger interval including, but not limited to <span class="math inline">\(\theta^*\)</span>. We can then use the so-called Savage-Dickey method, described in Section <a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey">11.4.1</a>, to compare the null and the alternative models as so-called <em>nested models</em>.</p>
<p>When the null hypothesis is interval-valued, the alternative model can be conceived as based on the complement of the null hypothesis. We can then use an extension of the Savage-Dickey method based on a so-called encompassing model, described in Section <a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models">11.4.2</a>, where we construe both the null model and the alternative model as nested under a third, well, encompassing model.</p>
<p>This chapter shows how Bayes factors can be approximated based on samples from the posterior following both of these approaches.</p>
<div id="ch-03-07-hypothesis-testing-Bayes-Savage-Dickey" class="section level3 hasAnchor" number="11.4.1">
<h3><span class="header-section-number">11.4.1</span> The Savage-Dickey method<a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Savage-Dickey method is a very convenient way of computing Bayes factors for <em>nested models</em>, especially when models only differ with respect to one parameter.</p>
<p>Suppose that there are <span class="math inline">\(n\)</span> continuous parameters of interest <span class="math inline">\(\theta = \langle \theta_1, \dots, \theta_n \rangle\)</span>. <span class="math inline">\(M_1\)</span> is a (Bayesian) model defined by <span class="math inline">\(P(\theta \mid M_1)\)</span> and <span class="math inline">\(P(D \mid \theta, M_1)\)</span>. <span class="math inline">\(M_0\)</span> is <strong>properly nested</strong> under <span class="math inline">\(M_1\)</span> if:</p>
<ul>
<li><span class="math inline">\(M_0\)</span> assigns fixed values to parameters <span class="math inline">\(\theta_i = x_i, \dots, \theta_n = x_n\)</span></li>
<li><span class="math inline">\(P(D \mid \theta_1, \dots, \theta_{i-1}, M_0) = P(D \mid \theta_1, \dots, \theta_{i-1}, \theta_i = x_i, \dots, \theta_n = x_n, M_1)\)</span></li>
<li><span class="math inline">\(\lim_{\theta_i \rightarrow x_i, \dots, \theta_n \rightarrow x_n} P(\theta_1, \dots, \theta_{i-1} \mid \theta_i, \dots, \theta_n, M_1) = P(\theta_1, \dots, \theta_{i-1} \mid M_0)\)</span></li>
</ul>
<p>Intuitively put, <span class="math inline">\(M_0\)</span> is properly nested under <span class="math inline">\(M_1\)</span>, if <span class="math inline">\(M_0\)</span> is a special case of <span class="math inline">\(M_1\)</span> which fixes certain parameters to specific point-values.
Notice that the last condition is satisfied in particular when <span class="math inline">\(M_1\)</span>’s prior over <span class="math inline">\(\theta_1, \dots, \theta_{i-1}\)</span> is independent of the values for the remaining parameters.</p>
<p>We can express a point-valued hypothesis in terms of a model <span class="math inline">\(M_0\)</span> which is nested under the alternative model <span class="math inline">\(M_1\)</span>, the latter of which assumes that the parameters in question can take more than one value.
For such properly nested models, we can compute a Bayes factor efficiently using the following result.</p>
<div class="mathstuff">
<div class="theorem">
<p><span id="thm:unnamed-chunk-339" class="theorem"><strong>Theorem 11.1  (Savage-Dickey Bayes factors for nested models) </strong></span>Let <span class="math inline">\(M_0\)</span> be properly nested under <span class="math inline">\(M_1\)</span> s.t. <span class="math inline">\(M_0\)</span> fixes <span class="math inline">\(\theta_i = x_i, \dots, \theta_n = x_n\)</span>. The Bayes factor <span class="math inline">\(\text{BF}_{01}\)</span> in favor of <span class="math inline">\(M_0\)</span> over <span class="math inline">\(M_1\)</span> is then given by the ratio of posterior probability to prior probability of the parameters <span class="math inline">\(\theta_i = x_i, \dots, \theta_n = x_n\)</span> from the point of view of the nesting model <span class="math inline">\(M_1\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\text{BF}_{01} &amp; = \frac{P(\theta_i = x_i, \dots, \theta_n = x_n \mid D, M_1)}{P(\theta_i = x_i, \dots, \theta_n = x_n \mid M_1)}
\end{aligned}
\]</span></p>
</div>
<div class="collapsibleProof">
<button class="trigger">
Show proof.
</button>
<div class="content">
<div class="proof">
<p><span id="unlabeled-div-5" class="proof"><em>Proof</em>. </span>Let’s assume that <span class="math inline">\(M_0\)</span> has parameters <span class="math inline">\(\theta = \langle\phi, \psi\rangle\)</span> with <span class="math inline">\(\phi = \phi_0\)</span>, and that <span class="math inline">\(M_1\)</span> has parameters <span class="math inline">\(\theta = \langle\phi, \psi \rangle\)</span> with <span class="math inline">\(\phi\)</span> free to vary. If <span class="math inline">\(M_0\)</span> is properly nested under <span class="math inline">\(M_1\)</span>, we know that <span class="math inline">\(\lim_{\phi \rightarrow \phi_0} P(\psi \mid \phi, M_1) = P(\psi \mid M_0)\)</span>. We can then rewrite the marginal likelihood under <span class="math inline">\(M_0\)</span> as follows:</p>
<p><span class="math display">\[
\begin{aligned}
P(D \mid M_0) &amp; = \int P(D \mid \psi, M_0) P(\psi \mid M_0) \ \text{d}\psi
&amp; \text{[marginalization]}
\\
&amp; = \int P(D \mid \psi, \phi = \phi_0, M_1) P(\psi \mid \phi = \phi_0, M_1)  \ \text{d}\psi
&amp; \text{[assumption of nesting]}
\\
&amp; = P(D \mid \phi = \phi_0, M_1)
&amp; \text{[marginalization]}
\\
&amp; = \frac{P(\phi = \phi_0 \mid D, M_1) P(D \mid M_1)}{P(\phi = \phi_0 \mid M_1)}
&amp; \text{[Bayes rule]}
\end{aligned}
\]</span></p>
<p>The result follows if we divide by <span class="math inline">\(P(D \mid M_1)\)</span> on both sides of the equation.</p>
</div>
<p> </p>
</div>
</div>
</div>
<div id="example-247-1" class="section level4 hasAnchor" number="11.4.1.1">
<h4><span class="header-section-number">11.4.1.1</span> Example: 24/7<a href="ch-03-05-Bayesian-testing-comparison.html#example-247-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Here is an example based on the 24/7 data. For a nesting model with a flat prior (<span class="math inline">\(\theta \sim^{M_1} \text{Beta}(1,1)\)</span>), and a point hypothesis <span class="math inline">\(\theta_c = 0.5\)</span>, we just have to calculate the prior and posterior probability of the critical value <span class="math inline">\(\theta_c = 0.5\)</span>:</p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-1" aria-hidden="true" tabindex="-1"></a><span class="co"># point-value of interest</span></span>
<span id="cb512-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-2" aria-hidden="true" tabindex="-1"></a>theta_star <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb512-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-3" aria-hidden="true" tabindex="-1"></a><span class="co"># posterior probability in nesting model</span></span>
<span id="cb512-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-4" aria-hidden="true" tabindex="-1"></a>posterior_theta_star <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta_star, <span class="dv">8</span>, <span class="dv">18</span>)</span>
<span id="cb512-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-5" aria-hidden="true" tabindex="-1"></a><span class="co"># prior probability in nesting model</span></span>
<span id="cb512-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-6" aria-hidden="true" tabindex="-1"></a>prior_theta_star <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta_star, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb512-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayes factor (using Savage-Dickey)</span></span>
<span id="cb512-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-8" aria-hidden="true" tabindex="-1"></a>BF_01 <span class="ot">&lt;-</span> posterior_theta_star <span class="sc">/</span> prior_theta_star</span>
<span id="cb512-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb512-9" aria-hidden="true" tabindex="-1"></a>BF_01</span></code></pre></div>
<pre><code>## [1] 0.5157351</code></pre>
<p>This is very minor evidence in favor of the alternative model (Bayes factor <span class="math inline">\(\text{BF}_{10} \approx 1.94\)</span>). We would not like to draw any (strong) categorical conclusions from this result regarding the question of whether the coin might be fair. Figure <a href="ch-03-05-Bayesian-testing-comparison.html#fig:ch-03-07-hypothesis-testing-Bayes-SD-24-7">11.6</a> also shows the relation between prior and posterior at the point-value of interest.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch-03-07-hypothesis-testing-Bayes-SD-24-7"></span>
<img src="I2DA_files/figure-html/ch-03-07-hypothesis-testing-Bayes-SD-24-7-1.png" alt="Illustration of the Savage-Dickey method of Bayes factor computation for the 24/7 case." width="672" />
<p class="caption">
Figure 11.6: Illustration of the Savage-Dickey method of Bayes factor computation for the 24/7 case.
</p>
</div>
</div>
<div id="example-simon-task-1" class="section level4 hasAnchor" number="11.4.1.2">
<h4><span class="header-section-number">11.4.1.2</span> Example: Simon task<a href="ch-03-05-Bayesian-testing-comparison.html#example-simon-task-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In the previous 24/7 example, using the Savage-Dickey method was particularly easy because we know a closed-form solution of the precise posterior, so that we could easily calculate the posterior for the critical value without further ado.
When this is not the case, like in the application to the Simon task data, we have to obtain an estimate for the posterior density at the critical value, here: <span class="math inline">\(\delta = 0\)</span>, from the posterior samples which we obtain from sampling, as we did earlier in this chapter (using Stan).
An approximate method for obtaining this value is implemented in the <code>polspline</code> package (using polynomial splines to approximate the posterior curve).</p>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the samples for the delta parameter</span></span>
<span id="cb514-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-2" aria-hidden="true" tabindex="-1"></a><span class="co">#   from the earlier Stan fit</span></span>
<span id="cb514-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-3" aria-hidden="true" tabindex="-1"></a>delta_samples <span class="ot">&lt;-</span> tidy_draws_tt2 <span class="sc">%&gt;%</span> </span>
<span id="cb514-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Parameter <span class="sc">==</span> <span class="st">&quot;delta&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb514-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(value)</span>
<span id="cb514-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-7" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating the posterior density at delta = 0 with polynomial splines</span></span>
<span id="cb514-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-8" aria-hidden="true" tabindex="-1"></a>fit.posterior <span class="ot">&lt;-</span> polspline<span class="sc">::</span><span class="fu">logspline</span>(delta_samples)</span>
<span id="cb514-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-9" aria-hidden="true" tabindex="-1"></a>posterior_delta_null <span class="ot">&lt;-</span> polspline<span class="sc">::</span><span class="fu">dlogspline</span>(<span class="dv">0</span>, fit.posterior)</span>
<span id="cb514-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-11" aria-hidden="true" tabindex="-1"></a><span class="co"># computing the prior density of the point-value of interest</span></span>
<span id="cb514-12"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-12" aria-hidden="true" tabindex="-1"></a><span class="co">#   [NB: the prior on delta was a standard normal]</span></span>
<span id="cb514-13"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-13" aria-hidden="true" tabindex="-1"></a>prior_delta_null <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>) </span>
<span id="cb514-14"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-15"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-15" aria-hidden="true" tabindex="-1"></a><span class="co"># compute BF via Savage-Dickey</span></span>
<span id="cb514-16"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-16" aria-hidden="true" tabindex="-1"></a>BF_delta_null <span class="ot">=</span> posterior_delta_null <span class="sc">/</span> prior_delta_null</span>
<span id="cb514-17"><a href="ch-03-05-Bayesian-testing-comparison.html#cb514-17" aria-hidden="true" tabindex="-1"></a>BF_delta_null</span></code></pre></div>
<pre><code>## [1] 2.148062e-14</code></pre>
<p>We conclude from this result that the data provide extremely strong evidence against the null model, which assumes that <span class="math inline">\(\delta = 0\)</span>, when compared to an alternative model <span class="math inline">\(M_1\)</span>, which assumes that <span class="math inline">\(\delta \sim \mathcal{N}(0,1)\)</span> in the prior.</p>
<!-- exercise 2 -->
<!-- Taken from the prep exam (IDA-prep-exam-02.pages.pdf) -->
<div class="exercises">
<p><strong>Exercise 11.3: Bayes factors with the Savage-Dickey method</strong></p>
<p>Look at the plot below. You see the prior distribution and the posterior distribution over the <span class="math inline">\(\delta\)</span> parameter in a Bayesian <span class="math inline">\(t\)</span>-test model. We are going to use this plot to determine (roughly) the Bayes factor of two models: the full Bayesian <span class="math inline">\(t\)</span>-test model, and a model nested under this full model which assumes that <span class="math inline">\(\delta = 0\)</span>.</p>
<p><img src="I2DA_files/figure-html/unnamed-chunk-343-1.png" width="384" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: lower-alpha">
<li>Describe in intuitive terms what it means for a Bayesian model to be nested under another model. It is sufficient to neglect the conditions on the priors.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>A model nested under another model fixes certain parameters to specific values which may take on more than one value in the nesting model.</p>
</div>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Write down the formula for the Bayes factor in favor of the null model (where <span class="math inline">\(\delta = 0\)</span>) over the full model using the Savage-Dickey theorem.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p><span class="math inline">\(BF_{01}=\frac{P(\delta = 0 \mid D, M_1)}{P(\delta = 0 \mid M_1)}\)</span>.</p>
</div>
</div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Give a natural language paraphrase of the formula you wrote down above.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>The Bayes factor in favor of the embedded null model over the embedding model is given by the posterior density at <span class="math inline">\(\delta = 0\)</span> under the nesting model divided by the prior in the nesting model at <span class="math inline">\(\delta = 0\)</span>.</p>
</div>
</div>
<ol start="4" style="list-style-type: lower-alpha">
<li>Now look at the plot above. Give your approximate guess of the Bayes factor in favor of the null model in terms of a fraction of whole integers (something like: <span class="math inline">\(\frac{4}{3}\)</span> or <span class="math inline">\(\frac{27}{120}\)</span>, …).</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p><img src="I2DA_files/figure-html/unnamed-chunk-344-1.png" width="384" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(BF_{01} \approx \frac{5}{2}\)</span> (see plot above).</p>
</div>
</div>
<ol start="5" style="list-style-type: lower-alpha">
<li>Formulate a conclusion to be drawn from this numerical result about the research hypothesis that the mean of the two groups compared here is identical. Write one concise sentence like you would in a research paper.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>A BF of <span class="math inline">\(\frac{5}{2}\)</span> is mild evidence in favor of the null model, but conventionally not considered strong enough to be particularly noteworthy.</p>
</div>
</div>
</div>
</div>
<div id="excursion-calculating-the-bayes-factor-precisely" class="section level4 hasAnchor" number="11.4.1.3">
<h4><span class="header-section-number">11.4.1.3</span> [Excursion:] Calculating the Bayes factor precisely<a href="ch-03-05-Bayesian-testing-comparison.html#excursion-calculating-the-bayes-factor-precisely" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span style="color:firebrick">under construction</span></p>
<!-- Since this last numerical result relies on some computational approximation (namely in the estimation of the posterior density at $\delta = 0$ using polynomial splines approximation), we can also make use of the fact that the $t$-test model we used here allows for a direct mathematical computation of the Bayes factor. -->
</div>
</div>
<div id="ch-03-07-hypothesis-testing-Bayes-encompassing-models" class="section level3 hasAnchor" number="11.4.2">
<h3><span class="header-section-number">11.4.2</span> Encompassing models<a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Savage-Dickey method can be generalized to also cover interval-valued hypotheses.
The previous literature has focused on inequality-based intervals/hypotheses (like <span class="math inline">\(\theta \ge 0.5\)</span>) <span class="citation">(<a href="#ref-KlugkistKato2005:Bayesian-model" role="doc-biblioref">Klugkist, Kato, and Hoijtink 2005</a>; <a href="#ref-WetzelsGrasman2010:An-encompassing" role="doc-biblioref">Wetzels, Grasman, and Wagenmakers 2010</a>; <a href="#ref-Oh2014:Bayesian-compar" role="doc-biblioref">Oh 2014</a>)</span>, but the method also applies to ROPE-d hypotheses.
The advantage of this method is that we can use samples from the posterior distribution to approximate integrals, which is more robust than having to estimate point-values of posterior density.</p>
<p>Following previous work <span class="citation">(<a href="#ref-KlugkistKato2005:Bayesian-model" role="doc-biblioref">Klugkist, Kato, and Hoijtink 2005</a>; <a href="#ref-WetzelsGrasman2010:An-encompassing" role="doc-biblioref">Wetzels, Grasman, and Wagenmakers 2010</a>; <a href="#ref-Oh2014:Bayesian-compar" role="doc-biblioref">Oh 2014</a>)</span>, the main idea is to use so-called <strong>encompassing priors</strong>. Let <span class="math inline">\(\theta\)</span> be a single parameter of interest (for simplicity<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a>), which can in principle take on any real value. We are interested in the interval-based hypotheses:</p>
<ul>
<li><span class="math inline">\(H_0 \colon \theta \in I_0\)</span>, and</li>
<li><span class="math inline">\(H_1 \colon \theta \in I_{1}\)</span></li>
</ul>
<p>where <span class="math inline">\(I_{0}\)</span> is an interval, possibly half-open and <span class="math inline">\(I_1\)</span> is the “negation” of <span class="math inline">\(I_0\)</span> (in the sense that <span class="math inline">\(I_1 = \left \{ \theta \mid \theta \not \in I_0 \right \}\)</span>.</p>
<p>An <strong>encompassing model</strong> <span class="math inline">\(M_e\)</span> has a suitable likelihood function <span class="math inline">\(P(D \mid \theta, \omega, M_{e})\)</span> (where <span class="math inline">\(\omega\)</span> is a vector of other parameters besides the parameter <span class="math inline">\(\theta\)</span> of interest, so-called “nuisance parameters”).
It also defines a prior <span class="math inline">\(P(\theta, \omega \mid M_{e})\)</span>, which does not already rule out <span class="math inline">\(H_{0}\)</span> or <span class="math inline">\(H_{1}\)</span>.</p>
<p>Generalizing over the Savage-Dickey approach, we construct <em>two</em> models, one for each hypothesis, <em>both</em> of which are nested under the encompassing model:</p>
<ul>
<li><span class="math inline">\(M_0\)</span> has prior <span class="math inline">\(P(\theta, \omega \mid M_0) = P(\theta, \omega \mid \theta \in I_0, M_e)\)</span></li>
<li><span class="math inline">\(M_1\)</span> has prior <span class="math inline">\(P(\theta, \omega \mid M_1) = P(\theta, \omega \mid \theta \in I_1, M_e)\)</span></li>
</ul>
<p>We assume that the priors over <span class="math inline">\(\theta\)</span> are independent of the nuisance parameters <span class="math inline">\(\omega\)</span>.
Both <span class="math inline">\(M_0\)</span> and <span class="math inline">\(M_1\)</span> have the same likelihood function as <span class="math inline">\(M_e\)</span>.</p>
<p>Figure <a href="ch-03-05-Bayesian-testing-comparison.html#fig:ch-03-07-hypothesis-testing-Bayes-encompassing-prior">11.7</a> shows an example of the priors of an encompassing model for two nested models based on a ROPE-d hypothesis testing approach.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch-03-07-hypothesis-testing-Bayes-encompassing-prior"></span>
<img src="I2DA_files/figure-html/ch-03-07-hypothesis-testing-Bayes-encompassing-prior-1.png" alt="Example of the prior of an encompassing model and the priors of two models nested under it." width="672" />
<p class="caption">
Figure 11.7: Example of the prior of an encompassing model and the priors of two models nested under it.
</p>
</div>
<p>If our hypothesis of interest is <span class="math inline">\(I_0\)</span>, which is captured in <span class="math inline">\(M_0\)</span>, there are two comparisons we can make to quantify evidence in favor of or against <span class="math inline">\(M_0\)</span>: we can compare <span class="math inline">\(M_{0}\)</span> against the encompassing model <span class="math inline">\(M_{e}\)</span>, or against its “negation” <span class="math inline">\(M_{1}\)</span>.
Bayes Factors for both comparisons can be easily expressed with the encompassing-models approach, as shown in Theorems <a href="ch-03-05-Bayesian-testing-comparison.html#thm:encompassing-BG-against-encompassing">11.2</a> and <a href="ch-03-05-Bayesian-testing-comparison.html#thm:encompassing-BG-against-alternative">11.3</a>.
Essentially, we can express Bayes Factors in terms of statements regarding the prior or posterior propability of <span class="math inline">\(I_0\)</span> and <span class="math inline">\(I_1\)</span> from the point of view of the encompassing model alone.
This means that we can approximate these Bayes Factors by just setting up one model, the encompassing model, and retrieving prior and posterior samples for it.</p>
<p>Concretely, Theorem <a href="ch-03-05-Bayesian-testing-comparison.html#thm:encompassing-BG-against-encompassing">11.2</a> states that the Bayes Factor in favor of <span class="math inline">\(M_i\)</span>, when compared against the encompassing model <span class="math inline">\(M_e\)</span> is the ratio of the posterior probability of <span class="math inline">\(\theta\)</span> being in <span class="math inline">\(I_i\)</span> divided by the prior probability, both from the perspective of <span class="math inline">\(M_e\)</span>.</p>
<div class="mathstuff">
<div class="theorem">
<p><span id="thm:encompassing-BG-against-encompassing" class="theorem"><strong>Theorem 11.2  </strong></span>The Bayes Factor in favor of nested model <span class="math inline">\(M_{i}\)</span> over encompassing model <span class="math inline">\(M_{e}\)</span> is:
<span class="math display">\[\begin{align*}
    \mathrm{BF}_{ie} = \frac{P(\theta \in I_{i} \mid D, M_{e})}{P(\theta \in I_{i} \mid M_{e})}
  \end{align*}\]</span></p>
</div>
<div class="collapsibleProof">
<button class="trigger">
Show proof.
</button>
<div class="content">
<div class="proof">
<p><span id="unlabeled-div-6" class="proof"><em>Proof</em>. </span>The following is only a sketch of a proof.
Important doemal details are glossed over.
For more detail, see <span class="citation">(<a href="#ref-KlugkistHoijtink2007:The-Bayes-facto" role="doc-biblioref">Klugkist and Hoijtink 2007</a>)</span>.</p>
<p>We start by making three observations which hold for any model <span class="math inline">\(M_{i}\)</span>, <span class="math inline">\(i \in \left \{ 0,1 \right \}\)</span>, and any pair of vectors of parameter values <span class="math inline">\(\theta\prime, \omega\prime\)</span> such that <span class="math inline">\(P(\theta\prime, \omega\prime \mid D, M_{i}) \neq 0\)</span> (which entails that <span class="math inline">\(\theta\prime \in I_{I}\)</span>, <span class="math inline">\(P(\theta\prime, \omega\prime \mid M_{i}) &gt; 0\)</span> and <span class="math inline">\(P(D \mid \theta\prime, \omega\prime, M_{i}) &gt; 0\)</span>):</p>
<ul>
<li><p><strong>Observation 1:</strong> The definition of the posterior:
<span class="math display">\[\begin{align*}
    P(\theta\prime, \omega\prime \mid D, M_{i}) = \frac{P(D \mid \theta\prime, \omega\prime, M_{i}) \ P(\theta\prime, \omega\prime \mid M_{i})}{P(D \mid M_{i})}
  \end{align*}\]</span>
can be rewritten as:
<span class="math display">\[\begin{align*}
     P(D \mid M_{i}) = \frac{P(D \mid \theta\prime, \omega\prime, M_{i}) \ P(\theta\prime, \omega\prime \mid M_{i})}{P(\theta\prime, \omega\prime \mid D, M_{i})}
  \end{align*}\]</span>
This also holds for model <span class="math inline">\(M_{e}\)</span>.</p></li>
<li><p><strong>Observation 2:</strong> The prior for <span class="math inline">\(\theta\prime, \omega\prime\)</span> in <span class="math inline">\(M_{i}\)</span> can be expressed in terms of the priors in <span class="math inline">\(M_{e}\)</span> as:
<span class="math display">\[\begin{align*}
    P(\theta\prime, \omega\prime \mid M_{i}) = \frac{P(\theta\prime, \omega\prime \mid M_{e})}{P(\theta \in I_{i} \mid M_{e})}
  \end{align*}\]</span></p></li>
<li><p><strong>Observation 3:</strong> The posterior for <span class="math inline">\(\theta\prime, \omega\prime\)</span> in <span class="math inline">\(M_{i}\)</span> can be expressed in terms of the posteriors in <span class="math inline">\(M_{e}\)</span> as:
<span class="math display">\[\begin{align*}
    P(\theta\prime, \omega\prime \mid D, M_{i}) = \frac{P(\theta\prime, \omega\prime \mid D, M_{e})}{P(\theta \in I_{i} \mid D, M_{e})}
  \end{align*}\]</span></p></li>
</ul>
<p>With these observations in place, we can rewrite the Bayes Factor <span class="math inline">\(\mathrm{BF}_{ie}\)</span> in terms of a pair of vectors of parameter values <span class="math inline">\(\theta\prime, \omega\prime\)</span> (for which <span class="math inline">\(P(\theta\prime, \omega\prime \mid D, M_{i}) \neq 0\)</span>) as:
<span class="math display">\[\begin{align*}
    \mathrm{BF}_{ie}
    &amp; = \frac{P(D \mid M_{i})}{P(D \mid M_{e})}
    \\
    &amp; = \frac{P(D \mid \theta\prime, \omega\prime, M_{i}) \ P(\theta\prime, \omega\prime \mid M_{i})\ / \ P(\theta\prime, \omega\prime \mid D, M_{i})}
      {P(D \mid \theta\prime, \omega\prime, M_{e}) \ P(\theta\prime, \omega\prime \mid M_{e})\ / \ P(\theta\prime, \omega\prime \mid D, M_{e})}
    &amp; \textcolor{gray}{[\text{by Obs.~1}]}
    \\
    &amp; = \frac{ P(\theta\prime, \omega\prime \mid M_{i})\ / \ P(\theta\prime, \omega\prime \mid D, M_{i}))}
      { P(\theta\prime, \omega\prime \mid M_{e})\ / \ P(\theta\prime, \omega\prime \mid D, M_{e})}
    &amp; \textcolor{gray}{[\text{by def.~(identity of LH)}]}
    \\
    &amp; = \frac{P(\theta \in I_{i} \mid D, M_{e})}{P(\theta \in I_{i} \mid M_{e})}
    &amp; \textcolor{gray}{[\text{by Obs.~1 \&amp; 2}]}
  \end{align*}\]</span></p>
</div>
<p> </p>
</div>
</div>
</div>
<p>Theorem <a href="ch-03-05-Bayesian-testing-comparison.html#thm:encompassing-BG-against-encompassing">11.2</a> states that the Bayes Factor in favor of <span class="math inline">\(M_0\)</span>, when compared against the alternative “negated” model <span class="math inline">\(M_1\)</span> is the ratio of the posterior <em>odds</em> of <span class="math inline">\(\theta\)</span> being in <span class="math inline">\(I_0\)</span> divided by the prior <em>odds</em>, both from the perspective of <span class="math inline">\(M_e\)</span>.</p>
<div class="mathstuff">
<div class="theorem">
<p><span id="thm:encompassing-BG-against-alternative" class="theorem"><strong>Theorem 11.3  </strong></span>The Bayes Factor in favor of model <span class="math inline">\(M_{0}\)</span> over alternative model <span class="math inline">\(M_{1}\)</span> is:
<span class="math display">\[\begin{align*}
    \mathrm{BF}_{01} = \frac{P(\theta \in I_{0} \mid D, M_{e})}{P(\theta \in I_{1} \mid D, M_{e})} \ \frac{P(\theta \in I_{1} \mid  M_{e})}{P(\theta \in I_{0} \mid M_{e})}
\end{align*}\]</span></p>
</div>
<div class="collapsibleProof">
<button class="trigger">
Show proof.
</button>
<div class="content">
<div class="proof">
<p><span id="unlabeled-div-7" class="proof"><em>Proof</em>. </span>This result follows as a direct corollary from Theorem <a href="ch-03-05-Bayesian-testing-comparison.html#thm:encompassing-BG-against-encompassing">11.2</a> and Proposition <a href="Chap-03-06-model-comparison-BF.html#prp:transitivity-BF">10.1</a>.</p>
</div>
<p> </p>
</div>
</div>
</div>
<p>Which comparison should be used for quantifying evidence in favor of or against <span class="math inline">\(M_0\)</span>: the encompassing model <span class="math inline">\(M_e\)</span> or the alternative, “negation” model <span class="math inline">\(M_1\)</span>?
There are good reasons for taking <span class="math inline">\(M_1\)</span>.
Here is why.</p>
<p>Suppose we hypothesize that a coin is biased towards heads, i.e., we consider the interval-valued hypothesis of interest <span class="math inline">\(H_0\)</span> that <span class="math inline">\(\theta &gt; 0.5\)</span>, where <span class="math inline">\(\theta\)</span> is the parameter of a Binomial likelihood function.
Suppose we see <span class="math inline">\(k = 100\)</span> from <span class="math inline">\(N=100\)</span> tosses landing heads.
That is, intuitively, extremely strong evidence in favor of our hypothesis.
But if, as may be prudent, the encompassing model is neutral between our hypothesis and its negation, so that <span class="math inline">\(P(\theta &gt; 0.5 \mid M_{e}) = 0.5\)</span>, the biggest Bayes Factor that we could possibly attain in favor of <span class="math inline">\(\theta &gt; 0,5\)</span> over the encompassing model, no matter what data we observe, is 2.
This is because, by Theorem <a href="ch-03-05-Bayesian-testing-comparison.html#thm:encompassing-BG-against-encompassing">11.2</a>, the numerator can at most be 1 and the denominator is fixed, by assumption, to be 0.5.
That does not seem like an intuitive way of quantifying the evidence in favor of <span class="math inline">\(\theta &gt; 0.5\)</span> when observing <span class="math inline">\(k=100\)</span> out of <span class="math inline">\(N=100\)</span>, which seem quite overwhelming.
Instead, by Theorem <a href="ch-03-05-Bayesian-testing-comparison.html#thm:encompassing-BG-against-alternative">11.3</a>, the Bayes Factor for a comparison of <span class="math inline">\(\theta &gt; 0.5\)</span> against <span class="math inline">\(\theta \le 0.5\)</span> is virtually infinite, reflecting the intuition that this data set provides overwhelming support for the idea that <span class="math inline">\(\theta &gt; 0.5\)</span>.
Based on considerations like these, it seems that the more intuitive comparison is against the negation of an interval-valued hypothesis, not against the encompassing model.</p>
<div id="example-247-2" class="section level4 hasAnchor" number="11.4.2.1">
<h4><span class="header-section-number">11.4.2.1</span> Example: 24/7<a href="ch-03-05-Bayesian-testing-comparison.html#example-247-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Bayes factor using the ROPE-d method to compute the interval-valued hypothesis <span class="math inline">\(\theta = 0.5 \pm \epsilon\)</span> is:</p>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set the scene</span></span>
<span id="cb516-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-2" aria-hidden="true" tabindex="-1"></a>theta_null <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb516-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-3" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fl">0.01</span>                 <span class="co"># epsilon margin for ROPE</span></span>
<span id="cb516-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-4" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> theta_null <span class="sc">+</span> epsilon   <span class="co"># upper bound of ROPE</span></span>
<span id="cb516-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-5" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> theta_null <span class="sc">-</span> epsilon   <span class="co"># lower bound of ROPE</span></span>
<span id="cb516-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-6" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb516-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-7" aria-hidden="true" tabindex="-1"></a>prior_of_hypothesis <span class="ot">&lt;-</span> <span class="fu">pbeta</span>(upper, <span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">-</span> <span class="fu">pbeta</span>(lower, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb516-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-8" aria-hidden="true" tabindex="-1"></a>prior_odds <span class="ot">&lt;-</span> prior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> prior_of_hypothesis)</span>
<span id="cb516-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-9" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb516-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-10" aria-hidden="true" tabindex="-1"></a>posterior_of_hypothesis <span class="ot">&lt;-</span> <span class="fu">pbeta</span>(upper, <span class="dv">8</span>, <span class="dv">18</span>) <span class="sc">-</span> <span class="fu">pbeta</span>(lower, <span class="dv">8</span>, <span class="dv">18</span>)</span>
<span id="cb516-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-11" aria-hidden="true" tabindex="-1"></a>posterior_odds <span class="ot">&lt;-</span> posterior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> posterior_of_hypothesis)</span>
<span id="cb516-12"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-12" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb516-13"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-13" aria-hidden="true" tabindex="-1"></a>bf_ROPEd_hypothesis <span class="ot">&lt;-</span> posterior_odds <span class="sc">/</span> prior_odds</span>
<span id="cb516-14"><a href="ch-03-05-Bayesian-testing-comparison.html#cb516-14" aria-hidden="true" tabindex="-1"></a>bf_ROPEd_hypothesis</span></code></pre></div>
<pre><code>## [1] 0.5133012</code></pre>
<p>This is unnoteworthy evidence in favor of the alternative hypothesis (Bayes factor <span class="math inline">\(\text{BF}_{10} \approx 1.95\)</span>).
Notice that the reason why the alternative hypothesis does not fare better in this analysis is because it also includes a lot of parameter values (<span class="math inline">\(\theta &gt; 0.5\)</span>) which explain the observed data even more poorly than the values included in the null hypothesis.</p>
<p>We can also use this approach to test the directional hypothesis that <span class="math inline">\(\theta &lt; 0.5\)</span>.</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb518-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-2" aria-hidden="true" tabindex="-1"></a><span class="co">#   [trivial in the case at hand, but just to be explicit]</span></span>
<span id="cb518-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-3" aria-hidden="true" tabindex="-1"></a>prior_of_hypothesis <span class="ot">&lt;-</span> <span class="fu">pbeta</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">1</span>) </span>
<span id="cb518-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-4" aria-hidden="true" tabindex="-1"></a>prior_odds <span class="ot">&lt;-</span> prior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> prior_of_hypothesis)</span>
<span id="cb518-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb518-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-6" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb518-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-7" aria-hidden="true" tabindex="-1"></a>posterior_of_hypothesis <span class="ot">&lt;-</span> <span class="fu">pbeta</span>(<span class="fl">0.5</span>, <span class="dv">8</span>, <span class="dv">18</span>)</span>
<span id="cb518-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-8" aria-hidden="true" tabindex="-1"></a>posterior_odds <span class="ot">&lt;-</span> posterior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> posterior_of_hypothesis)</span>
<span id="cb518-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-9" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb518-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-10" aria-hidden="true" tabindex="-1"></a>bf_directional_hypothesis <span class="ot">&lt;-</span> posterior_odds <span class="sc">/</span> prior_odds</span>
<span id="cb518-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-11" aria-hidden="true" tabindex="-1"></a>bf_directional_hypothesis</span></code></pre></div>
<pre><code>## [1] 45.20512</code></pre>
<p>Here we should conclude that the data provide substantial evidence in favor of the assumption that the coin is biased towards tails, when compared against the alternative assumption that it is biased towards heads.
If the dichotomy is “heads bias vs tails bias” the data clearly tilts our beliefs towards the “tails bias” possibility.</p>
</div>
<div id="example-simon-task-2" class="section level4 hasAnchor" number="11.4.2.2">
<h4><span class="header-section-number">11.4.2.2</span> Example: Simon task<a href="ch-03-05-Bayesian-testing-comparison.html#example-simon-task-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Using posterior samples, we can also do similar calculations for the Simon task.
Let’s first approximate the Bayes factor in favor of the ROPE-d hypothesis <span class="math inline">\(\delta = 0 \pm 0.1\)</span> when compared against the alternative hypothesis <span class="math inline">\(\delta \not \in 0 \pm 0.1\)</span>.</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-1" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating the BF for ROPE-d hypothesis with encompassing priors</span></span>
<span id="cb520-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-2" aria-hidden="true" tabindex="-1"></a>delta_null <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb520-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-3" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fl">0.1</span>                  <span class="co"># epsilon margin for ROPE</span></span>
<span id="cb520-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-4" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> delta_null <span class="sc">+</span> epsilon   <span class="co"># upper bound of ROPE</span></span>
<span id="cb520-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-5" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> delta_null <span class="sc">-</span> epsilon   <span class="co"># lower bound of ROPE</span></span>
<span id="cb520-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-6" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb520-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-7" aria-hidden="true" tabindex="-1"></a>prior_of_hypothesis <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(upper, <span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(lower, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb520-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-8" aria-hidden="true" tabindex="-1"></a>prior_odds <span class="ot">&lt;-</span> prior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> prior_of_hypothesis)</span>
<span id="cb520-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-9" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb520-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-10" aria-hidden="true" tabindex="-1"></a>posterior_of_hypothesis <span class="ot">&lt;-</span> <span class="fu">mean</span>( lower <span class="sc">&lt;=</span> delta_samples <span class="sc">&amp;</span> delta_samples <span class="sc">&lt;=</span> upper )</span>
<span id="cb520-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-11" aria-hidden="true" tabindex="-1"></a>posterior_odds <span class="ot">&lt;-</span> posterior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> posterior_of_hypothesis)</span>
<span id="cb520-12"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-12" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb520-13"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-13" aria-hidden="true" tabindex="-1"></a>bf_ROPEd_hypothesis <span class="ot">&lt;-</span> posterior_odds <span class="sc">/</span> prior_odds</span>
<span id="cb520-14"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-14" aria-hidden="true" tabindex="-1"></a>bf_ROPEd_hypothesis</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>This is overwhelming evidence against the ROPE-d hypothesis that <span class="math inline">\(\delta = 0 \pm 0.1\)</span>.</p>
<p>We can also use this approach to test the directional hypothesis that <span class="math inline">\(\delta &gt; 0.5\)</span>.</p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb522-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-2" aria-hidden="true" tabindex="-1"></a><span class="co">#   [trivial in the case at hand, but just to be explicit]</span></span>
<span id="cb522-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-3" aria-hidden="true" tabindex="-1"></a>prior_of_hypothesis <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb522-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-4" aria-hidden="true" tabindex="-1"></a>prior_odds <span class="ot">&lt;-</span> prior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> prior_of_hypothesis)</span>
<span id="cb522-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-5" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb522-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-6" aria-hidden="true" tabindex="-1"></a>posterior_of_hypothesis <span class="ot">&lt;-</span> <span class="fu">mean</span>( delta_samples <span class="sc">&gt;=</span> <span class="fl">0.5</span> )</span>
<span id="cb522-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-7" aria-hidden="true" tabindex="-1"></a>posterior_odds <span class="ot">&lt;-</span> posterior_of_hypothesis <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> posterior_of_hypothesis)</span>
<span id="cb522-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-8" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb522-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-9" aria-hidden="true" tabindex="-1"></a>bf_directional_hypothesis <span class="ot">&lt;-</span> posterior_odds <span class="sc">/</span> prior_odds</span>
<span id="cb522-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-10" aria-hidden="true" tabindex="-1"></a>bf_directional_hypothesis</span></code></pre></div>
<pre><code>## [1] Inf</code></pre>
<p>Modulo imprecision induced by sampling, we see that the evidence in favor of the directional hypothesis <span class="math inline">\(\delta &gt; 0.5\)</span> is immense.</p>
<!-- exercise 3 -->
<div class="exercises">
<p><strong>Exercise 11.4: True or False?</strong></p>
<p>Decide for the following statements whether they are true or false.</p>
<ol style="list-style-type: lower-alpha">
<li>An encompassing model for addressing ROPE-d hypotheses needs two competing models nested under it.</li>
<li>A Bayes factor of <span class="math inline">\(BF_{01} = 20\)</span> constitutes strong evidence in favor of the alternative hypothesis.</li>
<li>A Bayes factor of <span class="math inline">\(BF_{10} = 20\)</span> constitutes minor evidence in favor of the alternative hypothesis.</li>
<li>We can compute the BF in favor of the alternative hypothesis with <span class="math inline">\(BF_{10} = \frac{1}{BF_{01}}\)</span>.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>Statements a. and d. are correct.</p>
</div>
</div>
</div>

</div>
</div>
</div>
<!-- </div> -->



<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-KlugkistHoijtink2007:The-Bayes-facto" class="csl-entry">
Klugkist, Irene, and Herbert Hoijtink. 2007. <span>“The Bayes Factor for Inequality and about Equality Constrained Models.”</span> <em>Computational Statistics and Data Analysis</em> 51 (12): 6367–79.
</div>
<div id="ref-KlugkistKato2005:Bayesian-model" class="csl-entry">
Klugkist, Irene, Bernet Kato, and Herbert Hoijtink. 2005. <span>“Bayesian Model Selection Using Encompassing Priors.”</span> <em>Statistica Neelandica</em> 59 (1): 57–69.
</div>
<div id="ref-Oh2014:Bayesian-compar" class="csl-entry">
Oh, Man-Suk. 2014. <span>“Bayesian Comparison of Models with Inequality and Equality Constraints.”</span> <em>Statistics and Probability Letters</em> 84: 176–82.
</div>
<div id="ref-WetzelsGrasman2010:An-encompassing" class="csl-entry">
Wetzels, Ruud, Raoul P. P. P. Grasman, and Eric-Jan Wagenmakers. 2010. <span>“An Encompassing Prior Generalization of the Savage–Dickey Density Ratio.”</span> <em>Computational Statistics and Data Analysis</em> 54: 2094–2102.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="53">
<li id="fn53"><p>This method also works for vectors of parameters.<a href="ch-03-05-Bayesian-testing-comparison.html#fnref53" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-03-05-Bayes-testing-estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Chap-04-01-simple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
