<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.1 p-values | Introduction to Data Analysis</title>
  <meta name="description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="generator" content="bookdown 0.17.2 and GitBook 2.6.7" />

  <meta property="og:title" content="10.1 p-values | Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.1 p-values | Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-03-05-hypothesis-testing.html"/>
<link rel="next" href="ch-03-05-hypothesis-testing-CLT.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!--<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.css">-->
<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.css">

<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-v0.9.13.js" defer async></script>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
<link rel="stylesheet" href="webppl-editor.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="Chap-01-00-intro-learning-goals.html"><a href="Chap-01-00-intro-learning-goals.html"><i class="fa fa-check"></i><b>1.1</b> Learning goals</a></li>
<li class="chapter" data-level="1.2" data-path="Chap-01-00-intro-course-structure.html"><a href="Chap-01-00-intro-course-structure.html"><i class="fa fa-check"></i><b>1.2</b> Course structure</a></li>
<li class="chapter" data-level="1.3" data-path="Chap-01-00-intro-tools-methods.html"><a href="Chap-01-00-intro-tools-methods.html"><i class="fa fa-check"></i><b>1.3</b> Tools and topics covered (and not covered) here</a></li>
<li class="chapter" data-level="1.4" data-path="Chap-01-00-intro-data-sets.html"><a href="Chap-01-00-intro-data-sets.html"><i class="fa fa-check"></i><b>1.4</b> Data sets covered</a></li>
<li class="chapter" data-level="1.5" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html"><i class="fa fa-check"></i><b>1.5</b> Installation</a><ul>
<li class="chapter" data-level="1.5.1" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html#Chap-01-00-intro-installation-VirtualBox"><i class="fa fa-check"></i><b>1.5.1</b> VirtualBox Setup</a></li>
<li class="chapter" data-level="1.5.2" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html#Chap-01-00-intro-installation-Manual"><i class="fa fa-check"></i><b>1.5.2</b> Manual installation</a></li>
<li class="chapter" data-level="1.5.3" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html#Chap-01-00-intro-installation-Updating"><i class="fa fa-check"></i><b>1.5.3</b> Updating the course package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap-01-01-R.html"><a href="Chap-01-01-R.html"><i class="fa fa-check"></i><b>2</b> Basics of R</a><ul>
<li class="chapter" data-level="2.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>2.1</b> First steps</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#functions"><i class="fa fa-check"></i><b>2.1.1</b> Functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>2.1.2</b> Variables</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>2.1.3</b> Literate coding</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>2.1.4</b> Objects</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#packages"><i class="fa fa-check"></i><b>2.1.5</b> Packages</a></li>
<li class="chapter" data-level="2.1.6" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#Chap-01-01-R-help"><i class="fa fa-check"></i><b>2.1.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>2.2</b> Data types</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numeric-vectors-matrices"><i class="fa fa-check"></i><b>2.2.1</b> Numeric vectors &amp; matrices</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>2.2.2</b> Booleans</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>2.2.3</b> Special values</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>2.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>2.2.5</b> Factors</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>2.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html"><i class="fa fa-check"></i><b>2.3</b> Functions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#some-important-built-in-functions"><i class="fa fa-check"></i><b>2.3.1</b> Some important built-in functions</a></li>
<li class="chapter" data-level="2.3.2" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#defining-your-own-functions"><i class="fa fa-check"></i><b>2.3.2</b> Defining your own functions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html"><i class="fa fa-check"></i><b>2.4</b> Loops and maps</a></li>
<li class="chapter" data-level="2.5" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html"><i class="fa fa-check"></i><b>2.5</b> Piping</a></li>
<li class="chapter" data-level="2.6" data-path="ch-01-01-Rmarkdown.html"><a href="ch-01-01-Rmarkdown.html"><i class="fa fa-check"></i><b>2.6</b> Rmarkdown</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="3" data-path="Chap-02-01-data.html"><a href="Chap-02-01-data.html"><i class="fa fa-check"></i><b>3</b> Data, variables &amp; experimental designs</a><ul>
<li class="chapter" data-level="3.1" data-path="Chap-02-01-data-kinds-of-data.html"><a href="Chap-02-01-data-kinds-of-data.html"><i class="fa fa-check"></i><b>3.1</b> Different kinds of data</a></li>
<li class="chapter" data-level="3.2" data-path="Chap-02-01-data-variables.html"><a href="Chap-02-01-data-variables.html"><i class="fa fa-check"></i><b>3.2</b> On the notion of “variables”</a></li>
<li class="chapter" data-level="3.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html"><i class="fa fa-check"></i><b>3.3</b> Basics of experimental design</a><ul>
<li class="chapter" data-level="3.3.1" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#what-to-analyze-dependent-variables"><i class="fa fa-check"></i><b>3.3.1</b> What to analyze? – Dependent variables</a></li>
<li class="chapter" data-level="3.3.2" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#conditions-trials-items"><i class="fa fa-check"></i><b>3.3.2</b> Conditions, trials, items</a></li>
<li class="chapter" data-level="3.3.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#sample-size"><i class="fa fa-check"></i><b>3.3.3</b> Sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="Chap-02-02-data-IO.html"><a href="Chap-02-02-data-IO.html"><i class="fa fa-check"></i><b>4.1</b> Data in, data out</a></li>
<li class="chapter" data-level="4.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#running-example"><i class="fa fa-check"></i><b>4.2.1</b> Running example</a></li>
<li class="chapter" data-level="4.2.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>4.2.2</b> Definition of <em>tidy data</em></a></li>
<li class="chapter" data-level="4.2.3" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#excursion-non-redundant-data"><i class="fa fa-check"></i><b>4.2.3</b> Excursion: non-redundant data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html"><i class="fa fa-check"></i><b>4.3</b> Data manipulation: the basics</a><ul>
<li class="chapter" data-level="4.3.1" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#pivoting"><i class="fa fa-check"></i><b>4.3.1</b> Pivoting</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#subsetting-row-columns"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting row &amp; columns</a></li>
<li class="chapter" data-level="4.3.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#Chap-02-02-tidy-selection"><i class="fa fa-check"></i><b>4.3.3</b> Tidy selection of column names</a></li>
<li class="chapter" data-level="4.3.4" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#adding-changing-and-renaming-columns"><i class="fa fa-check"></i><b>4.3.4</b> Adding, changing and renaming columns</a></li>
<li class="chapter" data-level="4.3.5" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#splitting-and-uniting-columns"><i class="fa fa-check"></i><b>4.3.5</b> Splitting and uniting columns</a></li>
<li class="chapter" data-level="4.3.6" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#sorting-a-data-set"><i class="fa fa-check"></i><b>4.3.6</b> Sorting a data set</a></li>
<li class="chapter" data-level="4.3.7" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#combining-tibbles"><i class="fa fa-check"></i><b>4.3.7</b> Combining tibbles</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chap-02-02-data-grouping-nesting.html"><a href="Chap-02-02-data-grouping-nesting.html"><i class="fa fa-check"></i><b>4.4</b> Grouped operations</a></li>
<li class="chapter" data-level="4.5" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html"><i class="fa fa-check"></i><b>4.5</b> Case study: the King of France</a><ul>
<li class="chapter" data-level="4.5.1" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html#cleaning-the-data"><i class="fa fa-check"></i><b>4.5.1</b> Cleaning the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap-02-03-summary-statistics.html"><a href="Chap-02-03-summary-statistics.html"><i class="fa fa-check"></i><b>5</b> Summary statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html"><i class="fa fa-check"></i><b>5.1</b> Counts and proportions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#loading-and-inspecting-the-data"><i class="fa fa-check"></i><b>5.1.1</b> Loading and inspecting the data</a></li>
<li class="chapter" data-level="5.1.2" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#obtaining-counts-with-n-count-and-tally"><i class="fa fa-check"></i><b>5.1.2</b> Obtaining counts with <code>n</code>, <code>count</code> and <code>tally</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html"><i class="fa fa-check"></i><b>5.2</b> Central tendency and dispersion</a><ul>
<li class="chapter" data-level="5.2.1" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#the-data-for-the-remainder-of-the-chapter"><i class="fa fa-check"></i><b>5.2.1</b> The data for the remainder of the chapter</a></li>
<li class="chapter" data-level="5.2.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.2.2</b> Measures of central tendency</a></li>
<li class="chapter" data-level="5.2.3" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-dispersion"><i class="fa fa-check"></i><b>5.2.3</b> Measures of dispersion</a></li>
<li class="chapter" data-level="5.2.4" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#quantifying-confidence-with-bootstrapping"><i class="fa fa-check"></i><b>5.2.4</b> Quantifying confidence with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html"><i class="fa fa-check"></i><b>5.3</b> Co-variance &amp; correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#covariance"><i class="fa fa-check"></i><b>5.3.1</b> Covariance</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#correlation"><i class="fa fa-check"></i><b>5.3.2</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap-02-02-visualization.html"><a href="Chap-02-02-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="Chap-02-04-Anscombe-example.html"><a href="Chap-02-04-Anscombe-example.html"><i class="fa fa-check"></i><b>6.1</b> Motivating example: Anscombe’s quartet</a></li>
<li class="chapter" data-level="6.2" data-path="Chap-02-04-good-visualization.html"><a href="Chap-02-04-good-visualization.html"><i class="fa fa-check"></i><b>6.2</b> Visualization: the good, the bad and the info-graphic</a></li>
<li class="chapter" data-level="6.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html"><i class="fa fa-check"></i><b>6.3</b> Basics of <code>ggplot</code></a><ul>
<li class="chapter" data-level="6.3.1" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#incrementally-composition-of-a-plot"><i class="fa fa-check"></i><b>6.3.1</b> Incrementally composition of a plot</a></li>
<li class="chapter" data-level="6.3.2" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#elements-in-the-layered-grammar-of-graphs"><i class="fa fa-check"></i><b>6.3.2</b> Elements in the layered grammar of graphs</a></li>
<li class="chapter" data-level="6.3.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#layers-and-groups"><i class="fa fa-check"></i><b>6.3.3</b> Layers and groups</a></li>
<li class="chapter" data-level="6.3.4" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#grouping"><i class="fa fa-check"></i><b>6.3.4</b> Grouping</a></li>
<li class="chapter" data-level="6.3.5" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#example-of-a-customized-plot"><i class="fa fa-check"></i><b>6.3.5</b> Example of a customized plot</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html"><i class="fa fa-check"></i><b>6.4</b> A rendezvous with popular geoms</a><ul>
<li class="chapter" data-level="6.4.1" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#scatter-plots-with-geom_point"><i class="fa fa-check"></i><b>6.4.1</b> Scatter plots with <code>geom_point</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#smooth"><i class="fa fa-check"></i><b>6.4.2</b> Smooth</a></li>
<li class="chapter" data-level="6.4.3" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#line"><i class="fa fa-check"></i><b>6.4.3</b> Line</a></li>
<li class="chapter" data-level="6.4.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#barplot"><i class="fa fa-check"></i><b>6.4.4</b> Barplot</a></li>
<li class="chapter" data-level="6.4.5" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#plotting-distributions-histograms-boxplots-densities-and-violins"><i class="fa fa-check"></i><b>6.4.5</b> Plotting distributions: histograms, boxplots, densities and violins</a></li>
<li class="chapter" data-level="6.4.6" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#rugs"><i class="fa fa-check"></i><b>6.4.6</b> Rugs</a></li>
<li class="chapter" data-level="6.4.7" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#annotation"><i class="fa fa-check"></i><b>6.4.7</b> Annotation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Chap-02-04-faceting.html"><a href="Chap-02-04-faceting.html"><i class="fa fa-check"></i><b>6.5</b> Faceting</a></li>
<li class="chapter" data-level="6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html"><i class="fa fa-check"></i><b>6.6</b> Customization etc.</a><ul>
<li class="chapter" data-level="6.6.1" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#themes"><i class="fa fa-check"></i><b>6.6.1</b> Themes</a></li>
<li class="chapter" data-level="6.6.2" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#guides"><i class="fa fa-check"></i><b>6.6.2</b> Guides</a></li>
<li class="chapter" data-level="6.6.3" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#axes-ticks-and-tick-labels"><i class="fa fa-check"></i><b>6.6.3</b> Axes, ticks and tick labels</a></li>
<li class="chapter" data-level="6.6.4" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#labels"><i class="fa fa-check"></i><b>6.6.4</b> Labels</a></li>
<li class="chapter" data-level="6.6.5" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#combining-arranging-plots"><i class="fa fa-check"></i><b>6.6.5</b> Combining &amp; arranging plots</a></li>
<li class="chapter" data-level="6.6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#latex-expressions-in-plot-labels"><i class="fa fa-check"></i><b>6.6.6</b> LaTeX expressions in plot labels</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Models and inferences</b></span></li>
<li class="chapter" data-level="7" data-path="Chap-03-01-probability.html"><a href="Chap-03-01-probability.html"><i class="fa fa-check"></i><b>7</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="7.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html"><i class="fa fa-check"></i><b>7.1</b> Probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#outcomes-events-observations"><i class="fa fa-check"></i><b>7.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="7.1.2" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.3" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#interpretations-of-probability"><i class="fa fa-check"></i><b>7.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="7.1.4" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#urns-frequencies-distributions-as-samples"><i class="fa fa-check"></i><b>7.1.4</b> Urns, frequencies &amp; distributions as samples</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html"><i class="fa fa-check"></i><b>7.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#probability-table-for-a-flip-and-draw-scenario"><i class="fa fa-check"></i><b>7.2.1</b> Probability table for a flip-and-draw scenario</a></li>
<li class="chapter" data-level="7.2.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>7.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="7.2.3" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#marginalization"><i class="fa fa-check"></i><b>7.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html"><i class="fa fa-check"></i><b>7.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="7.3.1" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#bayes-rule"><i class="fa fa-check"></i><b>7.3.1</b> Bayes rule</a></li>
<li class="chapter" data-level="7.3.2" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence"><i class="fa fa-check"></i><b>7.3.2</b> Stochastic (in-)dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html"><i class="fa fa-check"></i><b>7.4</b> Random variables</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>7.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="7.4.2" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>7.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
<li class="chapter" data-level="7.4.3" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#expected-value-variance"><i class="fa fa-check"></i><b>7.4.3</b> Expected value &amp; variance</a></li>
<li class="chapter" data-level="7.4.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#composite-random-variables"><i class="fa fa-check"></i><b>7.4.4</b> Composite random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Chap-03-01-probability-R.html"><a href="Chap-03-01-probability-R.html"><i class="fa fa-check"></i><b>7.5</b> Probability distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap-03-03-models.html"><a href="Chap-03-03-models.html"><i class="fa fa-check"></i><b>8</b> Models</a><ul>
<li class="chapter" data-level="8.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html"><i class="fa fa-check"></i><b>8.1</b> Probabilistic models in statistics</a><ul>
<li class="chapter" data-level="8.1.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html#Chap-03-03-models-general-urn-example"><i class="fa fa-check"></i><b>8.1.1</b> Example 1: a single draw from an urn</a></li>
<li class="chapter" data-level="8.1.2" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html#example-2-avocado-prices-by-type"><i class="fa fa-check"></i><b>8.1.2</b> Example 2: avocado prices by type</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html"><i class="fa fa-check"></i><b>8.2</b> Parameters, priors, probability and predictions</a><ul>
<li class="chapter" data-level="8.2.1" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#whats-a-model-parameter"><i class="fa fa-check"></i><b>8.2.1</b> What’s a model parameter?</a></li>
<li class="chapter" data-level="8.2.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-02-models-priors"><i class="fa fa-check"></i><b>8.2.2</b> Priors over parameters</a></li>
<li class="chapter" data-level="8.2.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#two-notions-of-probability-revisited"><i class="fa fa-check"></i><b>8.2.3</b> Two notions of probability (revisited)</a></li>
<li class="chapter" data-level="8.2.4" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#prior-predictions"><i class="fa fa-check"></i><b>8.2.4</b> Prior predictions</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="Chap-03-03-models-three-pillars.html"><a href="Chap-03-03-models-three-pillars.html"><i class="fa fa-check"></i><b>8.3</b> Three pillars of data analysis</a></li>
<li class="chapter" data-level="8.4" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html"><i class="fa fa-check"></i><b>8.4</b> Notation &amp; graphical representation</a><ul>
<li class="chapter" data-level="8.4.1" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#formula-notation"><i class="fa fa-check"></i><b>8.4.1</b> Formula notation</a></li>
<li class="chapter" data-level="8.4.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#graphical-notation"><i class="fa fa-check"></i><b>8.4.2</b> Graphical notation</a></li>
<li class="chapter" data-level="8.4.3" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#multiple-observations"><i class="fa fa-check"></i><b>8.4.3</b> Multiple observations</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html"><i class="fa fa-check"></i><b>8.5</b> Strolling the zoo of models</a><ul>
<li class="chapter" data-level="8.5.1" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#Chap-03-03-models-examples-binomial"><i class="fa fa-check"></i><b>8.5.1</b> The Binomial Model</a></li>
<li class="chapter" data-level="8.5.2" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#flip-and-draw-model"><i class="fa fa-check"></i><b>8.5.2</b> Flip-and-Draw Model</a></li>
<li class="chapter" data-level="8.5.3" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#flip-and-draw-hypergeometric-model"><i class="fa fa-check"></i><b>8.5.3</b> Flip-and-Draw-Hypergeometric Model</a></li>
<li class="chapter" data-level="8.5.4" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#t-test-model-comparing-two-groups"><i class="fa fa-check"></i><b>8.5.4</b> T-Test Model: comparing two groups</a></li>
<li class="chapter" data-level="8.5.5" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>8.5.5</b> Simple Linear Regression Model</a></li>
<li class="chapter" data-level="8.5.6" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#Chap-03-03-models-examples-linear-regression"><i class="fa fa-check"></i><b>8.5.6</b> Linear Regression with Two Groups</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="Chap-03-03-models-hypotheses.html"><a href="Chap-03-03-models-hypotheses.html"><i class="fa fa-check"></i><b>8.6</b> Expressing hypotheses with models</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-03-04-parameter-inference.html"><a href="ch-03-04-parameter-inference.html"><i class="fa fa-check"></i><b>9</b> Parameter estimation</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html"><i class="fa fa-check"></i><b>9.1</b> Bayes rule of parameter estimation</a><ul>
<li class="chapter" data-level="9.1.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#the-effects-of-prior-and-likelihood-on-the-posterior"><i class="fa fa-check"></i><b>9.1.1</b> The effects of prior and likelihood on the posterior</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#posterior-means-and-credible-intervals"><i class="fa fa-check"></i><b>9.1.2</b> Posterior means and credible intervals</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#computing-bayesian-posteriors-with-conjugate-priors"><i class="fa fa-check"></i><b>9.1.3</b> Computing Bayesian posteriors with conjugate priors</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#sequential-updating"><i class="fa fa-check"></i><b>9.1.4</b> Sequential updating</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html"><i class="fa fa-check"></i><b>9.2</b> A frequentist approach to parameter estimation</a><ul>
<li class="chapter" data-level="9.2.1" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html#maximum-likelihood-estimate"><i class="fa fa-check"></i><b>9.2.1</b> Maximum likelihood estimate</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html#confidence-intervals"><i class="fa fa-check"></i><b>9.2.2</b> Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ch-03-03-estimation-testing.html"><a href="ch-03-03-estimation-testing.html"><i class="fa fa-check"></i><b>9.3</b> Addressing point-valued hypotheses with parameter estimation</a></li>
<li class="chapter" data-level="9.4" data-path="ch-03-03-estimation-comparison.html"><a href="ch-03-03-estimation-comparison.html"><i class="fa fa-check"></i><b>9.4</b> Comparing Bayesian and frequentist estimates</a></li>
<li class="chapter" data-level="9.5" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html"><i class="fa fa-check"></i><b>9.5</b> Algorithms for parameter estimation</a><ul>
<li class="chapter" data-level="9.5.1" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#optimizing-functions"><i class="fa fa-check"></i><b>9.5.1</b> Optimizing functions</a></li>
<li class="chapter" data-level="9.5.2" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#approximating-posterior-distributions"><i class="fa fa-check"></i><b>9.5.2</b> Approximating posterior distributions</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html"><i class="fa fa-check"></i><b>9.6</b> Probabilistic modeling with <code>greta</code></a><ul>
<li class="chapter" data-level="9.6.1" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html#basics-of-greta"><i class="fa fa-check"></i><b>9.6.1</b> Basics of <code>greta</code></a></li>
<li class="chapter" data-level="9.6.2" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html#binomial-model"><i class="fa fa-check"></i><b>9.6.2</b> Binomial Model</a></li>
<li class="chapter" data-level="9.6.3" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html#t-test-model-for-mental-chronometry"><i class="fa fa-check"></i><b>9.6.3</b> T-Test Model for Mental Chronometry</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-03-05-hypothesis-testing.html"><a href="ch-03-05-hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html"><i class="fa fa-check"></i><b>10.1</b> <em>p</em>-values</a><ul>
<li class="chapter" data-level="10.1.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#binomial-model---frequentist-version"><i class="fa fa-check"></i><b>10.1.1</b> Binomial Model - frequentist version</a></li>
<li class="chapter" data-level="10.1.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-for-the-binomial-model"><i class="fa fa-check"></i><b>10.1.2</b> <em>p</em>-values for the Binomial Model</a></li>
<li class="chapter" data-level="10.1.3" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#statistical-significance"><i class="fa fa-check"></i><b>10.1.3</b> Statistical significance</a></li>
<li class="chapter" data-level="10.1.4" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-and-alpha-errors"><i class="fa fa-check"></i><b>10.1.4</b> <em>p</em>-values and <span class="math inline">\(\alpha\)</span>-errors</a></li>
<li class="chapter" data-level="10.1.5" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#relation-of-p-values-to-confidence-intervals"><i class="fa fa-check"></i><b>10.1.5</b> Relation of <em>p</em>-values to confidence intervals</a></li>
<li class="chapter" data-level="10.1.6" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#distribution-of-p-values"><i class="fa fa-check"></i><b>10.1.6</b> Distribution of <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="10.1.7" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#how-not-to-interpret-p-values"><i class="fa fa-check"></i><b>10.1.7</b> How (not) to interpret <em>p</em>-values</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html"><i class="fa fa-check"></i><b>10.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="10.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html"><i class="fa fa-check"></i><b>10.3</b> Selected tests</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-Pearsons-Chi"><i class="fa fa-check"></i><b>10.3.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span>-tests</a></li>
<li class="chapter" data-level="10.3.2" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-z-test"><i class="fa fa-check"></i><b>10.3.2</b> <em>z</em>-test</a></li>
<li class="chapter" data-level="10.3.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-t-test"><i class="fa fa-check"></i><b>10.3.3</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="10.3.4" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-ANOVA"><i class="fa fa-check"></i><b>10.3.4</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html"><i class="fa fa-check"></i><b>10.4</b> Three approaches</a><ul>
<li class="chapter" data-level="10.4.1" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#fisher"><i class="fa fa-check"></i><b>10.4.1</b> Fisher</a></li>
<li class="chapter" data-level="10.4.2" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#neyman-pearson"><i class="fa fa-check"></i><b>10.4.2</b> Neyman-Pearson</a></li>
<li class="chapter" data-level="10.4.3" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#hypbrid-modern-nhst"><i class="fa fa-check"></i><b>10.4.3</b> Hypbrid modern NHST</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ch-03-05-hypothesis-testing-3-model-checking.html"><a href="ch-03-05-hypothesis-testing-3-model-checking.html"><i class="fa fa-check"></i><b>10.5</b> Relation to model checking Section</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap-03-06-model-comparison.html"><a href="Chap-03-06-model-comparison.html"><i class="fa fa-check"></i><b>11</b> Model Comparison</a><ul>
<li class="chapter" data-level="11.1" data-path="Chap-03-06-model-comparison-case-study.html"><a href="Chap-03-06-model-comparison-case-study.html"><i class="fa fa-check"></i><b>11.1</b> Case study: recall models</a></li>
<li class="chapter" data-level="11.2" data-path="Chap-03-06-model-comparison-AIC.html"><a href="Chap-03-06-model-comparison-AIC.html"><i class="fa fa-check"></i><b>11.2</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="11.3" data-path="Chap-03-06-model-comparison-LR-test.html"><a href="Chap-03-06-model-comparison-LR-test.html"><i class="fa fa-check"></i><b>11.3</b> Likelihood-Ratio Test</a></li>
<li class="chapter" data-level="11.4" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html"><i class="fa fa-check"></i><b>11.4</b> Bayes factors</a><ul>
<li class="chapter" data-level="11.4.1" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#grid-approximation"><i class="fa fa-check"></i><b>11.4.1</b> Grid approximation</a></li>
<li class="chapter" data-level="11.4.2" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#naive-monte-carlo"><i class="fa fa-check"></i><b>11.4.2</b> Naive Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="outlook.html"><a href="outlook.html"><i class="fa fa-check"></i><b>11.5</b> Outlook</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ch-03-07-hypothesis-testing-Bayes.html"><a href="ch-03-07-hypothesis-testing-Bayes.html"><i class="fa fa-check"></i><b>12</b> Bayesian hypothesis testing</a><ul>
<li class="chapter" data-level="12.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html"><i class="fa fa-check"></i><b>12.1</b> Data and models for this chapter</a><ul>
<li class="chapter" data-level="12.1.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#section"><i class="fa fa-check"></i><b>12.1.1</b> 24/7</a></li>
<li class="chapter" data-level="12.1.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#eco-sensitivity-fictitious"><i class="fa fa-check"></i><b>12.1.2</b> Eco-sensitivity (fictitious)</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="testing-as-posterior-estimation.html"><a href="testing-as-posterior-estimation.html"><i class="fa fa-check"></i><b>12.2</b> Testing as posterior estimation</a><ul>
<li class="chapter" data-level="12.2.1" data-path="testing-as-posterior-estimation.html"><a href="testing-as-posterior-estimation.html#example-247"><i class="fa fa-check"></i><b>12.2.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="12.2.2" data-path="testing-as-posterior-estimation.html"><a href="testing-as-posterior-estimation.html#example-eco-sensitivity"><i class="fa fa-check"></i><b>12.2.2</b> Example: Eco-sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html"><i class="fa fa-check"></i><b>12.3</b> The Savage-Dickey method</a><ul>
<li class="chapter" data-level="12.3.1" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#nested-bayesian-models"><i class="fa fa-check"></i><b>12.3.1</b> Nested (Bayesian) models</a></li>
<li class="chapter" data-level="12.3.2" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#savage-dickey-theorem"><i class="fa fa-check"></i><b>12.3.2</b> Savage-Dickey theorem</a></li>
<li class="chapter" data-level="12.3.3" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#example-247-1"><i class="fa fa-check"></i><b>12.3.3</b> Example: 24/7</a></li>
<li class="chapter" data-level="12.3.4" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#example-eco-sensitivity-1"><i class="fa fa-check"></i><b>12.3.4</b> Example: eco-sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><a href="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><i class="fa fa-check"></i><b>12.4</b> Bayes factors for ROPE-d hypotheses through encompassing models</a><ul>
<li class="chapter" data-level="12.4.1" data-path="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><a href="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html#example-247-2"><i class="fa fa-check"></i><b>12.4.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="12.4.2" data-path="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><a href="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html#example-eco-sensitivity-2"><i class="fa fa-check"></i><b>12.4.2</b> Example: eco-sensitivity</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Appliied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="13" data-path="Chap-04-01-simple-linear-regression.html"><a href="Chap-04-01-simple-linear-regression.html"><i class="fa fa-check"></i><b>13</b> Simple linear regression</a><ul>
<li class="chapter" data-level="13.1" data-path="data-set-murder-data.html"><a href="data-set-murder-data.html"><i class="fa fa-check"></i><b>13.1</b> Data set: murder data</a></li>
<li class="chapter" data-level="13.2" data-path="what-is-a-simple-linear-regression.html"><a href="what-is-a-simple-linear-regression.html"><i class="fa fa-check"></i><b>13.2</b> What is a (simple) linear regression?</a><ul>
<li class="chapter" data-level="13.2.1" data-path="what-is-a-simple-linear-regression.html"><a href="what-is-a-simple-linear-regression.html#prediction-without-any-further-information"><i class="fa fa-check"></i><b>13.2.1</b> Prediction without any further information</a></li>
<li class="chapter" data-level="13.2.2" data-path="what-is-a-simple-linear-regression.html"><a href="what-is-a-simple-linear-regression.html#prediction-with-knowledge-of-unemployment-rate"><i class="fa fa-check"></i><b>13.2.2</b> Prediction with knowledge of unemployment rate</a></li>
<li class="chapter" data-level="13.2.3" data-path="what-is-a-simple-linear-regression.html"><a href="what-is-a-simple-linear-regression.html#simple-linear-regression-general-problem-formulation"><i class="fa fa-check"></i><b>13.2.3</b> Simple linear regression: general problem formulation</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html"><i class="fa fa-check"></i><b>13.3</b> Ordinary least-squares regression</a><ul>
<li class="chapter" data-level="13.3.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#finding-optimal-parameters-with-optim"><i class="fa fa-check"></i><b>13.3.1</b> Finding optimal parameters with <code>optim</code></a></li>
<li class="chapter" data-level="13.3.2" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#fitting-ols-regression-lines-with-lm"><i class="fa fa-check"></i><b>13.3.2</b> Fitting OLS regression lines with <code>lm</code></a></li>
<li class="chapter" data-level="13.3.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#finding-optimal-parameter-values-with-math"><i class="fa fa-check"></i><b>13.3.3</b> Finding optimal parameter values with math</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="a-maximum-likelihood-approach.html"><a href="a-maximum-likelihood-approach.html"><i class="fa fa-check"></i><b>13.4</b> A maximum-likelihood approach</a></li>
<li class="chapter" data-level="13.5" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html"><i class="fa fa-check"></i><b>13.5</b> A Bayesian approach</a><ul>
<li class="chapter" data-level="13.5.1" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html#implementation-in-greta"><i class="fa fa-check"></i><b>13.5.1</b> Implementation in <code>greta</code></a></li>
<li class="chapter" data-level="13.5.2" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html#using-the-brms-package"><i class="fa fa-check"></i><b>13.5.2</b> Using the <code>brms</code> package</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="testing-coefficients.html"><a href="testing-coefficients.html"><i class="fa fa-check"></i><b>13.6</b> Testing coefficients</a><ul>
<li class="chapter" data-level="13.6.1" data-path="testing-coefficients.html"><a href="testing-coefficients.html#bayesian-approach"><i class="fa fa-check"></i><b>13.6.1</b> Bayesian approach</a></li>
<li class="chapter" data-level="13.6.2" data-path="testing-coefficients.html"><a href="testing-coefficients.html#frequentist-approach"><i class="fa fa-check"></i><b>13.6.2</b> Frequentist approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap-04-02-beyond-simple-regression.html"><a href="Chap-04-02-beyond-simple-regression.html"><i class="fa fa-check"></i><b>14</b> Beyond simple linear regression</a><ul>
<li class="chapter" data-level="14.1" data-path="section-1.html"><a href="section-1.html"><i class="fa fa-check"></i><b>14.1</b> </a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>15</b> Logistic regression</a><ul>
<li class="chapter" data-level="15.0.1" data-path="logistic-regression.html"><a href="logistic-regression.html#beta-binomial-model---one-group-revisited"><i class="fa fa-check"></i><b>15.0.1</b> Beta-Binomial model - one group (revisited)</a></li>
<li class="chapter" data-level="15.0.2" data-path="logistic-regression.html"><a href="logistic-regression.html#beta-binomial-model---two-groups-revisited"><i class="fa fa-check"></i><b>15.0.2</b> Beta-Binomial model - two groups (revisited)</a></li>
<li class="chapter" data-level="15.0.3" data-path="logistic-regression.html"><a href="logistic-regression.html#simple-linear-regression-model-revisited"><i class="fa fa-check"></i><b>15.0.3</b> Simple linear regression model (revisited)</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="multinomial-regression.html"><a href="multinomial-regression.html"><i class="fa fa-check"></i><b>16</b> Multinomial regression</a></li>
<li class="chapter" data-level="17" data-path="ordinal-regression.html"><a href="ordinal-regression.html"><i class="fa fa-check"></i><b>17</b> Ordinal regression</a></li>
<li class="chapter" data-level="18" data-path="ch-05-05-hierarchical-modeling.html"><a href="ch-05-05-hierarchical-modeling.html"><i class="fa fa-check"></i><b>18</b> Hierarchical regression</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="app-90-further-material.html"><a href="app-90-further-material.html"><i class="fa fa-check"></i><b>A</b> Further useful material</a><ul>
<li class="chapter" data-level="A.1" data-path="material-on-introduction-to-probability.html"><a href="material-on-introduction-to-probability.html"><i class="fa fa-check"></i><b>A.1</b> Material on <em>Introduction to Probability</em>:</a></li>
<li class="chapter" data-level="A.2" data-path="material-on-bayesian-data-analysis.html"><a href="material-on-bayesian-data-analysis.html"><i class="fa fa-check"></i><b>A.2</b> Material on <em>Bayesian Data Analysis</em>:</a></li>
<li class="chapter" data-level="A.3" data-path="material-on-frequentist-statistics.html"><a href="material-on-frequentist-statistics.html"><i class="fa fa-check"></i><b>A.3</b> Material on <em>frequentist statistics</em>:</a></li>
<li class="chapter" data-level="A.4" data-path="material-on-r-tidyverse-etc-.html"><a href="material-on-r-tidyverse-etc-.html"><i class="fa fa-check"></i><b>A.4</b> Material on <em>R, tidyverse, etc.</em>:</a></li>
<li class="chapter" data-level="A.5" data-path="further-information-for-rstudio.html"><a href="further-information-for-rstudio.html"><i class="fa fa-check"></i><b>A.5</b> Further information for RStudio</a></li>
<li class="chapter" data-level="A.6" data-path="resources-on-webppl.html"><a href="resources-on-webppl.html"><i class="fa fa-check"></i><b>A.6</b> Resources on WebPPL</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="app-91-distributions.html"><a href="app-91-distributions.html"><i class="fa fa-check"></i><b>B</b> Common probability distributions</a><ul>
<li class="chapter" data-level="B.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.1</b> Selected continuous distributions of random variables</a><ul>
<li class="chapter" data-level="B.1.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-normal"><i class="fa fa-check"></i><b>B.1.1</b> Normal distribution</a></li>
<li class="chapter" data-level="B.1.2" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-chi2"><i class="fa fa-check"></i><b>B.1.2</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="B.1.3" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#f-distribution"><i class="fa fa-check"></i><b>B.1.3</b> F distribution</a></li>
<li class="chapter" data-level="B.1.4" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-students-t"><i class="fa fa-check"></i><b>B.1.4</b> Student’s <em>t</em>-distribution</a></li>
<li class="chapter" data-level="B.1.5" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-beta"><i class="fa fa-check"></i><b>B.1.5</b> Beta distribution</a></li>
<li class="chapter" data-level="B.1.6" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#uniform-distribution"><i class="fa fa-check"></i><b>B.1.6</b> Uniform distribution</a></li>
<li class="chapter" data-level="B.1.7" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-dirichlet"><i class="fa fa-check"></i><b>B.1.7</b> Dirichlet distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.2</b> Selected discrete distributions of random variables</a><ul>
<li class="chapter" data-level="B.2.1" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-binomial"><i class="fa fa-check"></i><b>B.2.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="B.2.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-multinomial"><i class="fa fa-check"></i><b>B.2.2</b> Multinomial distribution</a></li>
<li class="chapter" data-level="B.2.3" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-bernoulli"><i class="fa fa-check"></i><b>B.2.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="B.2.4" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-categorical"><i class="fa fa-check"></i><b>B.2.4</b> Categorical distribution</a></li>
<li class="chapter" data-level="B.2.5" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-beta-binomial"><i class="fa fa-check"></i><b>B.2.5</b> Beta-Binomial distribution</a></li>
<li class="chapter" data-level="B.2.6" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#poisson-distribution"><i class="fa fa-check"></i><b>B.2.6</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="understanding-distributions-as-random-variables.html"><a href="understanding-distributions-as-random-variables.html"><i class="fa fa-check"></i><b>B.3</b> Understanding distributions as random variables</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="app-92-exponential-family.html"><a href="app-92-exponential-family.html"><i class="fa fa-check"></i><b>C</b> Exponential Family and Maximum Entropy</a><ul>
<li class="chapter" data-level="C.1" data-path="an-important-family-the-exponential-family.html"><a href="an-important-family-the-exponential-family.html"><i class="fa fa-check"></i><b>C.1</b> An important family: The Exponential Family</a></li>
<li class="chapter" data-level="C.2" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html"><i class="fa fa-check"></i><b>C.2</b> Excursos: “Information Entropy” and “Maximum Entropy Principal”</a><ul>
<li class="chapter" data-level="C.2.1" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html#information-entropy"><i class="fa fa-check"></i><b>C.2.1</b> Information Entropy</a></li>
<li class="chapter" data-level="C.2.2" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html#deriving-probability-distributions-using-the-maximum-entropy-principle"><i class="fa fa-check"></i><b>C.2.2</b> Deriving Probability Distributions using the Maximum Entropy Principle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="app-93-data-sets.html"><a href="app-93-data-sets.html"><i class="fa fa-check"></i><b>D</b> Data sets used in the book</a><ul>
<li class="chapter" data-level="D.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html"><i class="fa fa-check"></i><b>D.1</b> Mental Chronometry</a><ul>
<li class="chapter" data-level="D.1.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#nature-origin-and-rationale-of-the-data"><i class="fa fa-check"></i><b>D.1.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.1.2" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#loading-and-preprocessing-the-data"><i class="fa fa-check"></i><b>D.1.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.1.3" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#cleaning-the-data-1"><i class="fa fa-check"></i><b>D.1.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.1.4" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#exploration-summary-stats-plots"><i class="fa fa-check"></i><b>D.1.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.1.5" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#data-analysis"><i class="fa fa-check"></i><b>D.1.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="simon-task.html"><a href="simon-task.html"><i class="fa fa-check"></i><b>D.2</b> Simon Task</a><ul>
<li class="chapter" data-level="D.2.1" data-path="simon-task.html"><a href="simon-task.html#experiment"><i class="fa fa-check"></i><b>D.2.1</b> Experiment</a></li>
<li class="chapter" data-level="D.2.2" data-path="simon-task.html"><a href="simon-task.html#results"><i class="fa fa-check"></i><b>D.2.2</b> Results</a></li>
<li class="chapter" data-level="D.2.3" data-path="simon-task.html"><a href="simon-task.html#analysis"><i class="fa fa-check"></i><b>D.2.3</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html"><i class="fa fa-check"></i><b>D.3</b> World Values Survey (wave 6 | 2010-2014)</a><ul>
<li class="chapter" data-level="D.3.1" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html#nature-origin-and-rationale-of-the-data-1"><i class="fa fa-check"></i><b>D.3.1</b> Nature, origin and rationale of the data</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html"><i class="fa fa-check"></i><b>D.4</b> King of France</a><ul>
<li class="chapter" data-level="D.4.1" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#app-93-data-sets-king-of-france-background"><i class="fa fa-check"></i><b>D.4.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.4.2" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#loading-and-preprocessing-the-data-1"><i class="fa fa-check"></i><b>D.4.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.4.3" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#cleaning-the-data-2"><i class="fa fa-check"></i><b>D.4.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.4.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#exploration-summary-stats-plots-1"><i class="fa fa-check"></i><b>D.4.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.4.5" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#data-analysis-1"><i class="fa fa-check"></i><b>D.4.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html"><i class="fa fa-check"></i><b>D.5</b> Bio-Logic Jazz-Metal (and where to consume it)</a><ul>
<li class="chapter" data-level="D.5.1" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#nature-origin-and-rationale-of-the-data-2"><i class="fa fa-check"></i><b>D.5.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.5.2" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#loading-and-preprocessing-the-data-2"><i class="fa fa-check"></i><b>D.5.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.5.3" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#exploration-counts-plots"><i class="fa fa-check"></i><b>D.5.3</b> Exploration: counts &amp; plots</a></li>
</ul></li>
<li class="chapter" data-level="D.6" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html"><i class="fa fa-check"></i><b>D.6</b> Avocado prices</a><ul>
<li class="chapter" data-level="D.6.1" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#nature-origin-and-rationale-of-the-data-3"><i class="fa fa-check"></i><b>D.6.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.6.2" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#loading-and-preprocessing-the-data-3"><i class="fa fa-check"></i><b>D.6.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.6.3" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#summary-statistics"><i class="fa fa-check"></i><b>D.6.3</b> Summary statistics</a></li>
<li class="chapter" data-level="D.6.4" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#plots"><i class="fa fa-check"></i><b>D.6.4</b> Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-03-05-hypothesis-p-values" class="section level2">
<h2><span class="header-section-number">10.1</span> <em>p</em>-values</h2>
<p>All prominent frequentist approaches to statistical hypothesis testing (see Section <a href="ch-03-05-hypothesis-testing-3-approaches.html#ch-03-05-hypothesis-testing-3-approaches">10.4</a>) agree that if empirical observations are sufficiently <em>un</em>likely from the point of view of the null-hypothesis <span class="math inline">\(H_0\)</span>, this should be treated (in some way or other) as evidence <em>against</em> the null-hypothesis.<a href="references.html#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a>
A measure, perhaps approximate, of how unlikely (some aspect of) the data is in the light of <span class="math inline">\(H_0\)</span> is the <span class="math inline">\(p\)</span>-value.
To preview the main definition and intuition (to be worked out in detail hereafter), let’s first consider a verbal and then a mathematical formulation.</p>
<div class="infobox">
<p>
<strong>Definition <span class="math inline"><span class="math inline">\(p\)</span></span>-value.</strong> The <span class="math inline"><span class="math inline">\(p\)</span></span>-value associated with observed data <span class="math inline"><span class="math inline">\(D_\text{obs}\)</span></span> gives the probability, derived from the assumption that <span class="math inline"><span class="math inline">\(H_0\)</span></span> is true, of observing an outcome for the chosen test statistic that is at least as extreme evidence against <span class="math inline"><span class="math inline">\(H_0\)</span></span> as the observed outcome.
</p>
<p>
Formally, the <span class="math inline"><span class="math inline">\(p\)</span></span>-value of observed data <span class="math inline"><span class="math inline">\(D_\text{obs}\)</span></span> is: <span class="math display"><span class="math display">\[
p(D_{\text{obs}}) = P(T^{|H_0} \succeq^{H_{0,a}} t(D_{\text{obs}})) % = P(\mathcal{D}^{|H_0} \in \{D \mid t(D) \ge t(D_{\text{obs}})\}) 
\]</span></span> where <span class="math inline"><span class="math inline">\(t \colon \mathcal{D} \rightarrow \mathbb{R}\)</span></span> is a <strong>test statistic</strong> which picks out a relevant summary statistic of each potential data observation, <span class="math inline"><span class="math inline">\(T^{|H_0}\)</span></span> is the <strong>sampling distribution</strong>, namely the random variable derived from test statistic <span class="math inline"><span class="math inline">\(t\)</span></span> and the assumption that <span class="math inline"><span class="math inline">\(H_0\)</span></span> is true, and <span class="math inline"><span class="math inline">\(\succeq^{H_{0,a}}\)</span></span> is a linear order on the image of <span class="math inline"><span class="math inline">\(t\)</span></span> such that <span class="math inline"><span class="math inline">\(t(D_1) \succeq^{H_{0,a}} t(D_2)\)</span></span> expresses that test value <span class="math inline"><span class="math inline">\(t(D_1)\)</span></span> is at least as extreme evidence <em>against</em> <span class="math inline"><span class="math inline">\(H_0\)</span></span> as test value <span class="math inline"><span class="math inline">\(t(D_2)\)</span></span>.<a href="references.html#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
</p>










</div>
<p>A few aspects of this defintion are particularly important (and subsequent text is dedicated to making these aspects more comprehensible):</p>
<ol style="list-style-type: decimal">
<li>this is a frequentist approach in the sense that probabilities are entirely based on (hypothetical) repetitions of the assumed data-generating process, which assumes that <span class="math inline">\(H_0\)</span> is true;</li>
<li>the test statistic <em>t</em> plays a fundamental role and should be chosen such that:
<ul>
<li>it must necessarily select exactly those aspects of the data that matter to our research question,</li>
<li>it should optimally make it possible to derive a closed form (approximation) of <span class="math inline">\(T\)</span>, and<a href="references.html#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a></li>
<li>it would be desirable (but not necessary) to formulate <span class="math inline">\(t\)</span> in such a way that the comparison relation <span class="math inline">\(\succeq^{H_{0,a}}\)</span> coincides with a simple comparison of numbers: <span class="math inline">\(t(D_1) \succeq^{H_{0,a}} t(D_2)\)</span> iff <span class="math inline">\(t(D_1) \ge t(D_2)\)</span>;</li>
</ul></li>
<li>there is an assumed data-generating model buried inside notation <span class="math inline">\(T^{|H_0}\)</span>; and</li>
<li>the notion of “more extreme evidence against <span class="math inline">\(H_0\)</span>”, captured in comparison relation <span class="math inline">\(\succeq^{H_{0,a}}\)</span> depends on our epistemic purposes, i.e., what research question we are ultimately interested in.<a href="references.html#fn54" class="footnote-ref" id="fnref54"><sup>54</sup></a></li>
</ol>
<p>The following sections will elaborate on all of these points. It is important to mention that especially the third aspect (that there is an implicit data-generating model “inside of” classical hypothesis tests) is not something that receives a lot of emphasis in traditional statistics textbooks. Bad textbooks do not even mention the assumptions implicit in a given test. Better textbooks mention these assumptions, good ones stress them. Using a model-centric approach, as we do here, tries to go even a bit further. We will not only stress key assumptions behind a test but present all of the assumptions behind classical tests in a graphical model, similar to what we did for Bayesian models. This arguably makes all implicit assumptions maximally transparent in a concise and lucid representation. It will also help see parallels between Bayesian and frequentist approaches, thereby helping to see both as more of the same rather than as something completely different. In order to cash in this model-based approach, the following sections will therefore introduce new graphical tools to communicate the data-generating model implicit in the classical tests we cover.</p>
<div id="binomial-model---frequentist-version" class="section level3">
<h3><span class="header-section-number">10.1.1</span> Binomial Model - frequentist version</h3>
<p>We start with the Binomial Model because it is the simplest and perhaps most intuitive case. We work out what a <span class="math inline">\(p\)</span>-value is for data for this model and introduce the new graphical language to communicate “frequentist models” in the following. We also introduce the notions of <em>test statistic</em> and <em>sampling distribution</em> based on a case that should be very intuitive, if not familar.</p>
<p>The <a href="Chap-03-03-models-examples-binomial">Binomial Model</a> was covered before from a Bayesian point of view, where we represented it using graphical notation like in Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-Binomial-Model-repeated">10.1</a> (repeated from above). Remember that this is a model to draw inferences about a coin’s bias <span class="math inline">\(\theta\)</span> based on observations of outcomes of flips of that coin. The Bayesian modeling approach treated the number of observed heads <span class="math inline">\(k\)</span> and the number of flips in total <span class="math inline">\(N\)</span> as given, and the coin’s bias parameter <span class="math inline">\(\theta\)</span> as latent.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-Binomial-Model-repeated"></span>
<img src="visuals/binomial-model.png" alt="The Binomial Model (repeated from before) for a Bayesian approach to parameter inference/testing." width="40%" />
<p class="caption">
Figure 10.1: The Binomial Model (repeated from before) for a Bayesian approach to parameter inference/testing.
</p>
</div>
<p>Actually, this way of writing the Binomial Model is rather a shortcut. It glosses over each individual data observation (whether the <span class="math inline">\(i\)</span>-the coin flip was heads or tails) and jumps directly to the most relevant summary statistic of how many of the <span class="math inline">\(N\)</span> flips were heads. This might, of course, be just the relevant level of analysis. If our assumption is true that the outcome of each coin flip is independent of any other flip, and given our goal to learn something about <span class="math inline">\(\theta\)</span>, all that really matters is <span class="math inline">\(k\)</span>. But to prepare ourselves for subsequent frequentist approaches, and in order to appreciate (later!) how powerful a tool a test statistic can be, we can also rewrite the Bayesian model from Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-Binomial-Model-repeated">10.1</a> as the equivalent extended model in Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-Binomial-Model-extended">10.2</a>. In the latter representation, the individual outcomes of each flip are represented as <span class="math inline">\(x_i \in \{0,1\}\)</span>. Each individual outcome is sampled from a <a href="app-91-distributions-bernoulli">Bernoulli distribution</a>. Based on the whole vector of <span class="math inline">\(x_i\)</span>-s, together with knowledge of <span class="math inline">\(N\)</span>, we derive the <strong>test statistic</strong> <span class="math inline">\(k\)</span>, which maps each observation (a vector <span class="math inline">\(x\)</span> or zeros and ones) to a single number <span class="math inline">\(k\)</span> (the number of heads in the vector). Notice that the node for <span class="math inline">\(k\)</span> has a solid double edge, indicating that it follows deterministically from its parent nodes. This is why we can think of <span class="math inline">\(k\)</span> as a sample from a random variable constructed from “raw data” observations <span class="math inline">\(x\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-Binomial-Model-extended"></span>
<img src="visuals/binomial-model-extended.png" alt="The Binomial Model for a Bayesian approach, extended to show 'raw observations' and the 'summary statistic' implicitly used." width="60%" />
<p class="caption">
Figure 10.2: The Binomial Model for a Bayesian approach, extended to show ‘raw observations’ and the ‘summary statistic’ implicitly used.
</p>
</div>
<p>Compare this latter representation in Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-Binomial-Model-extended">10.2</a> with the frequentist Binomial Model in Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-Binomial-Model-frequentist">10.3</a>. The frequentist model treats the number of observations <span class="math inline">\(N\)</span> as observed, just like the Bayesian model. But it also fixes a specific value for the coin’s bias <span class="math inline">\(\theta\)</span>. This is where the (point-valued) null hypothesis comes in. For purposes of analysis, we fix the value of the relevant unobservable latent parameter to a specific value (because we do not want to assign probabilities to latent parameters, but we still like to talk about probabilities somehow). In our graphical model in Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-Binomial-Model-frequentist">10.3</a> the node for the coin’s bias is shaded (=treated as known) but also has a doted second edge to indicate that this is where our null-hypothesis assumption kicks in. We then treat the data vector <span class="math inline">\(x\)</span> and with it the associated test statistic <span class="math inline">\(k\)</span> as unobserved. The data we actually observed will, of course, come in at some point. But the frequentist model leaves the observed data out at first in order to bring in the kinds of probabilities frequentist approaches feel comfortable with: probabilities derived from (hypothetical) repetitions of chance events. So, the frequentist model can now make statements about the likelihood of (raw) data <span class="math inline">\(x\)</span> and values of the derived summary statistic <span class="math inline">\(k\)</span> based on the assumption that the null hypothesis is true. Indeed, for the case at hand, we already know that the <strong>sampling distribution</strong>, i.e., the distribution of values for <span class="math inline">\(k\)</span> given <span class="math inline">\(\theta_0\)</span> is the <a href="app-91-distributions-binomial">Binomial distribution</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-Binomial-Model-frequentist"></span>
<img src="visuals/binomial-model-frequentist.png" alt="The Binomial Model for a frequentist binomial test." width="80%" />
<p class="caption">
Figure 10.3: The Binomial Model for a frequentist binomial test.
</p>
</div>
<p>Let’s take a step back. The frequentist model for the binomial case considers (“raw”) data of the form <span class="math inline">\(\langle x_1, \dots, x_N \rangle\)</span> where each <span class="math inline">\(x_i \in \{0,1\}\)</span> indicates whether the <span class="math inline">\(i\)</span>-th flip was a success (= heads, =1) or a failure (=tails, =0). We identify the set of all binary vectors of length <span class="math inline">\(N\)</span> as the set of hypothetical data which we could, in principle, observe in fictitious repetition of this data-generating process. <span class="math inline">\(\mathcal{D}^{|H_0}\)</span> is then the random variable that assigns each potential observation <span class="math inline">\(D = \langle x_1, \dots, x_N \rangle\)</span> the probability with which it would occur if <span class="math inline">\(H_0\)</span> (=a specific value of <span class="math inline">\(\theta\)</span>) is true. In our case, that is:</p>
<p><span class="math display">\[P(\mathcal{D}^{|H_0} = \langle x_1, \dots, x_N \rangle) = \prod_{i=1}^N \text{Bernoulli}(x_i, \theta_0)\]</span></p>
<p>The model does not work with this raw data and its implied distribution (represented by random variable <span class="math inline">\(\mathcal{D}^{|H_0}\)</span>), it uses a (very natural!) <strong>test statistic</strong> <span class="math inline">\(t \colon \langle x_1, \dots, x_N \rangle \mapsto \sum_{i=1}^N x_i\)</span> instead. The <strong>sampling distribution</strong> for this model is therefore the distribution of values for the derived measure <span class="math inline">\(k\)</span> - a distribution which follows from the distribution of the raw data (<span class="math inline">\(\mathcal{D}^{|H_0}\)</span>) and this particular test statistic <span class="math inline">\(t\)</span>. In its most general form, we write the sampling distribution as <span class="math inline">\(T^{|H_0} = t(\mathcal{D^{H_0}})\)</span>.<a href="references.html#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a> It just so happens (what a relief!) that we know how to express <span class="math inline">\(T^{|H_0}\)</span> in a mathematically very concise fashion. It’s just the Binomial distribution, so that <span class="math inline">\(k \sim \text{Binomial}(\theta_0, N)\)</span>. (Notice how the sampling distribution is really a function of <span class="math inline">\(\theta_0\)</span> (the null-hypothesis) and also of <span class="math inline">\(N\)</span>.)</p>
</div>
<div id="p-values-for-the-binomial-model" class="section level3">
<h3><span class="header-section-number">10.1.2</span> <em>p</em>-values for the Binomial Model</h3>
<p>After seeing a frequentist model and learning about test statistic and sampling distribution, let’s explore what a <span class="math inline">\(p\)</span>-value is based on the frequentist Binomial Model. Our running example will be the 24/7 case, where <span class="math inline">\(N = 24\)</span> and <span class="math inline">\(k = 7\)</span>. Notice that we are glossing over the “raw” data immediately and work with the value of the test statistic of the observed data directly: <span class="math inline">\(t(D_{\text{obs}}) = 7\)</span>.</p>
<p>Remember that, by the definition given above, <span class="math inline">\(p(D_{\text{obs}})\)</span> is the probability of observing a value of the test statistic that is at least as extreme evidence against <span class="math inline">\(H_0\)</span> as <span class="math inline">\(t(D_{\text{obs}})\)</span>, under the assumption that <span class="math inline">\(H_0\)</span> is true:</p>
<p><span class="math display">\[
  p(D_{\text{obs}}) = P(T^{|H_0} \succeq^{H_{0,a}} t(D_{\text{obs}})) % = P(\mathcal{D}^{|H_0} \in \{D \mid t(D) \ge t(D_{\text{obs}})\}) 
\]</span></p>
<p>To fill this with life, we need to set a null hypothesis, i.e., a value <span class="math inline">\(\theta_0\)</span> of coin bias <span class="math inline">\(\theta\)</span>, that we would like to collect evidence <em>against</em>. A fixed <span class="math inline">\(H_0\)</span> will directly fix <span class="math inline">\(T^{|H_0}\)</span> but we will have to put extra thought into how to conceptualize <span class="math inline">\(\succeq^{H_{0,a}}\)</span> for any given <span class="math inline">\(H_0\)</span>. To make exactly this clearer is the job of this section. Specifically, we will look at what is standardly called a <strong>two-sided <span class="math inline">\(p\)</span>-value</strong> and a <strong>one-sided <span class="math inline">\(p\)</span>-value</strong>.</p>
<p>As stated in the introduction to this chapter, since this testing routine is geared to give us evidence against <span class="math inline">\(H_0\)</span>, we should choose <span class="math inline">\(H_0\)</span> in such a way as to give us information about the research question that really matter to us. So, let’s suppose that our research question is either one of the following:</p>
<ul>
<li>Is the coin fair (<span class="math inline">\(\theta = 0.5\)</span>)?</li>
<li>Is the coin biased towards heads (<span class="math inline">\(\theta &gt; 0.5\)</span>)?</li>
</ul>
<p>As we will see below, in both cases the null hypothesis will be the same: we are going to assume that <span class="math inline">\(\theta_0 = 0.5\)</span>. But given our research question, the <strong>alternative hypothesis</strong> <span class="math inline">\(H_a\)</span> to the null-hypothesis will be different. In the case of testing for fairness (<span class="math inline">\(\theta = 0.5\)</span>), the pair of null hypothesis and alternative hypothesis are:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 \colon \theta = 0.5 &amp;&amp; H_a \colon \theta \neq 0.5
\end{aligned}
\]</span>
Notice that here the alternative hypothesis <span class="math inline">\(H_a\)</span> is two-sided in the sense that it departs from <span class="math inline">\(H_0\)</span> left and right, so to speak.</p>
<p>But in the case of testing whether there is a bias towards heads (<span class="math inline">\(\theta &gt; 0.5\)</span>), the null hypothesis is the same but the alternative hypothesis is one-sided:^[An alternative way of looking at this case is to say that, at first, we test the interval-range null hypothesis <span class="math inline">\(\theta &gt; 0.5\)</span>, so that research and null hypothesis coincide. To gather evidence against this interval-range null hypothesis, we will compare it to the alternative hypothesis <span class="math inline">\(\theta &lt; 0.5\)</span>. Since we need a point-value to easily generated the sampling distribution, the question becomes which point for the null-hypothesis to take. We then choose the value that if we gather evidence <em>against</em> this value, this is most disastrous to the null hypothesis in question.]</p>
<p><span class="math display">\[
\begin{aligned}
H_0 \colon \theta = 0.5 &amp;&amp; H_a \colon \theta &lt; 0.5
\end{aligned}
\]</span></p>
<p><strong>Research question <span class="math inline">\(\theta = 0.5\)</span>.</strong> To begin with, assume that we want to address the question of whether the coin is fair, i.e., whether <span class="math inline">\(\theta = 0.5\)</span>. In this case, we identify the research question with the null hypothesis and set <span class="math inline">\(\theta_0 = 0.5\)</span>. Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-testing-binomial-sampling-distribution">10.4</a> shows the sampling distribution of the test statistic <span class="math inline">\(k\)</span>. The probability of the observed value of the sampling statistic is shown in red.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-testing-binomial-sampling-distribution"></span>
<img src="I2DA_files/figure-html/ch-03-04-testing-binomial-sampling-distribution-1.png" alt="Sampling distribution (here: Binomial distribution) and probability associated with observed data $k=7$ highlighted in red, for $N = 24$ coin flips, under the assumption of a null-hypothesis $\theta = 0.5$." width="672" />
<p class="caption">
Figure 10.4: Sampling distribution (here: Binomial distribution) and probability associated with observed data <span class="math inline">\(k=7\)</span> highlighted in red, for <span class="math inline">\(N = 24\)</span> coin flips, under the assumption of a null-hypothesis <span class="math inline">\(\theta = 0.5\)</span>.
</p>
</div>
<p>The question we need to settle to obtain a <span class="math inline">\(p\)</span>-value is which alternative values of <span class="math inline">\(k\)</span> would count as more extreme evidence against the chosen null hypothesis, i.e., how to interpret <span class="math inline">\(\succeq^{H_{0,a}}\)</span> for this case. The obvious approach is to use the probability of any value of the test statistic <span class="math inline">\(k\)</span> directly and say that observing <span class="math inline">\(D_1\)</span> counts as at least as extreme evidence against <span class="math inline">\(H_0\)</span> as observing <span class="math inline">\(D_2\)</span>, <span class="math inline">\(t(D_1) \succeq^{H_{0,a}} t(D_2)\)</span>, iff the probability of observing the test statistic associated with <span class="math inline">\(D_1\)</span> is at least as unlikely as observing <span class="math inline">\(D_2\)</span>: <span class="math inline">\(P(T^{|H_0} = t(D_1)) \le P(T^{|H_0} = t(D_1))\)</span>. To calculate the <span class="math inline">\(p\)</span>-value in this way, we therefore need to sum up the probabilities of all values <span class="math inline">\(k\)</span> under the Binomial distribution (with parameters <span class="math inline">\(N=24\)</span> and <span class="math inline">\(\theta = \theta_0 = 0.5\)</span>) that are no larger than the value of the observed <span class="math inline">\(k = 7\)</span>. In mathematical language:<a href="references.html#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a></p>
<p><span class="math display">\[
p(k) = \sum_{k&#39; = 0}^{N} [\text{Binomial}(k&#39;, N, \theta_0) &lt;= \text{Binomial}(k, N, \theta_0)] \ \text{Binomial}(k&#39;, N, \theta_0)
\]</span></p>
<p>In code, we calculate the this <span class="math inline">\(p\)</span>-value as follows:</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb385-1" data-line-number="1"><span class="co"># exact p-value for k=7 with N=24 and null-hypothesis theta = 0.5</span></a>
<a class="sourceLine" id="cb385-2" data-line-number="2">k_obs &lt;-<span class="st"> </span><span class="dv">7</span></a>
<a class="sourceLine" id="cb385-3" data-line-number="3">N &lt;-<span class="st">  </span><span class="dv">24</span></a>
<a class="sourceLine" id="cb385-4" data-line-number="4">theta_<span class="dv">0</span> &lt;-<span class="st">  </span><span class="fl">0.5</span></a>
<a class="sourceLine" id="cb385-5" data-line-number="5"><span class="kw">tibble</span>( <span class="dt">lh =</span> <span class="kw">dbinom</span>(<span class="dv">0</span><span class="op">:</span>N, N, theta_<span class="dv">0</span>) ) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb385-6" data-line-number="6"><span class="st">  </span><span class="kw">filter</span>( lh <span class="op">&lt;=</span><span class="st">  </span><span class="kw">dbinom</span>(k_obs, N, theta_<span class="dv">0</span>) ) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb385-7" data-line-number="7"><span class="st">  </span><span class="kw">pull</span>(lh) <span class="op">%&gt;%</span><span class="st"> </span>sum <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] 0.06391</code></pre>
<p>Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-testing-binomial-p-value">10.5</a> shows the values that need to be summed over in red.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-testing-binomial-p-value"></span>
<img src="I2DA_files/figure-html/ch-03-04-testing-binomial-p-value-1.png" alt="Sampling distribution (Binomial likelihood function) and $p$-value for the observation of $k=7$ successes in $N = 24$ coin flips, under the assumption of a null-hypothesis $\theta = 0.5$." width="672" />
<p class="caption">
Figure 10.5: Sampling distribution (Binomial likelihood function) and <span class="math inline">\(p\)</span>-value for the observation of <span class="math inline">\(k=7\)</span> successes in <span class="math inline">\(N = 24\)</span> coin flips, under the assumption of a null-hypothesis <span class="math inline">\(\theta = 0.5\)</span>.
</p>
</div>
<p>Of course, R also has a built-in function for a Binomial test. We can use it to verify that we get the same result for the <span class="math inline">\(p\)</span>-value:</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb387-1" data-line-number="1"><span class="kw">binom.test</span>(</a>
<a class="sourceLine" id="cb387-2" data-line-number="2">  <span class="dt">x =</span> <span class="dv">7</span>,     <span class="co"># observed successes</span></a>
<a class="sourceLine" id="cb387-3" data-line-number="3">  <span class="dt">n =</span> <span class="dv">24</span>,    <span class="co"># total nr. observations</span></a>
<a class="sourceLine" id="cb387-4" data-line-number="4">  <span class="dt">p =</span> <span class="fl">0.5</span>    <span class="co"># null hypothesis</span></a>
<a class="sourceLine" id="cb387-5" data-line-number="5">)</a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  7 and 24
## number of successes = 7, number of trials = 24, p-value = 0.06391
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.1261521 0.5109478
## sample estimates:
## probability of success 
##              0.2916667</code></pre>
<p><strong>Research question <span class="math inline">\(\theta &lt; 0.5\)</span>.</strong> Let’s now look at the case where our research hypothesis is that <span class="math inline">\(\theta &gt; 0.5\)</span>, i.e., that there is a bias towards heads. Again we need to settle what the null hypothesis should be and how <span class="math inline">\(\succeq^{H_{0,a}}\)</span> should be interpreted. In this case, we could consider an interval-valued null hypothesis like <span class="math inline">\(\theta_0 &gt; 0.5\)</span> (making the research hypothesis the null). But even so, we would still resort to testing a point-valed null hypothesis <span class="math inline">\(\theta_0 = 0.5\)</span> eventually. This is because point-valued null hypotheses are easy to work with.<a href="references.html#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a> It has therefore become customary to pick the value from the relevant interval which is most favorable of the interval-valued null-hypothesis. In case we find strong evidence <em>against</em> even the most favorable value from the interval, than this does consititute the strongest possible case <em>against</em> the whole interval-based null hypothesis.</p>
<p>But even though we use the the same null-value of <span class="math inline">\(\theta_0 = 0.5\)</span>, the calculation of the <span class="math inline">\(p\)</span>-value will be different from the case we looked at previously. The reason lies in a change to what we should consider more extreme evidence against this interval-valued null hypothesis, i.e., the interpretation of <span class="math inline">\(\succeq^{H_{0,a}}\)</span>. In the case at hand, observing values of <span class="math inline">\(k\)</span> larger than 12, even if they are unlikely for the point-valued hypothesis <span class="math inline">\(\theta_0 = 0.5\)</span> do not consititute evidence against the interval-valued hypothesis we are interested in. So, therefore, we disregard the contribution of the right hand side in Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-testing-binomial-p-value">10.5</a> to arrive at a picture like in Figure <a href="ch-03-05-hypothesis-p-values.html#fig:ch-03-04-testing-binomial-p-value-one-sided">10.6</a>. The associated <span class="math inline">\(p\)</span>-value with this, so-called <strong>one-sided test</strong>, is consequently:</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb389-1" data-line-number="1">k_obs &lt;-<span class="st"> </span><span class="dv">7</span></a>
<a class="sourceLine" id="cb389-2" data-line-number="2">N &lt;-<span class="st"> </span><span class="dv">24</span></a>
<a class="sourceLine" id="cb389-3" data-line-number="3">theta_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="fl">0.5</span></a>
<a class="sourceLine" id="cb389-4" data-line-number="4"><span class="co"># exact p-value for k=7 with N=24 and null-hypothesis theta &gt; 0.5</span></a>
<a class="sourceLine" id="cb389-5" data-line-number="5"><span class="kw">dbinom</span>(<span class="dv">0</span><span class="op">:</span>k_obs, N, theta_<span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span>sum <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] 0.03196</code></pre>
<p>We can double-check against the built-in function <code>binom.test</code> when we ask for a one-sided test:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb391-1" data-line-number="1"><span class="kw">binom.test</span>(</a>
<a class="sourceLine" id="cb391-2" data-line-number="2">  <span class="dt">x =</span> <span class="dv">7</span>,     <span class="co"># observed successes</span></a>
<a class="sourceLine" id="cb391-3" data-line-number="3">  <span class="dt">n =</span> <span class="dv">24</span>,    <span class="co"># total nr. observations</span></a>
<a class="sourceLine" id="cb391-4" data-line-number="4">  <span class="dt">p =</span> <span class="fl">0.5</span>,    <span class="co"># null hypothesis</span></a>
<a class="sourceLine" id="cb391-5" data-line-number="5">  <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span> <span class="co"># the alternative to compare against is theta &lt; 0.5</span></a>
<a class="sourceLine" id="cb391-6" data-line-number="6">)</a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  7 and 24
## number of successes = 7, number of trials = 24, p-value = 0.03196
## alternative hypothesis: true probability of success is less than 0.5
## 95 percent confidence interval:
##  0.0000000 0.4787279
## sample estimates:
## probability of success 
##              0.2916667</code></pre>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-testing-binomial-p-value-one-sided"></span>
<img src="I2DA_files/figure-html/ch-03-04-testing-binomial-p-value-one-sided-1.png" alt="Sampling distribution (Binomial likelihood function) and $p$-value for the observation of $k=7$ successes in $N = 24$ coin flips, under the assumption of a null-hypothesis $\theta &gt; 0.5$." width="672" />
<p class="caption">
Figure 10.6: Sampling distribution (Binomial likelihood function) and <span class="math inline">\(p\)</span>-value for the observation of <span class="math inline">\(k=7\)</span> successes in <span class="math inline">\(N = 24\)</span> coin flips, under the assumption of a null-hypothesis <span class="math inline">\(\theta &gt; 0.5\)</span>.
</p>
</div>
</div>
<div id="statistical-significance" class="section level3">
<h3><span class="header-section-number">10.1.3</span> Statistical significance</h3>
<p>Fisher’s early writing suggests that he considered <span class="math inline">\(p\)</span>-values as quantitative measures of strength of evidence against the null hypothesis. What would need to be done or concluded from such a quantitative measure would need to depend on further careful case-by-base deliberation. In contrast, present practice often uses <span class="math inline">\(p\)</span>-values to check whether a test result is noteworthy in a categorical, not quantitative way. Fixing an <span class="math inline">\(\alpha\)</span>-level of significance (with common values <span class="math inline">\(\alpha \in \{0.05, 0.01, 0.001\}\)</span>), we say that a test result is sigificant if the <span class="math inline">\(p\)</span>-value of the observed data is lower than the specified <span class="math inline">\(\alpha\)</span>.</p>
<p>Significance of a test result, as a categorical measure, can then be further interpreted as a trigger for decision making. Commonly, a significant test results is interpreted as the signal to reject the null hypothesis, i.e., to speak and act as if it was false.</p>
</div>
<div id="p-values-and-alpha-errors" class="section level3">
<h3><span class="header-section-number">10.1.4</span> <em>p</em>-values and <span class="math inline">\(\alpha\)</span>-errors</h3>
<p>Some blends of frequentist statistics focus on establishing a tight regime of error control (see Section <a href="ch-03-05-hypothesis-testing-3-approaches.html#ch-03-05-hypothesis-testing-3-approaches">10.4</a> below): we want to keep a cap on the long-run amount of errors that we make in statistical decision making. The <span class="math inline">\(p\)</span>-value is then related to the <span class="math inline">\(\alpha\)</span>-error, or Type-I error, when decisions to reject the null hypothesis are made based on whether the <span class="math inline">\(p\)</span>-value crosses a particular threshold.</p>
<p>An <span class="math inline">\(\alpha\)</span>-error occurs when we falsely reject the null hypothesis, i.e., we reject the null hypothesis (as implausible) when it is actually true.
Suppose we decide to reject the null hypothesis that the coin is fair in a two-sided test exactly when the <span class="math inline">\(p\)</span>-value of our test is smaller than <span class="math inline">\(\alpha\)</span>, e.g., <span class="math inline">\(\alpha = 0.05\)</span>. In this case, <span class="math inline">\(\alpha\)</span> is an upper bound on the <span class="math inline">\(\alpha\)</span>-error.</p>
</div>
<div id="relation-of-p-values-to-confidence-intervals" class="section level3">
<h3><span class="header-section-number">10.1.5</span> Relation of <em>p</em>-values to confidence intervals</h3>
<p>There is a close relation between <span class="math inline">\(p\)</span>-values and confidence intervals.<a href="references.html#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a> For a two sided test of null hypothesis <span class="math inline">\(\theta = \theta_0\)</span>, with alternatve <span class="math inline">\(H_a \colon \theta \neq \theta_0\)</span>, it holds for all possible data observations <span class="math inline">\(D\)</span> that</p>
<p><span class="math display">\[ p(D) &lt; \alpha \ \ \text{iff} \ \ \theta_0 \not \in \text{CI}(D) \]</span>
where <span class="math inline">\(\text{CI}(D)\)</span> is the <span class="math inline">\((1-\alpha) \cdot 100\%\)</span> confidence interval constructed for data <span class="math inline">\(D\)</span>.</p>
<p>This connection is intuitive when we think about long-term error. Decisions to reject the null hypothesis are false in exactly <span class="math inline">\((\alpha \cdot 100)\%\)</span> of the cases when the null hypothesis is true. The definition of a confidence interval was exactly the same: the true value should like outside a <span class="math inline">\((1-\alpha) \cdot 100\%\)</span> confidence interval in exactly <span class="math inline">\((\alpha \cdot 100)\%\)</span> of the cases. (Of course, this is only a vague and intuitively appealing argument based on the overall rate, not any particular case.)</p>
</div>
<div id="distribution-of-p-values" class="section level3">
<h3><span class="header-section-number">10.1.6</span> Distribution of <span class="math inline">\(p\)</span>-values</h3>
<p>A result that might seem surprising at first is that if the null hypothesis is true, the distribution of <span class="math inline">\(p\)</span>-values is uniform. This, however, is intuitive on second thought. Mathematically it is a direct consequence of the <strong>Probability Integral Transform Theorem</strong>.</p>

<div class="theorem">
<span id="thm:Probability-Integral-Transform" class="theorem"><strong>Theorem 10.1  (Probability Integral Transform)  </strong></span>If <span class="math inline">\(X\)</span> be a continuous random variable with cumulative distribution function <span class="math inline">\(F_X\)</span>, the random variable <span class="math inline">\(Y = F_X(X)\)</span> is a uniformly distributed over interval <span class="math inline">\([0;1]\)</span>, i.e., <span class="math inline">\(y \sim \text{Uniform}(0,1)\)</span>.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> Notice that the cumulative density function of a standard uniform distribution <span class="math inline">\(y \sim \text{Uniform}(0,1)\)</span> is linear line with intercept 0 and slope 1. It therefore suffices to show that <span class="math inline">\(F_Y(y) = y\)</span>.
<span class="math display">\[
\begin{aligned}
F_Y(y) &amp; = P(Y \le y)  &amp;&amp; [\text{def. of cumulative distribution}] \\
 &amp; = P(F_X(X) \le y)  &amp;&amp; [\text{by construction / assumption}] \\
 &amp; = P(X \le F^{-1}_X(y))  &amp;&amp; [\text{applying inverse cumulative function}] \\
 &amp; = F_X(F^{-1}_X(y))  &amp;&amp; [\text{def. of cumulative distribution}] \\
 &amp; = y  &amp;&amp; [\text{inverses cancel out}] \\
\end{aligned}
\]</span>
</div>

<p> </p>
<p>Seeing the uniform distribution of <span class="math inline">\(p\)</span>-values (under a true null hypothesis) helps appreciate how the <span class="math inline">\(\alpha\)</span>-level of significance is related to long-term error control. If the null hypothesis is true, the probability of a significant test result is exactly the significance level.</p>
</div>
<div id="how-not-to-interpret-p-values" class="section level3">
<h3><span class="header-section-number">10.1.7</span> How (not) to interpret <em>p</em>-values</h3>
<p>Though central to much of frequentist statistics, <span class="math inline">\(p\)</span>-values are frequently misinterpreted, even by seasoned scientists <span class="citation">(Haller and Krauss <a href="#ref-HallerKrauss2002:Misinterpretati">2002</a>)</span>. To repeat, the <span class="math inline">\(p\)</span>-value measures the probability of observing, if the null-hypothesis is correct, a value of the test statistic that is (in a specific, contextually specified sense) more extreme than the value of the test statistic that we assign to the observed data. We can therefore treat <span class="math inline">\(p\)</span>-values as a measure of evidence <em>against</em> the null-hypothesis. And if we want to be even more precise, we interpret this as evidence against the whole assumed data-generating process, a central part of which is the null-hypothesis.</p>
<p>The <span class="math inline">\(p\)</span>-value is <em>not</em> a statement about the probability of the null hypothesis given the data. So, it is <em>not</em> something like <span class="math inline">\(P(H_0 \mid D)\)</span>. The latter is a very appealing notion, but it is one that the frequentist denies herself access to. It can also only be computed based on some consideration of prior plausibility of <span class="math inline">\(H_0\)</span> in relation to some alternative hypothesis. Indeed, to calculate <span class="math inline">\(P(H_0 \mid D)\)</span> is the topic of the chapter on <a href="Chap-03-06-model-comparison.html#Chap-03-06-model-comparison">Model Comparison</a>.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-HallerKrauss2002:Misinterpretati">
<p>Haller, Heiko, and Stefan Krauss. 2002. “Misinterpretations of Significance: A Problem Students Share with Their Teachers?” <em>Methods of Psychological Research Online</em> 7 (1): 1–20.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="52">
<li id="fn52"><p>To preview later material (see Section <a href="ch-03-05-hypothesis-testing-3-approaches.html#ch-03-05-hypothesis-testing-3-approaches">10.4</a>), the Neyman-Pearson approach goes further and also looks at evidence in favor of the null-hypothesis. It also tries to quantify something like evidence in favor of the research hypothesis. But Fisher’s approach and some flavors of the hybrid approach only consider how much the data speaks against the null hypothesis.<a href="ch-03-05-hypothesis-p-values.html#fnref52" class="footnote-back">↩</a></p></li>
<li id="fn1"><p>Packages live in the official package repository <a href="https://cran.r-project.org/">CRAN</a>, or are supplied in less standardized forms, e.g., via open repositories, such as GitHub.<a href="Chap-01-01-R.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn53"><p>This latter aspect has been particularly important historically. Given more readily available computing power, alternative approaches based on Monte Carlo simulation of <span class="math inline">\(p\)</span>-values can also be used.<a href="ch-03-05-hypothesis-p-values.html#fnref53" class="footnote-back">↩</a></p></li>
<li id="fn54"><p>It is admittedly a bit of a notational overkill to write this comparison relation as a function of <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span> (the alternative hypothesis). Other definitions of the <span class="math inline">\(p\)</span>-value do not. But the comparison <em>is</em> context dependent, and you deserve to see this clearly. To see it clearly, a certain heaviness of notation is the price to pay.<a href="ch-03-05-hypothesis-p-values.html#fnref54" class="footnote-back">↩</a></p></li>
<li id="fn55"><p>Most often the random variable capturing the sampling distribution is just written as <span class="math inline">\(T\)</span>, but it does make sense to stress also notationally that <span class="math inline">\(T\)</span> depends crucially on <span class="math inline">\(H_0\)</span>.<a href="ch-03-05-hypothesis-p-values.html#fnref55" class="footnote-back">↩</a></p></li>
<li id="fn56"><p>Here, the bracket notation <span class="math inline">\([ \mathit{Boolean} ]\)</span> is the <a href="https://en.wikipedia.org/wiki/Iverson_bracket">Iverson bracket</a>, evaluation to 1 if the Boolean expression is true and to 0 otherwise.<a href="ch-03-05-hypothesis-p-values.html#fnref56" class="footnote-back">↩</a></p></li>
<li id="fn57"><p>The problem for interval-valued null hypothesis is that we would need to specify some more information about how to rank parameters, if only to say that they are all ranked equally (plausible, <em>a priori</em>), which is something that we try to avoid in frequentist approaches.<a href="ch-03-05-hypothesis-p-values.html#fnref57" class="footnote-back">↩</a></p></li>
<li id="fn58"><p>An important caveat applies here. There can be different (approximate) ways of defining <span class="math inline">\(p\)</span>-values and confidence intervals. The relation described here does not hold, when the (approximate) way of computing the <span class="math inline">\(p\)</span>-value does not match the (approximate) way of computing the confidence interval.<a href="ch-03-05-hypothesis-p-values.html#fnref58" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-03-05-hypothesis-testing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-03-05-hypothesis-testing-CLT.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["I2DA.epub", "I2DA.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
