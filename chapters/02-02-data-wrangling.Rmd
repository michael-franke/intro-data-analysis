# Data Wrangling

<hr>

<div style = "float:right; width:45%;">
<img src="visuals/badge-data-wrangling.png" alt="badge-data-wrangling">  
</div>  

The information relevant for our analysis goals is not always directly accessible. Sometimes we must first uncover it effortfully from an inconvenient representation. Also, sometimes data must be cleaned (ideally: by *a priori* specified criteria) by removing data points that are deemed of insufficient quality for a particular goal. All of this, and more, is the domain of **data wrangling**: preprocessing, cleaning, reshaping, renaming etc. Section \@ref(Chap-02-02-data-IO) describes how to read data from and write data to files. Section \@ref(Chap-02-02-data-tidy-data) introduces the concept of **tidy data**. We then look at a few common tricks of data manipulation in Section \@ref(Chap-02-02-data-preprocessing-cleaning). We will learn about grouping operations in Section \@ref(Chap-02-02-data-grouping-nesting) Finally, we look at a concrete application in Section \@ref(Chap-02-02-data-case-study-KoF).

```{block, type='infobox'}
The learning goals for this chapter are:

- be able to read from and write data to files
- understand notion of *tidy data*
- be able to solve common problems of data preprocessing
```


## Data in, data out {#Chap-02-02-data-IO}

The `readr` package handles the reading and writing of data stored in text files.^[Other packages help with reading data from and writing data to other file types, such as excel sheets. Look at the [data I/O cheat sheet](https://rawgit.com/rstudio/cheatsheets/master/data-import.pdf) for more information.] Here is a cheat sheet on the topice: [data I/O cheat sheet](https://rawgit.com/rstudio/cheatsheets/master/data-import.pdf). In this course will mostly deal with data stored in CSV files.

Reading a data set from a CSV file works with the `read_csv` function:

```{r, eval = F}
fresh_raw_data <- read_csv("PATH/FILENAME_RAW_DATA.csv")
```

Writing to a csv file can be done with the `write_csv` function:

<!-- TODO: mention reproducible workflow -->

```{r, eval = F}
write_csv(processed_data, "PATH/FILENAME_PROCESSED_DATA.csv")
```

If you want to use a different delimiter (between cells) than a comma, you can use `read_delim` and `write_delim` for example, which take an additional argument `delim` to be set to the delimiter in question. 

```{r, eval = F}
# reading data from a file where cells are (unconventionally) delimitted by string "|"
data_from_weird_file <- read_delim("WEIRD_DATA_FILE.TXT", delim = "|")
```

## Tidy data {#Chap-02-02-data-tidy-data}

The same data can be represented in multiple ways. There is even room for variance in the class of rectangular representations of data. Some manners of representations are more useful for certain purposes than for others. For data analysis (plotting, statistical analyses) we prefer to represent our data as (rectangular) **tidy data**.

### Running example

Consider the example of student grades for two exams in a course. A compact way of representing the data for visual digestion is the following representation:


```{r , echo = T}
exam_results_visual <- tribble(
  ~exam,       ~"Rozz",   ~"Andrew",   ~"Siouxsie",
  "midterm",   "1.3",     "2.0",       "1.7",
  "final"  ,   "2.3",     "1.7",       "1.0"
)
exam_results_visual
```

This is how such data would frequently be represented, e.g., in tables in a journal. Indeed, Rmarkdown helps us present this data in an appetizing manner, e.g., in Table \@ref(tab:Ch-02-01-exam-results-untidy), which is produced by the code below:

```{r Ch-02-01-exam-results-untidy}
knitr::kable(
  exam_results_visual,
  caption = "Fictitious exam results of fictitious students.", 
  booktabs = TRUE
)
```


Though highly perspicuous, this representation of the data is not tidy, in the special technical sense we endorse here. A tidy representation of the course results could be this:

```{r}
exam_results_tidy <- tribble(
  ~student,    ~exam,      ~grade,
  "Rozz",      "midterm",  1.3,
  "Andrew",    "midterm",  2.0,
  "Siouxsie",  "midterm",  1.7,
  "Rozz",      "final",    2.3,
  "Andrew",    "final",    1.7,
  "Siouxsie",  "final",    1.0
)
exam_results_tidy
```

### Definition of *tidy data*

Following @Wickham2014:Tidy-Data, a tidy representation of (rectangular) data is defined as one where:

1. each variable forms a column,
2. each observation forms a row, and
3. each type of observational unit forms a table.

Any data set that is not tidy is **messy data**. Messy data that satisfies the first two contraints, but not the third will be called **almost tidy data** in this course. We will work, wherever possible, with data that is at least almost tidy. Figure \@ref(fig:02-02-tidy-data-picture) shows a graphical representation of the concept of tidy data.

```{r 02-02-tidy-data-picture, echo = F, fig.cap="Organization of tidy data (taken from @wickham2016)."}
knitr::include_graphics("visuals/tidy-data-R4DS.png")
```

### Excursion: non-redundant data

The final condition in the definition of tidy data is not particularly important for us here (since we will make do with 'almost tidy data'), but to understand it nonetheless consider the following data set:

```{r}
exam_results_overloaded <- tribble(
  ~student,    ~stu_number,    ~exam,      ~grade,
  "Rozz",      "666",          "midterm",  1.3,
  "Andrew",    "1969",         "midterm",  2.0,
  "Siouxsie",  "3.14",         "midterm",  1.7,
  "Rozz",      "666",          "final",    2.3,
  "Andrew",    "1969",         "final",    1.7,
  "Siouxsie",  "3.14",         "final",    1.0
)
exam_results_overloaded
```

This table is not tidy in an intuitive sense because it includes redundancy. Why list the student numbers twice, once with each observation of exam score? The table is not tidy in the technical sense that not every observational unit forms a table, i.e., the observation of student numbers and the observation of exam scores should be stored independently in different tables, like so:

```{r}
# same as before
exam_results_tidy <- tribble(
  ~student,    ~exam,      ~grade,
  "Rozz",      "midterm",  1.3,
  "Andrew",    "midterm",  2.0,
  "Siouxsie",  "midterm",  1.7,
  "Rozz",      "final",    2.3,
  "Andrew",    "final",    1.7,
  "Siouxsie",  "final",    1.0
)
# additional table with student numbers
student_numbers <- tribble(
  ~student,    ~student_number,
  "Rozz",      "666",   
  "Andrew",    "1969",
  "Siouxsie",  "3.14"
)
```

Notice that, although the information is distributed over two tibbles, it is linked by the common column `student`. If we really need to bring all of the information together, the tidyverse has a quick and elegant solution:

```{r}
full_join(exam_results_tidy, student_numbers, by = "student")
```


## Data manipulation: the basics {#Chap-02-02-data-preprocessing-cleaning}

### Pivoting

The tidyverse strongly encourages the use of tidy data, or at least almost tidy data. If your data is (almost) tidy, you can be reasonably sure that you can plot and analyze the data without additional wrangling. If your data is not (almost) tidy because it is too wide or too long (see below), what is required is a joyful round of pivoting. There are two directions of pivoting: making data longer, and making data wider.

#### Making too wide data longer with `pivot_longer`

Consider the previous example of messy data again:

```{r}
exam_results_visual <- tribble(
  ~exam,       ~"Rozz",   ~"Andrew",   ~"Siouxsie",
  "midterm",   "1.3",     "2.0",       "1.7",
  "final"  ,   "2.3",     "1.7",       "1.0"
)
exam_results_visual
```

This data is "too wide". We can make it longer with the function `pivot_longer` from the `tidyr` package. Check out the example below before we plunge into a description of `pivot_longer`.

```{r}
exam_results_visual %>% 
  pivot_longer(
    # pivot every column except the first 
    cols = - 1,
    # name of new column which contains the
    # names of the columns to be "gathered"
    names_to = "student",
    # name of new column which contains the values
    # of the cells which now form a new column
    values_to = "grade"
  ) %>% 
  # optional reordering of columns (to make 
  # the output exactly like `exam_results_tidy`)
  select(student, exam, grade)
```

What `pivot_longer` does, in general, is take a bunch of columns and gather the values of all cells in these columns into a single, new column, the so-called *value column*, i.e., the column with the values of the cells to be gathered. If `pivot_longer` stopped here, we would loose information about which cell values belonged to which original column. Therefore, `pivot_longer` also creates a second new column, the so-called *name column*, i.e., the column with the names of the original columns that we gathered together. Consequently, in order to do its job, `pivot_longer` minimally needs three pieces of information:^[There are alternative possibilities for specifying names of the value and name column, which allow for more dynamic construction of strings. We will not cover all of these details here, but we will use some of these alternative specifications in subsequent examples.]

1. which columns to spin around (function argument `cols`)
2. the name of the to-be-created new value column (function argument `values_to`)
3. the name of the to-be-created new name column (function argument `names_to`)

For different ways of selecting columns to pivot around, see Section \@ref(Chap-02-02-tidy-selection) below.

#### Making too long data wider with `pivot_wider`

Consider the following example of data which is untidy because it is too long:

```{r}
mixed_results_too_long <- 
  tibble(student = rep(c('Rozz', 'Andrew', 'Siouxsie'), times = 2),
         what =    rep(c('grade', 'participation'), each = 3),
         howmuch = c(2.7, 2.0, 1.0, 75, 93, 33))
mixed_results_too_long
```

This data is untidy because it lumps two types of different measurements (a course grade, and the percentage of participation) in a single column. These are different variables, and so should be represented in different columns.

To fix a data representation that is too long, we can make it wider with the help of the `pivot_wider` function from the `tidyr` package. We look at an example before looking at the general behavior of the `pivot_wider` function.

```{r}
mixed_results_too_long %>% 
  pivot_wider(
    # column containing the names of the new columns
    names_from = what,
    # column containing the values of the new columns
    values_from = howmuch
  )
```

In general, `pivot_wider` picks out two columns, one column of values to distribute into new to-be-created columns, and one vector of names or groups which contains the information about the, well, names of the to-be-created new columns. There are more refined options for `pivot_wider` some of which we will encounter in the context of concrete cases of application.

### Subsetting row & columns

If a data set contains too much information for your current purposes, you can discard irrelevant (or unhelpful) rows and columns. The function `filter` takes a Boolean expression and returns only those rows of which the Boolean expression is true:

```{r}
exam_results_tidy %>% 
  # keep only entries with grades better than 1.7
  filter(grade <= 1.7)
```

To select rows by an index or a vector of indeces, use the `slice` function:

```{r}
exam_results_tidy %>% 
  # keep only entries from rows with an even index
  dplyr::slice(c(2,4,6)) # explicit call to avoid name clash (package 'greta')
```

The function `select` allows to pick out a subset of columns. Interestingly, it can also be used to reorder columns, because the order in which column names are specified matches the order in the returned tibble.

```{r}
exam_results_tidy %>% 
  # select columns `grade` and `name`
  select(grade, exam)
```

### Tidy selection of column names {#Chap-02-02-tidy-selection}

To select the colums in several functions within the tidyverse, such as `pivot_longer` or `select`, there are useful helper functions from the `tidyselect` package. Here are some examples:^[The helpers from the `tidyselect` package also accept regular expressions.]

```{r, eval = F}
# bogus code for illustration of possibilities!
SOME_DATA %>% 
  select( ... # could be one of the following
        # all columns indexed 2, 3, ..., 10
        2:10
        # all columns except the one called "COLNAME"
        - COLNAME
        # all columns with names starting with "STRING"
       ... starts_with("STRING")
       # all columns with names ending with "STRING"
       ... ends_with("STRING")
       # all columns with names containing "STRING"
       ... contains("STRING")
       # all columns with names of the form "Col_i" with i = 1, ..., 10
       ... num_range("Col_", 1:10)
  )
```


### Adding, changing and renaming columns

To add a new column, or to change an existing one use function `mutate`, like so:

```{r}
exam_results_tidy %>% 
  mutate(
    # add a new column called 'passed' depending on grade
    # [NB: severe passing conditions in this class!!]
    passed = grade <= 1.7, 
    # change an existing column; here: change
    # character column 'exam' to ordered factor
    exam = factor(exam, ordered = T)
  )
```

If you want to rename a column, function `rename` is what you want:

```{r}
exam_results_tidy %>% 
  # rename existing colum "student" to new name "participant"
  # [NB: rename takes the new name first]
  rename(participant = student)
```

### Splitting and uniting columns

Here is data from course homework:

```{r}
homework_results_untidy <- 
  tribble(
    ~student,      ~results,
    "Rozz",        "1.0,2.3,3.0",
    "Andrew",      "2.3,2.7,1.3",
    "Siouxsie",    "1.7,4.0,1.0"
  )
```

This is not a useful representation format. Results of three homework sets are mushed together in a single column. Each value is separated by a comma, but it's all stored as a character vector.

To disentangle information in a single column, use the `separate` function:

```{r}
homework_results_untidy %>% 
  separate(
    # which column to split up
    col = results,
    # names of the new column to store results
    into = str_c("HW_", 1:3),
    # separate by which character / reg-exp
    sep = ",",
    # automatically (smart-)convert the type of the new cols
    convert = T 
    )
```

If you have reason to perform the reverse operation, i.e., join together several columns, use the `unite` function.


### Sorting a data set

If you want to indicate a fixed order of the reoccurring elements in a (character) vector, e.g., for plotting in a particular order, you should make this column an ordered factor. But if you want to order a data set along a column, e.g., for inspection or printing as a table, then you can do that using the `arrange` function. You can specify several columns to sort alpha-numerically in ascending order, and also indicate a descending order using the `desc` function:

```{r}
exam_results_tidy %>% 
  arrange(desc(student), grade)
```


### Combining tibbles

There are frequently occasions on which data from two separate variables needs to be combined. The simplest case is where two entirely disjoint data sets merely need to be glued together, either horizontally (binding columns together with function `cbind`) or vertically (binding rows together with function `rbind`).

```{r}
new_exam_results_tidy <- tribble(
  ~student,    ~exam,      ~grade,
  "Rozz",      "bonus",  1.7,
  "Andrew",    "bonus",  2.3,
  "Siouxsie",  "bonus",  1.0
)
rbind(
  exam_results_tidy, 
  new_exam_results_tidy
)
```

If two data sets have information in common, and the combination should respect that commonality, the `join` family of functions is of great help. Consider the case of distributed information again that we looked at to understand the third constraint of the concept of "tidy data". There are two tibbles, both of which contain information about the same students. They share the column `student` (this does not necessarily have to be in the same order!) and we might want to join the information from both sources into a single (messy but almost tidy) representation, using `full_join`. We have seen an example already, which is repeated here:

```{r}
# same as before
exam_results_tidy <- tribble(
  ~student,    ~exam,      ~grade,
  "Rozz",      "midterm",  1.3,
  "Andrew",    "midterm",  2.0,
  "Siouxsie",  "midterm",  1.7,
  "Rozz",      "final",    2.3,
  "Andrew",    "final",    1.7,
  "Siouxsie",  "final",    1.0
)
# additional table with student numbers
student_numbers <- tribble(
  ~student,    ~student_number,
  "Rozz",      "666",   
  "Andrew",    "1969",
  "Siouxsie",  "3.14"
)
full_join(exam_results_tidy, student_numbers, by = "student")
```

If two data sets are to be joined by a column that is not exactly shared by both sets (one contains entries in this columns that the other doesn't) then a `full_join` will retain all information from both. If that is not what you want, check out alternative functions like `right_join`, `semi_join` etc. using the [data wrangling cheat sheet](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf).

## Grouped operations {#Chap-02-02-data-grouping-nesting}

A frequently occurring problem in data analysis is to obtain a summary statistic (see Section \@ref(Chap-02-03-summary-statistics)) for different subsets of data. For example, we might want to calculate the average score for each student in our class. We could do that by filtering like so (notice that `pull` gives you the column vector specified):

```{r}
# extracting mean grade for Rozz
mean_grade_Rozz <- exam_results_tidy %>% 
  filter(student == "Rozz") %>% pull(grade) %>% mean
mean_grade_Rozz
```

But then we need to do that two more times, so we shouldn't copy-paste code, so we write a function and use `mutate` to add a mean for each student:

```{r}
get_mean_for_student = function(student_name) {
  exam_results_tidy %>% 
  filter(student == student_name) %>% pull(grade) %>% mean
}

map_dbl(
  exam_results_tidy %>% pull(student) %>% unique,
  get_mean_for_student
)
```

Also not quite satisfactory, clumsy and error-prone. Enter, grouping in the tidyverse. If we want to apply a particular operation to all combinations of levels of different variables (no matter whether they are encoded as factors or not when we group), we can do this with the function `group_by`, followed by either a call to `mutate` or `summarise`. Check this example:

```{r}
exam_results_tidy %>% 
  group_by(student) %>% 
  summarise(
    student_mean = mean(grade)
  )
```

The funciton `summarise` returns a single row for each combination of levels of grouping variables. If we use the function `mutate` instead, the summary statistic is added (repeatedly) in each of the original rows:

```{r}
exam_results_tidy %>% 
  group_by(student) %>% 
  mutate(
    student_mean = mean(grade)
  )
```

The latter can sometimes be handy, for example when overlaying a plot of the data with grouped means, for instance.

It may be important to remember that after a call of `group_by`, the resulting tibbles retains the grouping information for *all* subsequent operations. To remove grouping information, use the function `ungroup`.


<!-- TODO: summarizing to return tibbles -->
 

## Case study: the King of France {#Chap-02-02-data-case-study-KoF}

<div style = "float:right; width:12%;">
<img src="visuals/skull_king.png" alt="badge-data-wrangling">  
</div>  

Let's go through one case study of data preprocessing. We look at the example introduced and fully worked out in Appendix \@ref(app-93-data-sets-king-of-france). (Please read Section \@ref(app-93-data-sets-king-of-france-background) to find out more about where this data set is coming from.)

The raw data set is stored in the GitHub repository that also hosts this web-book. It can be loaded using:

```{r, echo = F}
data_KoF_raw <- read_csv('data_sets/king-of-france_data_raw.csv',
                         col_types = cols(
                           submission_id = col_double(),
                           RT = col_double(),
                           age = col_double(),
                           comments = col_character(),
                           item_version = col_character(),
                           correct_answer = col_logical(),
                           education = col_character(),
                           gender = col_character(),
                           languages = col_character(),
                           question = col_character(),
                           response = col_logical(),
                           timeSpent = col_double(),
                           trial_name = col_character(),
                           trial_number = col_double(),
                           trial_type = col_character(),
                           vignette = col_character()
                         ))
```


```{r eval = F}
data_KoF_raw <- read_csv(url('https://raw.githubusercontent.com/michael-franke/intro-data-analysis/master/data_sets/king-of-france_data_raw.csv'))
```

We can then get a glimpse at the data using:

```{r}
glimpse(data_KoF_raw )
```

The variables in this data set are:

- `submission_id`: unique identifier for each participant
- `RT`: the reaction time for each decision
- `age`: the (self-reported) age of the participant
- `comments`: the (optional) comments each participant may have given
- `item_version`: the condition which the test sentence belongs to (only given for trials of type `main` and `special`)
- `correct_answer`: for trials of type `filler` and `special` what the true answer should have been
- `education`: the (self-reported) education level with options `Graduated College`, `Graduated High School`, `Higher Degree`
- `gender`: (self-reported) gender
- `languages`: (self-reported) native languages
- `question`: the sentence to be judged true or false
- `response`: the answer ("TRUE" or "FALSE") on each trial
- `trial_name`: whether the trial is a main or practice trials (levels `main_trials` and `practice_trials`)
- `trial_number`: consecutive numbering of each participant's trial
- `trial_type`: whether the trial was of the category `filler`, `main`, `practice` or `special`, where the latter encodes the "background checks"
- `vignette`: the current item's vignette number (applies only to trials of type `main` and `special`)





Let's have brief look at the comments (sometimes helpful, usually entertaining) and the self-reported native languages:

```{r}
data_KoF_raw %>% pull(comments) %>% unique
```

```{r}
data_KoF_raw %>% pull(languages) %>% unique
```

We might wish to exclude people who do not include "English" as one of their native languages in some studies. Here, we do not since we also have strong, more specific filters on comprehension (see below). Since we are not going to use this information later on, we might as well discard it now:

```{r}
data_KoF_raw <- data_KoF_raw %>% 
  select(-languages, - comments, -age, - RT, - education, - gender)
```


But even after pruning irrelevant columns, this data set is still not ideal. We need to preprocess it more thoroughly to make it more intuitively managable. For example, the information in column `trial_name` does not give the trial's name in an intuitive sense, but its type: whether it is a practice or a main trial. But this information, and more, is also represented in the column `trial_type`. The column `item_version` contains information about the experimental condition. To see this (mess) the code below prints the selected information from the main trials of only one participant in an order that makes it easier to see what is what.

```{r}
data_KoF_raw %>% 
  # ignore practice trials for the moment
  # focus on one participant only
  filter(trial_type != "practice", submission_id == 192) %>% 
  select(trial_type, item_version, question) %>% 
  arrange(desc(trial_type), item_version) %>% 
  print(n = Inf)
```

We see that the information in `item_version` specifies the critical condition. To make this more intuitively manageable, we would like to have a column called `condition` and it should, ideally, also contain useful information for the cases where `trial_type` is not `main` or `special`. That is why we will therefore remove the column `trial_name` completely, and create an informative column `condition` in which we learn of every row whether it belongs to one of the 5 experimental conditions, and if not whether it is a filler or a "background check" (= special) trial.

```{r}
data_KoF_processed <-  data_KoF_raw %>% 
  # drop redundant information in column `trial_name`
  select(-trial_name) %>% 
  # discard practice trials
  filter(trial_type != "practice") %>% 
  mutate(
    # add a 'condition' variable
    condition = case_when(
      trial_type == "special" ~ "background check",
      trial_type == "main" ~ str_c("Condition ", item_version),
      TRUE ~ "filler"
    ) %>% 
      # make the new 'condition' variable a factor
      factor( 
        ordered = T,
        levels = c(
          str_c("Condition ", c(0, 1, 6, 9, 10)), 
          "background check", "filler"
        )
      )
  )
# write_csv(data_KoF_processed, "data_sets/king-of-france_data_processed.csv")
```


<!-- TODO: mention reproducible workflow -->

### Cleaning the data

We clean the data in two consecutive steps:

1. Remove all data from any participant who got more than 50% of the answer to filler material wrong.
2. Remove individual main trials if the corresponding "background check" question was answered wrongly.

#### Cleaning by-participant

```{r}
# look at error rates for filler sentences by subject
# mark every subject as an outlier when they 
# have a proportion of correct responses of less than 0.5 
subject_error_rate <- data_KoF_processed %>% 
  filter(trial_type == "filler") %>% 
  group_by(submission_id) %>% 
  summarise(
    proportion_correct = mean(correct_answer == response),
    outlier_subject = proportion_correct < 0.5
  ) %>% 
  arrange(proportion_correct)
```

Apply the cleaning step:

```{r}
# add info about error rates and exclude outlier subject(s)
d_cleaned <- 
  full_join(data_KoF_processed, subject_error_rate, by = "submission_id") %>% 
  filter(outlier_subject == FALSE)

```


#### Cleaning by-trial


```{r}
# exclude every critical trial whose 'background' test question was answered wrongly
d_cleaned <- 
  d_cleaned %>% 
  # select only the 'background question' trials
  filter(trial_type == "special") %>% 
  # is the background question answered correctly?
  mutate(
    background_correct = correct_answer == response
  ) %>%
  # select only the relevant columns
  select(submission_id, vignette, background_correct) %>%
  # right join lines to original data set 
  right_join(d_cleaned, by = c("submission_id", "vignette")) %>% 
  # remove all special trials, as well as main trials with incorrect background check
  filter(trial_type == "main" & background_correct == TRUE)

# write_csv(d_cleaned, "data_sets/king-of-france_data_cleaned.csv")
```


