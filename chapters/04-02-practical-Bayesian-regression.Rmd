# Bayesian regression in practice {#Chap-04-02-Bayes-regression-practice}

<hr>

Instead of hand-coding each Bayesian regression model, we can use the `brms` package [@brms2017].
From now on, the exploration of Bayesian data analysis in this book will be centered on this package.
This chapter provides a practical introduction to using this package.

<div style = "float:right; width:7%;">
<img src="visuals/badge-thermometer.png" alt="badge-thermometer">
</div>

As a running example, this chapter uses the [world temperature data set](#app-93-data-sets-temperature).
We are going to regress `avg_temp` against `year` in order to address the "research question" of whether the world is getting warmer.
More concretely, we are going to address the question of whether the data provide reason to believe that, on the assumption of a linear relationship $y = \beta_0 + \beta_1 x$, where $x$ is a calendar year and $y$ is the average surface temperature for that year, the coefficient $\beta_1$ is credibly positive.^[Not to let the elephant sneak into the room: yes, there are much better models for this kind of data and research question than a simple linear regression model. But first things first.]


```{block, type='infobox'}
The learning goals for this chapter are:

- be able to use the `brms` package to run linear regression models and in particular, to:
  - specify a regression model with an R formula
  - interpret the summary output
  - extract posterior samples
  - change the default priors
  - test hypotheses about regression coefficients

```


## Simple linear regression with `brms`

The main function of the `brms` package is `brm` (short for **B**ayesian **R**egression **M**odel). It behaves very similarly to the `glm` function we saw above.^[Actually, `brm` is similar to the `lmer` function from the `lme4` package, which is more general than `glm`. Both `lmer` and `brm` also cover so-called hierarchical regression models.] Here is an example of the current case study based on the [world temperature data set](#app-93-data-sets-temperature):

```{r, eval = T}
fit_temperature <- brm(
  # specify what to explain in terms of what
  #  using the formula syntax
  formula = avg_temp ~ year,
  # which data to use
  data = aida::data_WorldTemp
)
```

The formula syntax `y ~ x` tells R that we want to explain or predict the dependent variable `y` in terms of associated measurements of `x`, as stored in the data set (`tibble` or `data.frame`) supplied in the function call as `data`.

The object returned by this function call is a special-purpose object of the class `brmsfit`. If we print this object to the screen we get a summary (which we can also produce with the explicit call `summary(fit_temperature)`).

```{r}
fit_temperature
```

This output tells us which model we fitted and it states some properties of the MCMC sampling routine used to obtain samples from the posterior distribution.
The most important pieces of information for drawing conclusions from this analysis are the summaries for the estimated parameters, here called "Intercept" (the $\beta_0$ of the regression model), "year" (the slope coefficient $\beta_1$ for the `year` column in the data) and "sigma" (the standard deviation of the Gaussian error function around the central predictor).
The "Estimate" shown here for each parameter is its posterior mean.
The columns "l-95% CI" and "u-95% CI" give the 95% inner quantile range of the marginal posterior distribution for each parameter.


## Extracting posterior samples

The function `brms::posterior_samples` extracts the samples from the posterior which are part of the `brmsfit` object.^[The column `lp__` gives the log probability of the data for the corresponding parameter values in each row. This is useful information for model checking and model comparison, but we will neglect it here.]

```{r}
post_samples_temperature <- brms::posterior_samples(fit_temperature) 
head(post_samples_temperature)
```

These extracted samples can be used as before, e.g., to compute our own summary tibble:

```{r}
map_dfr(post_samples_temperature %>% select(-lp__), aida::summarize_sample_vector) %>% 
  mutate(Parameter = colnames(post_samples_temperature[1:3]))
```

Or for manual plotting:^[There are also specialized packages for plotting the output of Stan models and `brms` model fits, such as the excellent `tidybayes` and `ggdist` packages.]

```{r}
post_samples_temperature %>% 
  select(-lp__) %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(x = value)) +
  geom_density() +
  facet_wrap(~name, scales = "free")
```

## [Excursion:] Inspecting the underlying Stan code

Under the hood, the `brms` package automatically creates Stan code, runs it and computes useful additional information for regression modeling around the `stan_fit` object.
Here's how we can inspect the precise model that `brms` set up for us and ran:

```{r}
brms::stancode(fit_temperature)
```

Even if the Stan code itself is not entirely transparent, a few interesting observations to be glimpsed are:

1. `brms` automatically centralizes the predictor values, but returns fits for the non-centralized coefficients
2. by default, the prior for slope coefficients is a completely uninformative one (every value is equally likely)

## Setting priors

Bayesian models require priors for all parameters.
The function `brms::prior_summary` shows which priors a model fitted with `brms` has (implicitly) assumed.

```{r}
prior_summary(fit_temperature)
```

This output tells us that `brms` used a Student's $t$ distribution for the intercept and the standard deviation.^[Actually, the prior on the standard deviation is a *truncated* Student's $t$ distribution, as negative values are impossible for a standard deviation.]
It also shows us that all slope coefficients (abbreviated here as "b") have a flat (non-informative) prior.

If we want to change the prior for any model parameter, or family of model parameters, we can use the `prior` argument in the `brm` function, which requires a special type of input using `brms`' `prior()` function.
The syntax for distributions inside the `prior()` follows that of Stan, as documented in the [Stan function reference](https://mc-stan.org/docs/2_25/functions-reference/index.html).
The example below sets the prior for the slope coefficient to a very narrow Student's $t$ distribution with mean `-0.01` and standard deviation `0.001`.


```{r}
fit_temperature_skeptical <- brm(
  # specify what to explain in terms of what
  #  using the formula syntax
  formula = avg_temp ~ year,
  # which data to use
  data = aida::data_WorldTemp,
  # hand-craft priors for slope
  prior = prior(student_t(1, -0.01, 0.001), coef = year)
)
```

This prior is a *skeptical prior* in the sense that it assumes a negative slope to be more likely, that is, the world has been getting colder over the years.
Comparing the summary statistics for the original fit:

```{r}
map_dfr(post_samples_temperature %>% select(-lp__), aida::summarize_sample_vector) %>% 
  mutate(Parameter = colnames(post_samples_temperature[1:3]))
```

against those of the new fit using skeptical priors:

```{r}
post_samples_temperature_skeptical <- brms::posterior_samples(fit_temperature_skeptical)
map_dfr(post_samples_temperature_skeptical %>% select(-lp__),
        aida::summarize_sample_vector) %>% 
  mutate(Parameter = colnames(post_samples_temperature_skeptical[1:3]))
```

we see that the data has overturned the initial skeptical prior, suggesting that the evidence provided in the data for the belief that the slope coefficient is positive is stronger than the original (maybe hypothetical) assumption to the contrary.

<div class = "exercises">
**Exercise 13.1**

What do you expect to happen to the estimate of the intercept when using a very strong prior on the slope coefficient for `year`, e.g., a normal distribution with a mean of 5 and a standard deviation of .01?

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

We should expect the posterior of the slope for `year` to be much higher than the original estimate, much closer to 5.
The reason is that the normal distribution is much less "willing" to allow outliers and so constraints the fit much stronger towards the mean of the prior than the Student's $t$ distribution.
Notice that with slope values close to 5, the estimates for the intercept and standard deviation also change (in ridiculous ways).

```{r}
fit_temperature_ridiculous <- brm(
  # specify what to explain in terms of what
  #  using the formula syntax
  formula = avg_temp ~ year,
  # which data to use
  data = aida::data_WorldTemp,
  # hand-craft priors for slope
  prior = prior(normal(5, 0.01), coef = year)
)
post_samples_temperature_ridiculous <- brms::posterior_samples(fit_temperature_ridiculous)
map_dfr(post_samples_temperature_ridiculous %>% select(-lp__),
        aida::summarize_sample_vector) %>% 
  mutate(Parameter = colnames(post_samples_temperature_ridiculous[1:3]))
```

</div>
</div>
</div>

## Posterior predictions

The function `brms::posterior_predict` returns samples from the posterior predictive distribution of a `brms_fit` object.
For example, the code below yields 4000 sampled predictions for each of the 269 `year` values in the world temperature data set.

```{r}
samples_post_pred_temperature <- brms::posterior_predict(fit_temperature)
dim(samples_post_pred_temperature)
```

The function `brms::posterior_predict` can also be used to sample from the posterior predictive distribution of a fitted regression model for new values of the model's predictors.
If we are interested in predictions of average world surface temperature for the years 2025 and 2040, all we need to do is supply a data frame (or tibble) with the predictor values of interest as an argument.

```{r}
# create a tibble with new predictor values
X_new <- tribble(
  ~ "year", 2025, 2040
)
# get sample predictions from the Bayesian model
post_pred_new <- brms::posterior_predict(fit_temperature, X_new)
# get a (Bayesian) summary for these posterior samples
rbind(
  aida::summarize_sample_vector(post_pred_new[,1], "2025"),
  aida::summarize_sample_vector(post_pred_new[,2], "2040")  
)
```

## Testing hypotheses

The `brms` package also contains a useful function to address hypotheses about model parameters.
The function `brms::hypothesis` can compute Bayes factors for point-valued hypotheses using the Savage-Dickey method.
It also computes a binary test of whether a point-valued hypothesis is credible based on inclusion in a Bayesian credible interval. 
For interval-valued hypotheses $\theta \in [a;b]$, the function `brms::hypothesis` computes the posterior odds (called *evidence ratio* in the context of this function):^[Notice that for priors where $P(\theta \in [a;b]) = 0.5$, the posterior odds equal the Bayes factor.
For other priors, we'd need to correct the posterior odds by the priors to obtain Bayes factors, something that the `brms` package does not (presently seem to) do, unfortunately.]
$$
\frac{P(\theta \in [a;b] \mid D)}{P(\theta \not \in [a;b] \mid D)}
$$

Computing Bayes factors for point-valued hypotheses with `brms::hypothesis` requires proper priors for all parameters that are part of the hypothesis.
It also requires taking samples from the priors of parameters.^[It may seem unnecessary to take prior samples for parameters, because, after all, couldn't we just look at the (closed-form) definition of the prior for that parameter? Well, that only works for top-level parameters, but not parameters in a hierarchical model which depend on the value of other parameters and which therefore have no (easily accessible) closed-form prior to look up.]
So, here is a function call of `brms:brm` which (i) specifies a reasonably unconstrained but proper parameter for the slope coefficient for `year` and (ii) also collects samples from the prior (by setting the option `sample_prior = "yes"`):

```{r}
fit_temperature_weakinfo <- brm(
  # specify what to explain in terms of what
  #  using the formula syntax
  formula = avg_temp ~ year,
  # which data to use
  data = aida::data_WorldTemp,
  # weakly informative prior for slope
  prior = prior(student_t(1, 0, 1), coef = year),
  # option to sample from priors as well
  # (necessary for calculating BFs with Savage-Dickey)
  sample_prior = 'yes',
  # increase number of iterations (for precision of estimates)
  iter = 20000
)
```

Before addressing hypotheses about the slope parameter for `year`, let's remind ourselves of the summary statistics for the posterior:

```{r}
brms::posterior_samples(fit_temperature_weakinfo) %>% 
  pull(b_year) %>% 
  aida::summarize_sample_vector()
```

The main "research hypothesis" of interest is whether the slope for `year` is credibly positive. 
This is an interval-valued hypothesis and we can test it like so:


```{r}
hypothesis(fit_temperature_weakinfo, "year > 0")
```

The table shows the estimate for the slope of `year`, together with an estimated error, lower and upper bounds of a credible interval (95% by default).
All of these numbers are rounded.
It also shows the "Evidence ratio" which, for an interval-valued hypothesis is *not* the Bayes factor, but the posterior odds (see above).
In the present case, an evidence ratio of `Inf` means that all posterior samples for the slope coefficient were positive.
This is also expressed in the posterior probability ("Post.Prod" in the table) for the proposition that the interval-valued hypothesis is true (given data and model).

The following tests a point-valued hypothesis:

```{r}
hypothesis(fit_temperature_weakinfo, "year = 0.005")
```

For this point-valued hypothesis, the estimate (and associated error and credible interval) are calculated as a comparison against 0, as shown in the "Hypothesis" column.
The evidence ratio given in the results table is the Bayes factor of the point-valued hypothesis against the embedding model (the full regression model with the prior we specified), as calculated by the Savage-Dickey method.
As before, the posterior probability is also shown.
The "Star" in this table indicates that the point-valued hypothesis is excluded from the computed credible interval, so that - if we adopted the (controversial) binary decision logic discussed in Chapter \@ref(ch-03-07-hypothesis-testing-Bayes) - we would reject the tested hypothesis.


