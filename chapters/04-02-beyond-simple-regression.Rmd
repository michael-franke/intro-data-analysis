# Beyond simple linear regression {#Chap-04-02-beyond-simple-regression}

<hr>

This chapter showcases how linear regression models can be applied flexibly to a variety of data analysis problems. In particular, we will look at how linear regression can be used to compute the mean differences between different groups.

- categorical predictors
  - two-groups (eco-sensitivity data)
  - more groups (mental chronometry)
  - interactions (Winter data)
- metric and categorical predictors combined
  - avocado data
<!-- - logistic regression -->
<!--   - KoF data -->


## Two categorical predictors

Let's revisit the (fictitious) eco-sensitivity data from Chapter \@ref(ch-03-07-hypothesis-testing-Bayes):

```{r}
x_A <- c(
  104, 105, 100, 91, 105, 118, 164, 168, 111, 107, 136, 149, 104, 114, 107, 95, 
  83, 114, 171, 176, 117, 107, 108, 107, 119, 126, 105, 119, 107, 131
)
x_B <- c(
  133, 115, 84, 79, 127, 103, 109, 128, 127, 107, 94, 95, 90, 118, 124, 108, 
  87, 111, 96, 89, 106, 121, 99, 86, 115, 136, 114
)
```

Remember that we are interested in the question of whether there is a difference in means of group A and group B. Previously we used a $t$-test for this two-group comparison (frequentist or Bayesian). But we can also cast this as a regression problem. Here is how.

Let's first squeeze the data into a tibble:

```{r}
eco_sensitivity_data <- tibble(
  group = c(rep("A", length(x_A)), rep("B", length(x_B))),
  measurement = c(x_A, x_B)
) 
eco_sensitivity_data
```

Notice that this tibble contains the data in a tidy format, i.e., each row contains a tuple of associated measurements. We want to explain or predict the variable `measurement` in terms of the variable `group`.We can then run a regression model with the formula `measurement ~ group`. Here's such a model using the Bayesian approach:

```{r, eval = F}
fit_brms_eco_sensitivity <- brm(
  # specify what to explain in terms of what
  #  using the formula syntax
  formula = measurement ~ group,
  # which data to use
  data = eco_sensitivity_data
)
```

```{r, echo = F}
fit_brms_eco_sensitivity <- readRDS('models_brms/fit_brms_eco_sensitivity.rds')
```

Let's inspect the summary information for the posterior samples:

```{r}
# just showing the currently most relevant information
summary(fit_brms_eco_sensitivity)$fixed[,c("Estimate","l-95% CI", "u-95% CI")]
```

Compare this with the summary of the posterior estimates we obtained from the Bayesian $t$-test model for this data which we implemented in `greta` and ran in Chapter \@ref(ch-03-07-hypothesis-testing-Bayes). [TODO: redo with Stan]

```{r echo = T, eval = F}
draws_t_test_2 <- readRDS('models_greta/ttest_2_draws.rds')
tidy_draws_tt2 = ggmcmc::ggs(draws_t_test_2)
# get means and 95% HDI
Bayes_estimates_eco <- tidy_draws_tt2 %>% 
  group_by(Parameter) %>%
  summarise(
    '|95%' = HDInterval::hdi(value)[1],
    mean = mean(value),
    '95|%' = HDInterval::hdi(value)[2]
  )
```

```{r, eval = F}
Bayes_estimates_eco
```

The mean of the $\delta$ parameter looks suspiciously similar to the ominous `groupB` parameter shown in the output of the `brms` model fit. The 95% HDIs of the estimated posterior for the $\delta$ parameter also look suspiciously like the values of the 95% inter-quantile range for the `groupB` parameter. This is no coincidence! In fact, the regression model that `brms` calculates here is essentially the same as the $t$-test model we implemented in `greta` by hand except for slight differences in the choice of the priors and inessential differences in the mathematical formulation of the group mean comparison. 

The call to `brm` above implicitly computed a linear regression model of the following form:

$$
\begin{aligned}
\hat{y}_i & = \beta_0 + \beta_1 x_i & y_i & \sim \text{Normal}(\mu = \hat{y}_i, \sigma)
\end{aligned}
$$

The only important point is that the vector $x$, which corresponds to the group information in the column `group` (which contains entries of strings `"A"` and `"B"`), is implicitly treated as a vector of zeros and ones. Implicitly, `brm` has chosen the string `"A"` as the **reference category** which is encoded as zero. The string `"B"` is the other category, encoded as number 1. As a consequence, the linear model's intercept parameter $\beta_0$ can be interpreted as the predicted mean of the reference category: if for some $i$ we have $x_i = 0$, then the predictor $\hat{y}_i$ will just be $\hat{y}_i = \beta_0$; whence that the intercept $\beta_0$ will be fitted to the mean of the reference category. If for some $i$ we have $x_i = 1$ instead, the predicted value will be computed as $\hat{y}_i = \beta_0 + \beta_1$, so that the slope term $\beta_1$ will effectively play the role of the difference $\delta$ between the mean of the groups. Modulo choice of priors and variable naming, the `brm` model encodes a Bayesian $t$-test model exactly like we previously did using `greta`. The upshot is, that we can conceive of a **$t$-test as a special case of a linear regression model!**

Of course, nothing in this correspondence depends on a Bayesian analysis in particular. Let's look at the frequentist version:

```{r}
fit_glm_eco <- glm(
  # specify what to explain in terms of what
  #  using the formula syntax
  formula = measurement ~ group,
  # which data to use
  data = eco_sensitivity_data
)
summary(fit_glm_eco)
```

The $p$-value associated with the test of whether the slope coefficient (the difference between means) is plausibly zero corresponds to the result we get from a $t$-test (when assuming equal variance in groups; an assumption that the linear modeling approach makes per default).

```{r}
t.test(x_A, x_B, paired = F, var.equal = T)
```

<div class = "exercises">
**Exercise 14.1**
For the given data below, compute the coefficients of linear regression by hand. Choose the appropriate encoding of group information.

groupA: (1,0,2) and groupB: (10,13,7)

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">
For $\hat{y}_i  = \beta_0 + \beta_1 x_i$, let $x_i =0$ if the data point if from groupA and $x_i=1$ if it's from groupB. Then the mean of groupA is computed by the intercept $\mu_A  = \beta_0$ and the mean of groupB is computed as sum of the intercept and the slope $\mu_B  = \beta_0 + \beta_1$. Since $\mu_A = 1$ and $\mu_B = 10$, we can guess that $\beta_0 = 1$ and $\beta_1 = 10 - 1 = 9$.
</div>
</div>
</div>

## More than two categorical predictors

<div style = "float:right; width:15%;">
<img src="visuals/badge-mental-chronometry.png" alt="badge-mental-chronometry">  
</div>  

A $t$-test is only applicable to at most two groups. The classical approach to generalizing frequentist testing to the comparison of more than two groups is to use ANOVA, as briefly discussed in Chapter \@ref(ch-03-05-hypothesis-testing-ANOVA). But we can also use a linear regression approach for this, as demonstrated here based on the [mental chronometry data](app-93-data-sets-mental-chronometry). 

We load the data as usual, but also immediately mutate the column `block` (which captures the experimental manipulation we want to use to explain the dependent variable `RT` (= reaction times)) so that the "goNoGo" condition will come first in alphabetic order. This has the effect that, later in regression modeling, the "goNoGo" condition will be treated as the reference level to compare other groups against. This makes sense because our main question of interest is whether these inequalities are supported by the data:

$$
\text{RT in 'reaction'} < 
\text{RT in 'goNoGo'} <
\text{RT in 'discrimination'}
$$

So we are interested in the $\delta$s, so to speak, between 'reaction' and 'goNoGo' and between 'discrimination' and 'goNoGo'.

```{r, eval = F}
mc_url <- url('https://raw.githubusercontent.com/michael-franke/intro-data-analysis/master/data_sets/mental-chrono-data_cleaned.csv')
mc_data_cleaned <- read_csv(mc_url) %>% 
  # renaming to make 'goNoGo' the reference level 
  #  (dirty hack, but simpler than to messing with contrast coding)
  mutate(
    block = case_when(
      block == "reaction"         ~ "B_reaction",
      block == "goNoGo"           ~ "A_goNoGo",
      block == "discrimination"   ~ "C_discrimination"
    )
  )
```

```{r, echo = F}
mc_data_cleaned <- read_csv('data_sets/mental-chrono-data_cleaned.csv') %>% 
  mutate(
    block = case_when(
      block == "reaction"         ~ "B_reaction",
      block == "goNoGo"           ~ "A_goNoGo",
      block == "discrimination"   ~ "C_discrimination"
    )
  )
```

To fit this model with `brm` we then just need a simple function call with the formula `RT ~ block` that precisely describes what we are interested in: to explain reaction times as a function of the experimental condition:

```{r eval = F}
fit_brms_mc <- brm(
  # model 'RT' as a function of 'block'
  formula = RT ~ block,
  data = mc_data_cleaned
)
```


```{r echo = F}
fit_brms_mc <- readRDS('models_brms/mc_data_fit.rds')
```

To inspect the posterior fits of this model, we can extract the relevant summary statistics as before:

```{r}
summary(fit_brms_mc)$fixed[,c("Estimate","l-95% CI", "u-95% CI")]
```

Notice that there is an intercept term, as before. This corresponds to the mean reaction time of the reference level (here: 'goNoGo'). There are two slope coefficients, one for the difference between the 'goNoGo' and the 'reaction' condition ('blockB_reaction') and another for the difference between the 'goNoGo' and the 'discrimination' condition ('blockC_discrimination'). In formula, $\hat{y}_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}$, whereas $\beta_0$: Intercept, $\beta_1$: blockB_reaction and $\beta_2$: blockC_discrimination. $x_{i1} = 1$ iff the data point is from the 'reaction' condition and $x_{i2} = 1$ iff it's from the 'discrimination' condition.

As we may have expected, the 95% inter-quantile range for both slope coefficients (which, given the amount of data we have, is almost surely almost identical to the 95% HDI) does not include 0 by a very wide margin. We could, therefore, conclude, based on a Bayesian approach to hypothesis testing in terms of posterior estimation, that the reaction times of conditions are credibly different.

The function call for a frequentist analysis with `glm` is almost identical:

```{r}
fit_glm_mc <- glm(
  # model 'RT' as a function of 'block'
  formula = RT ~ block,
  data = mc_data_cleaned
)
```

The summary of the model fit reveals $p$-values for both slope coefficients, which indicate (unsurprisingly) that there is very strong evidence against the null hypothesis of no difference between the means of the two pairs of conditions we compare with this model:

```{r}
summary(fit_glm_mc)
```

## Interaction terms in factorial designs

<div style = "float:right; width:15%;">
<img src="visuals/badge-politeness.png" alt="badge-politeness">  
</div>  

The following content is a distilled version of a short tutorial on Bayesian regression modeling for factorial designs [@FrankeRoettger2019:Bayesian-regres], which can be downloaded [here](https://psyarxiv.com/cdxv3). We consider data on voice pitch in a $2 \times 2$ factorial design, with factors `gender` and `context`. This is laboratory data measuring the voice pitch of male and female speakers (factor `gender`) in two different kinds of linguistic contexts, namely a polite and an informal situation (factor `context`).




We load the data, inspect and plot it.

```{r, eval = F}
politeness_url <- url('https://raw.githubusercontent.com/michael-franke/intro-data-analysis/master/data_sets/politeness_data.csv')
politeness_data <- read_csv(politeness_url)
```

```{r, echo = F}
politeness_data <- read_csv('data_sets/politeness_data.csv')
politeness_data
```

```{r, echo = F}
# this code is copy pasted from tutorial paper
politedata <- politeness_data 
politedata.agg <- 
  politedata %>% 
    group_by(gender, context, sentence) %>% 
    summarize(mean_frequency = mean(pitch))

politedata.agg2 <- 
  politedata %>%
  group_by(gender, context) %>% 
  summarize(mean_frequency = round(mean(pitch), 0))

ggplot(data = politedata.agg, 
       aes(x = gender, 
           y = mean_frequency, 
           colour = context)) + 
  geom_point(position = position_dodge(0.5), 
             alpha = 0.3, 
             size = 3) +
  geom_point(data = politedata.agg2, 
             aes(x = gender, 
                 y = mean_frequency, 
                 #colour = context,
                 fill = context),
             position = position_dodge(0.5), 
             pch = 21, 
             colour = "black",
             size = 5) +
  scale_x_discrete(breaks = c("F", "M"),
                  labels = c("female", "male")) +
  scale_y_continuous(expand = c(0, 0), breaks = (c(50,100,150,200,250,300)), limits = c(50,300)) +
  scale_colour_manual(breaks = c("inf", "pol"),
                      labels = c("informal", "polite"),
                      values = c("#f1a340", "#998ec3")) +
  scale_fill_manual(breaks = c("inf", "pol"),
                      labels = c("informal", "polite"),
                      values = c("#f1a340", "#998ec3")) +
  ylab("pitch in Hz\n") +
  xlab("\ngender")
```

In a $2 \times 2$ factorial design like this, there are essentially four pairs of factor levels (so-called **design cells**): female speakers in informal contexts, female speakers in polite contexts, male speakers in informal contexts and male speakers in polite contexts. Different schemes exist by means of which different comparisons of means of design cells (or single factors) can be probed. A simple coding scheme for differences in our $2 \times 2$ design is shown in Figure \@ref(fig:Chap-04-02-beyond-simple-regression-factorial-coefficients). We consider the cell "female+informal" as the reference level and therefore model its mean as intercept $\beta_0$. We then have a slope term $\beta_{\text{pol}}$ which encodes the difference between female pitch in informal and female pitch in polite contexts. Analogous reasoning holds for $\beta_{\text{male}}$. Finally, we also include a so-called **interaction term**, denoted as $\beta_{\text{pol\&male}}$ in Figure \@ref(fig:Chap-04-02-beyond-simple-regression-factorial-coefficients). The interaction term quantifies how much a change away from the reference level in both variables differs from the sum of unilateral changes.

```{r Chap-04-02-beyond-simple-regression-factorial-coefficients, echo = F, fig.cap="Regression coefficients for a factorial design (using so-called 'treatment coding').", fig.width=4}
knitr::include_graphics("visuals/coefficients_factorial_design.png")
```

We can fit a regression model with this coding scheme using the formula `pitch ~ gender * context`. Importantly the star `*` between explanatory variables `gender` and `context` indicates that we also want to include the interaction term.

```{r eval = F}
fit_brms_politeness <- brm(
  # model 'pitch' as a function of 'gender' and 'context',
  #  also including the interaction between `gender` and `context`
  formula = pitch ~ gender * context,
  data = politeness_data
)
```

```{r echo = F}
fit_brms_politeness <- readRDS('models_brms/politeness_fit.rds')
```

The summary statistics below lists the model parameters indicated in Figure \@ref(fig:Chap-04-02-beyond-simple-regression-factorial-coefficients).

```{r}
summary(fit_brms_politeness)$fixed[,c("Estimate","l-95% CI", "u-95% CI")]
```

We could conclude from this that, given model and data, it is plausible to think that male speakers had lower voices than female speakers in informal contexts: this shows in the exclusion of 0 in the 95% inter-quantile range for parameter `genderM`. We may also conclude that given model and data, it is plausible to think that female speakers used lower voices in polite contexts than in formal ones  (parameter `contextpol`).
The posterior of the interaction term `genderM:contextpol` does not give any indication to think that 0, or any value near it, is not plausible. This can be interpreted as saying that there is no indication, given model and data, to believe that male speakers' voice pitch changes differently from informal to polite contexts than female speakers' voice pitch does.
