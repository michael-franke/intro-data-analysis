# (PART) Data {-}

# Data, variables & experimental designs {#Chap-02-01-data}

<hr>

<div style = "float:right; width:45%;">
<img src="visuals/badge-data.png" alt="HERE">  
</div>  

The focus of this course is on data from behavioral psychology experiments.^[A *behavioral experiment* is an experiment that records participants' behavioral choices, such as button clicks or linguistic responses in the form of text or speech. This contrasts with, say, *neurological experiments* in which participants' brain activity is recorded, such as fMRI or EEG, or, e.g., in a psycholinguistic context, *processing-related experiments* in which secondary measures of cognitive activity are measured, such as eye-movements, pupil dilation or galvanic skin responses.] In a sense, this is perhaps the most "well-behaved" data to analyze and therefore an excellent starting point into data analysis. However, we should not lose sight of the rich and diverse guises of data that are relevant for scientific purposes. The current chapter therefore starts, in Section \@ref(Chap-02-01-data-kinds-of-data), with sketching some of that richness and diversity. But it then hones in on some basic distinctions of the kinds of data we will frequently deal with in the cognitive sciences in Section \@ref(Chap-02-01-data-variables). We also pick up a few relevant concepts from standard experimental design in Section \@ref(Chap-02-01-data-exp-design).

<!-- TODO: insert references to subsections -->

```{block, type='infobox'}
The learning goals for this chapter are:

- appreciate the diversity of data
- distinguish different kinds of variables
  - dependent vs. independent
  - nominal vs. ordinal vs. metric
- get familiar with basic aspects of experimental design
  - factorial designs
  - within- vs. between-subjects design
  - repeated measures
  - randomization, fillers and controls
  - sample size
- understand the notion of "tidy data"
```

## Different kinds of data {#Chap-02-01-data-kinds-of-data}

Some say we live in the **data age**. But what is data actually? Purist pedants say: "The plural of datum" and add that a datum is just an observation. But when we say "data", we usually mean a bit more than a bunch of observations. The Merriam-Webster offers the following:

> Factual information (such as measurements or statistics) used as a basis for reasoning, discussion, or calculation.

This is a teleological definition in the sense that it refers to the purpose of the thing: "used as basis for reasoning, discussion, or calculation". So, what we mean by "data" is, in large part, defined by what we intend to do with it. Another important aspect of this definition is that we usually consider data to be systematically structured in some way or another. Even when we speak of "raw data", we expect there to be some structure (maybe labels, categories etc.) that distinguishes data from uninterpretable noise (e.g., the notion of a "variable", discussed in Section \@ref(Chap-02-01-data-variables)). In sum, we can say that **data is a representation of information stored in a systematic way for the purpose of inference, argument or decision making**.

There are different kinds of data. Figure \@ref(fig:02-01-data-graph) shows some basic distinctions, represented in a conceptual hierarchy.

```{r 02-01-data-graph, echo = F, fig.cap="Hierarchy of different kinds of data relevant for 'data science'."}
knitr::include_graphics("visuals/data-graph.png")
```

It is easy but wrong to think that data always has to be information based on observations of the world. It is easy to think this because **empirical data**, i.e., data obtained from empirical observation, is the most common form of data (given that it is, arguably, most relevant for decision making and argument). But it is wrong to think this because we can just as well look at **virtual data**. For example, virtual data, which is of interest to a data analyst, could be **data obtained from computer simulation studies**, e.g., from, say, 1 billion runs of a multi-agent simulation intended to shed light on the nature of cooperative interaction. It makes sense to analyze such data with the same tools as data from an experiment. We might find out that some parameter constellations in the simulation run are (statistically) most conducive to producing cooperative behavior among our agents, for instance. Another example of virtual data is **data generated as predictions of a model**, which we can use to test whether that model is any good, in so-called model criticism (see Section \@ref(Chap-03-08-model-criticism)).^[We will later speak of **prior/posterior predictions** for this kind of data. Other applicable terms are **repeat data** or sometimes **fake data**.] Finally, we should also include **logically possible sample data** in this list, because of its importance to central ideas of statistical inference (especially $p$-values, see Section \@ref(ch-03-05-hypothesis-testing)). Logically possible sample data is that was neither observed nor predicted by a model, but something that could have been observed hypothetically, something that it is merely logically possible to observe, even if it would almost never happen in reality or would not be predicted by any serious model.

The most frequent form of data, **empirical data** about the actual world, comes in two major variants. **Observational data** is data gathered by (passively) observing and recording what would have happened even if we had not been interested in it, so to speak. Examples of observational data are collections of socio-economic variables, like gender, education, income, number of children, etc. In contrast, **experimental** data is data recorded in a strict regime of manipulation-and-observation, i.e., a scientific experiment. Some pieces of information can only be recorded in an observational study (annual income), and others can only be obtained through experimentation (memory span). Both methods of data acquisition have their own pros and cons. Here are some of the more salient ones:


```{r, echo = F}
table_data <- tribble(
  ~observational, ~experimental,
  "ecologically valid", "possibly artificial",
  "easy/easier to obtain", "hard/harder to obtain",
  "correlation & causation hard to tease apart", "may yield information on causation vs. correlation"
)
knitr::kable(
  table_data,
  caption = "Comparison of the pros and cons of observational data and experimental data.", 
  booktabs = TRUE
)
```


No matter what kind of data we have at hand, there are at least two prominent purposes for which data can be useful: **explanation** and **prediction**. Though related, it is useful to keep these purposes cleanly apart. Data analysis for explanation uses the data to better understand the source of the data (the world, a computer simulation, a model, etc.). Data analysis for prediction tries to extract regularities from the data gathered so far to make predictions (as accurately as possible) about future or hitherto unobserved data.

## On the notion of "variables" {#Chap-02-01-data-variables}

Data used for data analysis, even if it is "raw data", i.e., data before preprocessing and cleaning, is usually structured or labeled in some way or other. Even if the whole data we have is a vector of numbers, we would usually know what these numbers represent. For instance, we might just have a quintuple of numbers, but we would (usually, ideally) know that these represent the results of an IQ test.

```{r}
# a simple data vector of IQ-scores
IQ_scores <- c(102, 115, 97, 126, 87)
```

Or we might have a Boolean vector with the information of whether each of five students passed an exam. But even then we would (usually/ideally) know the association between names and test results, as in a table like this:

```{r}

# who passed the exam
exam_results <- 
  tribble(
    ~student,   ~pass,
    "Jax",      TRUE,
    "Jason",    FALSE,
    "Jamie",    TRUE
  )
```

Association of information, as between different columns in a table like the one above, is crucial. Most often, we have more than one kind of observation that we care about. Most often, we care about systematic relationships between different observables in the world. For instance, we might want to look at pass/fail results from an exam in co-occurrence with information about the proportion of attendance of the course's tutorial sessions:

```{r}
# proportion of tutorials attended and exam pass/fail
exam_results <- 
  tribble(
    ~student,   ~tutorial_proportion,   ~pass,
    "Jax",      0.0,                    TRUE,
    "Jason",    0.78,                   FALSE,
    "Jamie",    0.39,                   TRUE
  )
exam_results
```

Data of this kind is also called **rectangular data**, i.e., data that fits into a rectangular table (More on the structure of rectangular data in Section \@ref(Chap-02-02-data-tidy-data).). In the example above, every column represents a **variable** of interest. A *(data) variable* stores the observations that are of the same kind.^[This sense of "data variable" is not to be confused with the notion of a "random variable", a concept we will introduce later in Section \@ref(Chap-03-01-probability-random-variables). The term "data variable" is not commonly used; the common term is merely "variable".]

Common kinds of variables are distinguished based on the structural properties of the kinds of observations that they contain. Common types of empirical data collected are:

- **nominal variable**: each observation is an instance of a (finite) set of clearly distinct categories, lacking a natural ordering;
- **binary variable**: special case of nominal variable when there are only two categories;
- **Boolean variable**: special case of a binary variable when the two categories are Boolean values "true" and "false";
- **ordinal variable**: each observation is an instance of a (finite) set of clearly distinct and naturally ordered categories, but there is no natural meaning of distance between categories (i.e., it makes sense to say that A is "more" than B but not that A is three times "more" than B);
- **metric variable**: each observation is isomorphic to a subset of the reals and interval-scaled (i.e., it makes sense to say that A is three times "more" than B);

Examples of some different kinds of variables are shown in Figure \@ref(fig:Ch-02-01-factor-levels) and Table \@ref(tab:Ch-02-01-variable-types-in-R) lists common and/or natural ways of representing different kinds of (data) variables in R.

```{r Ch-02-01-factor-levels, echo = F, fig.cap="Examples of different kinds of (data) variables."}
knitr::include_graphics("visuals/factor-levels.jpg")
```


```{r Ch-02-01-variable-types-in-R, echo = F}
table_data <- tribble(
  ~"variable type", ~"representation in R",
  "nominal / binary", "unordered factor",
  "boolean", "logical vector",
  "ordinal", "ordered factor",
  "metric", "numeric vector"
)
knitr::kable(
  table_data,
  caption = "Common / natural formats for representing data of different kinds in R.", 
  booktabs = TRUE
)
```


In experimental data, we also distinguish the **dependent variable(s)** from the **independent variables**. The dependent variables are the variables that we do not control or manipulate in the experiment, but the ones that we are curious to record (e.g., whether a patient recovered from an illness within a week). Dependent variables are also called **to-be-explained variables**. The independent variables are the variables in the experiment that we manipulate (e.g., which drug to administer), usually with the intention of seeing a particular effect on the dependent variables. Independent variables are also called **explanatory variables**.

## Basics of experimental design {#Chap-02-01-data-exp-design}

The most basic template for an experiment, inspired clearly by the natural sciences, is to just measure a quantity of interest (the dependent variable), without taking into account any kind of variation in any kind of independent variables. For instance, we measure the time it takes for an object, with specific shape and weight, to hit the ground when dropped from a height of exactly 2 meters. To filter out **measurement noise**, we do not just record one observation, but take a fair amount. We use the observed times, for instance, to test a theory about acceleration and gravity. Data from such a simple measurement experiment would be just a single vector of numbers.

A more elaborate kind of experiment would allow for at least one independent variable. Another archetypical example of an empirical experiment would be a medical study, e.g., one in which we are interested in the effect of a particular drug on the blood pressure of patients. We would then randomly allocate each participant to one of two groups. One group, the **treatment group**, receives the drug in question; the other group, **the control group**, receives a placebo (and nobody, not even the experimenter, knows who receives what). After a pre-defined exposure to either drug or placebo, blood pressure (for simplicity, just systolic blood pressure) is measured. The interesting question is whether there is a difference between the measurements across groups. This is a simple example of a **one-factor design**. The factor in question is which group any particular measurement belongs to. Data from such an experiment could look like this:

```{r}
tribble(
  ~subj_id,     ~group,        ~systolic,   
  1,            "treatment",   118,
  2,            "control",     132,
  3,            "control",     116,
  4,            "treatment",   127,
  5,            "treatment",   122
)
```

For the purposes of this course, which is not a course on experimental design, just a few key concepts of experimental design are important to be aware of. We will go through some of these issues in the following.

### What to analyze? -- Dependent variables

To begin with, it is important to realize that there is quite some variation in what counts as a dependent variable. Not only can there be more than one dependent variable, but each dependent variable can also be of quite a different type (nominal, ordinal, metric, ...), as discussed in the previous section. Moreover, we need to carefully distinguish between the actual measurement/observation and the dependent variable itself. The dependent variable is (usually) what we plot, analyze and discuss, but very often, we measure much more or something else. The dependent variable (of analysis) could well just be one part of the measurement. For example, a standard measure of blood pressure has a number for systolic and another for diastolic pressure. Focussing on just one of these numbers is a (hopefully: theoretically motivated; possibly: arbitrary; in the worst case: result-oriented) decision of the analyst. More interesting examples of such **data preprocessing** frequently arise in the cognitive sciences, for example:

- **eye-tracking**: the measured data are triples consisting of a time-point and two spatial coordinates, but what might be analyzed is just the relative proportion of looks at a particular spatial region of interest (some object on the screen) in a particular temporal region of interest (up to 200 ms after the image appeared);
- **EEG**: individual measurements obtained by EEG are very noisy, so that the dependent measure in many analyses is an aggregation over the mean voltage recorded by selected electrodes, where averages are taken for a particular subject over many trials of the same condition (repeated measures) that this subject has seen;

But we do not need to go fancy in our experimental methods, to see how issues of data processing affect data analysis at its earliest stages, namely by selecting the dependent variable (that which is to be analyzed). Just take the distinction between **closed questions** and **open questions** in text-based surveys. In closed questions, participants select an answer from a finite (usually) small number of choices. In open questions, however, they can write text freely, or they can draw, sing, pronounce, gesture etc. Open response formats are great and naturalistic, but they, too, often require the analyst to carve out a particular aspect of the (rich, natural) observed reality to enter analysis.

### Conditions, trials, items

A **factorial design** is an experiment with at least two independent variables, all of which are (ordered or unordered) factors.^[The archetypical medical experiment discussed above is a *one-factor design*. In contrast, the term 'factorial design' is usually used to refer to what is also often called a **full factorial design**.  These are designs with at least two independent variables.] Factorial designs are often described in terms of short abbreviations. For example, an experiment described as a "$2 \times 3$ factorial design" would have two factors of interest, the first of which has two levels, the second of which has three levels (such as a distinction between control and treatment group, and an orthogonal distinction of gender in categories 'male', 'female' and 'non-binary'). Many psychological studies are factorial designs. Whole batteries of analysis techniques have been developed specifically tuned to these kinds of experiments.

For a $2 \times 2 \times 3$ factorial design, there are `2 * 2 * 3 = 12` different **experimental conditions** (also sometimes called **design cells**). An important distinction in experimental design is whether all participants contribute data to all of the experimental conditions, or whether each only contributes to a part of it. If participants only contribute data to a part of all experimental conditions, this is called a **between-subjects design**. If all participants contribute data to all experimental conditions, we speak of a **within-subjects design**. Clearly, sometimes the nature of a design factor determines whether the study can be within-subjects. For example, switching gender for the purpose of a medical study on blood pressure drugs is perhaps a tad much to ask of a participant (though certainly a very enlightening experience). If there is room for the experimenter's choice of study type, it pays to be aware of some of the clear advantages and drawbacks of either method, as listed in Table \@ref(tab:Ch-02-01-comparison-designs).

```{r Ch-02-01-comparison-designs, echo = F}
table_data <- tribble(
  ~"between-subjects", ~"within-subjects",
  "no confound between conditions", "possible cross-contamination between conditions",
  "more participants needed", "fewer participants needed",
  "less associated information for analysis", "more associated data for analysis"
)
knitr::kable(
  table_data,
  caption = "Comparison of the pros and cons of between- and within-subjects designs.", 
  booktabs = TRUE
)
```

No matter whether we are dealing with a between- or within-subjects design, another important question is whether each participant gives us only one or more than one observation per cell. If participants contribute more than one observation to a design cell, we speak of a *repeated measures* design. Such designs are useful as they help separate the signal from the noise (recall the initial example of time measurement from physics). They are also economical because getting several observations worth of relevant data from a single participant for each condition means that we have to get fewer people to do the experiment (normally). 

However, exposing a participant repeatedly to the same experimental condition can be detrimental to an experiment's purpose. Participants might recognize the repetition and develop quick coping strategies to deal with the boredom, for example. For this reason, repeated measures designs usually include different kinds of trials:

- **critical trials** belong to, roughly put, the actual experiment, e.g., one of the experiment's design cells;
- **filler trials** are packaged around the critical trials to prevent blatant repetition, predictability or recognition of the experiment's purpose
- **control trials** are trials whose data is used not for statistics inference but for checking the quality of the data (e.g., attention checks or tests of whether a participant understood the task correctly)

When participants are exposed to several different kinds of trials and even several instances of the same experimental condition, it is also often important to introduce some variability between the instances of the same types of trials. Therefore, psychological experiments often use different **items**, i.e., different (theoretically exchangeable) instantiations of the same (theoretically important) pattern. For example, if a careful psycholinguist designs a study on the processing of garden-path sentences, she will include not just one example ("The horse raced past the barn fell") but several (e.g., "Since Jones frequently jogs a mile is a short distance to her"). Item-variability is also important for statistical analyses, as we will see when we talk about hierarchical modeling in Section \@ref(ch-05-05-hierarchical-modeling).

In longer experiments, especially within-subjects repeated measures designs in which participants encounter a lot of different items for each experimental condition, clever regimes of **randomization** are important to minimize the possible effect of carry-over artifacts, for example. A frequent method is **pseudo-randomization**, where the trial sequence is not completely arbitrary but arbitrary within certain constraints, such as a particular **block design**, where each block presents an identical number of trials of each type, but each block shuffles the sequence of its types completely at random. 

The complete opposite of a within-participants repeated measures design is a so-called **single-shot experiment** in which any participant gives exactly one data point for one experimental condition. 

### Sample size

A very important question for experimental design is that of the **sample size**: how many data points do we need (per experimental condition)? We will come back to this issue only much later in this course when we talk about statistical inference. This is because the decision of how many, say, participants to invite for a study, should ideally be influenced, not by the available time and money, but also by statistical considerations of the kind: how many data points do I need in order to obtain a reasonable level of confidence in the resulting statistical inferences I care about?



